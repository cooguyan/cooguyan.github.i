<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[5_Parallel_Memory_System]]></title>
    <url>%2F2019%2F01%2F30%2F5_Parallel_Memory_System%2F</url>
    <content type="text"><![CDATA[Outside of the GPU itself, the memory subsystem is the most important determiner of the performance of a graphics system. Graphics workloads demand very high transfer rates to and from memory. Pixel write and blend (read-modifywrite) operations, depth buffer reads and writes, and texture map reads, as well as command and object vertex and attribute data reads, comprise the majority of memory traffic.在GPU本身之外，存储器子系统是图形系统性能的最重要的决定因素。 图形工作负载需要非常高的内存传输速率。 像素写入和混合（读取 - 修改写入）操作，深度缓冲区读取和写入以及纹理映射读取以及命令和对象顶点和属性数据读取构成了大部分内存流量。Modern GPUs are highly parallel, as shown in Figure C.2.5. For example, the GeForce 8800 can process 32 pixels per clock, at 600 MHz. Each pixel typically requires a color read and write and a depth read and write of a 4-byte pixel. Usually an average of two or three texels of four bytes each are read to generate the pixel’s color. So for a typical case, there is a demand of 28 bytes times 32 pixels = 896 bytes per clock. Clearly the bandwidth demand on the memory system is enormous.现代GPU高度并行，如图C.2.5所示。 例如，GeForce 8800每时钟可处理32个像素，频率为600 MHz。 每个像素通常需要颜色读取和写入以及4字节像素的深度读取和写入。 通常，读取平均每个四个字节的两个或三个纹素，以生成像素的颜色。 因此，对于典型情况，需要28个字节乘以32个像素=每个时钟896个字节。 显然，存储系统的带宽需求是巨大的。 To supply these requirements, GPU memory systems have the following characteristics:为满足这些要求，GPU内存系统具有以下特征： They are wide, meaning there are a large number of pins to convey data between the GPU and its memory devices, and the memory array itself comprises many DRAM chips to provide the full total data bus width. 它们很宽，意味着有大量的引脚在GPU和它的存储器设备之间传送数据，并且存储器阵列本身包括许多DRAM芯片以提供完整的总数据总线宽度。 They are fast, meaning aggressive signaling techniques are used to maximize the data rate (bits/second) per pin. 它们很快，意味着积极的信令技术用于最大化每个引脚的数据速率（位/秒）。 GPUs seek to use every available cycle to transfer data to or from the memory array. To achieve this, GPUs specifcally do not aim to minimize latency to the memory system. High throughput (utilization efciency) and short latency are fundamentally in conﬂict. GPU寻求使用每个可用周期来将数据传输到存储器阵列或从存储器阵列传输数据。 为实现此目的，GPU特别不旨在最小化对存储器系统的延迟。 高吞吐量（利用效率）和短延迟基本上是冲突的。 Compression techniques are used, both lossy, of which the programmer must be aware, and lossless, which is invisible to the application and opportunistic. 使用压缩技术，既有损耗，程序员必须知道，无损，对应用程序和机会主义是不可见的。 Caches and work coalescing structures are used to reduce the amount of offchip traffic needed and to ensure that cycles spent moving data are used as fully as possible. 高速缓存和工作合并结构用于减少所需的片外流量，并确保尽可能充分地使用移动数据的周期。 DRAM Considerations DRAM注意事项GPUs must take into account the unique characteristics of DRAM. DRAM chips are internally arranged as multiple (typically four to eight) banks, where each bank includes a power-of-2 number of rows (typically around 16,384), and each row contains a power-of-2 number of bits (typically 8192). DRAMs impose a variety of timing requirements on their controlling processor. For example, dozens of cycles are required to activate one row, but once activated, the bits within that row are randomly accessible with a new column address every four clocks. Double-data rate (DDR) synchronous DRAMs transfer data on both rising and falling edges of the interface clock (see Chapter 5). So a 1 GHz clocked DDR DRAM transfers data at 2 gigabits per second per data pin. Graphics DDR DRAMs usually have 32 bidirectional data pins, so eight bytes can be read or written from the DRAM per clock.GPU必须考虑DRAM的独特特性。 DRAM芯片内部排列为多个（通常为四到八个）存储体，其中每个存储体包括2个幂的行数（通常约为16,384个），每行包含2个幂的位数（通常为8192个））。 DRAM对其控制处理器施加了各种时序要求。 例如，激活一行需要几十个周期，但一旦激活，该行中的位可随机访问，每四个时钟使用一个新的列地址。 双倍数据速率（DDR）同步DRAM在接口时钟的上升沿和下降沿传输数据（见第5章）。 因此，1 GHz时钟DDR DRAM以每个数据引脚每秒2千兆位的速度传输数据。 图形DDR DRAM通常具有32个双向数据引脚，因此每个时钟可以从DRAM读取或写入8个字节。 GPUs internally have a large number of generators of memory traffic. Different stages of the logical graphics pipeline each have their own request streams: command and vertex attribute fetch, shader texture fetch and load/store, and pixel depth and color read-write. At each logical stage, there are ofen multiple independent units to deliver the parallel throughput. These are each independent memory requestors. When viewed at the memory system, there are an enormous number of uncorrelated requests in ﬂight. This is a natural mismatch to the reference pattern preferred by the DRAMs. A solution is for the GPU’s memory controller to maintain separate heaps of trafc bound for diﬀerent DRAM banks, and wait until enough traffic for a particular DRAM row is pending before activating that row and transferring all the trafc at once. Note that accumulating pending requests, while good for DRAM row locality and thus efcient use of the data bus, leads to longer average latency as seen by the requestors whose requests spend time waiting for others. The design must take care that no particular request waits too long, otherwise some processing units can starve waiting for data and ultimately cause neighboring processors to become idle.GPU内部具有大量内存流量生成器。逻辑图形管道的不同阶段各自具有其自己的请求流：命令和顶点属性获取，着色器纹理获取和加载/存储，以及像素深度和颜色读写。在每个逻辑阶段，有多个独立单元来提供并行吞吐量。这些是每个独立的内存请求者。在内存系统中查看时，飞行中存在大量不相关的请求。这与DRAM优选的参考图案自然不匹配。一种解决方案是GPU的内存控制器维护绑定到不同DRAM库的单独的流量堆，并等待特定DRAM行的足够流量待激活，然后激活该行并立即传输所有流量。请注意，累积待处理请求虽然有利于DRAM行位置并因此有效地使用数据总线，但会导致请求者花费时间等待其他请求者的平均延迟时间更长。设计必须注意没有特定请求等待太长时间，否则一些处理单元可能会饿死等待数据并最终导致相邻处理器变为空闲。 GPU memory subsystems are arranged as multiple memory partitions, each of which comprises a fully independent memory controller and one or two DRAM devices that are fully and exclusively owned by that partition. To achieve the best load balance and therefore approach the theoretical performance of n partitions, addresses are fnely interleaved evenly across all memory partitions. The partition interleaving stride is typically a block of a few hundred bytes. The number of memory partitions is designed to balance the number of processors and other memory requesters.GPU存储器子系统被布置为多个存储器分区，每个存储器分区包括完全独立的存储器控制器和由该分区完全和专有地拥有的一个或两个DRAM设备。 为了实现最佳负载平衡并因此接近n个分区的理论性能，地址在所有内存分区上均匀地交错。 分区交织步幅通常是几百字节的块。 内存分区的数量旨在平衡处理器和其他内存请求者的数量。 CachesGPU workloads typically have very large working sets—on the order of hundreds of megabytes to generate a single graphics frame. Unlike with CPUs, it is not practical to construct caches on chips large enough to hold anything close to the full working set of a graphics application. Whereas CPUs can assume very high cache hit rates (99.9% or more), GPUs experience hit rates closer to 90% and must therefore cope with many misses in ﬂight. While a CPU can reasonably be designed to halt while waiting for a rare cache miss, a GPU needs to proceed with misses and hits intermingled. We call this a streaming cache architecture.GPU工作负载通常具有非常大的工作集 - 大约数百兆字节以生成单个图形帧。 与CPU不同，在足够大的芯片上构建缓存以保存靠近图形应用程序的完整工作集的任何东西都是不实际的。 虽然CPU可以承担非常高的缓存命中率（99.9％或更高），但GPU的命中率接近90％，因此必须应对飞行中的许多未命中。 虽然CPU可以合理地设计为在等待罕见的高速缓存未命中时停止，但是GPU需要继续进行未命中和命中混合。 我们称之为流缓存架构。 GPU caches must deliver very high-bandwidth to their clients. Consider the case of a texture cache. A typical texture unit may evaluate two bilinear interpolations for each of four pixels per clock cycle, and a GPU may have many such texture units all operating independently. Each bilinear interpolation requires four separate texels, and each texel might be a 64-bit value. Four 16-bit components are typical. Thus, total bandwidth is 2 x 4 x 4 x 64 = 2048 bits per clock. Each separate 64-bit texel is independently addressed, so the cache needs to handle 32 unique addresses per clock. This naturally favors a multibank and/or multiport arrangement of SRAM arrays.GPU缓存必须为其客户提供非常高的带宽。 考虑纹理缓存的情况。 典型的纹理单元可以针对每个时钟周期的四个像素中的每一个评估两个双线性插值，并且GPU可以具有全部独立操作的许多这样的纹理单元。 每个双线性插值需要四个单独的纹素，每个纹素可能是64位值。 通常有四个16位组件。 因此，总带宽是每时钟2×4×4×64 = 2048比特。 每个独立的64位纹素都是独立寻址的，因此缓存需要每个时钟处理32个唯一地址。 这自然有利于SRAM阵列的多库和/或多端口布置。 MMUModern GPUs are capable of translating virtual addresses to physical addresses. On the GeForce 8800, all processing units generate memory addresses in a 40-bit virtual address space. For computing, load and store thread instructions use 32-bit byte addresses, which are extended to a 40-bit virtual address by adding a 40-bit offset. A memory management unit performs virtual to physical address translation; hardware reads the page tables from local memory to respond to misses on behalf of a hierarchy of translation lookaside buffers spread out among the processors and rendering engines. In addition to physical page bits, GPU page table entries specify the compression algorithm for each page. Page sizes range from 4 to 128 kilobytes.现代GPU能够将虚拟地址转换为物理地址。 在GeForce 8800上，所有处理单元都在40位虚拟地址空间中生成内存地址。 对于计算，加载和存储线程指令，使用32位字节地址，通过添加40位偏移量将其扩展为40位虚拟地址。 存储器管理单元执行虚拟到物理地址转换; 硬件从本地存储器读取页表以代表在处理器和呈现引擎之间展开的转换后备缓冲器的层次结构来响应未命中。 除了物理页面位之外，GPU页表条目还为每个页面指定压缩算法。 页面大小范围为4到128千字节。 Memory SpacesAs introduced in Section C.3, CUDA exposes different memory spaces to allow the programmer to store data values in the most performance-optimal way. For the following discussion, NVIDIA Tesla architecture GPUs are assumed.如C.3节所述，CUDA公开了不同的内存空间，以允许程序员以最佳性能最佳的方式存储数据值。 对于以下讨论，假设使用NVIDIA Tesla架构GPU。 Global memoryGlobal memory is stored in external DRAM; it is not local to any one physical streaming multiprocessor (SM) because it is meant for communication among different CTAs (thread blocks) in different grids. In fact, the many CTAs that reference a location in global memory may not be executing in the GPU at the same time; by design, in CUDA a programmer does not know the relative order in which CTAs are executed. Because the address space is evenly distributed among all memory partitions, there must be a read/write path from any streaming multiprocessor to any DRAM partition. 1399/5000全局存储器存储在外部DRAM中;它不是任何一个物理流多处理器（SM）的本地，因为它用于不同网格中不同CTA（线程块）之间的通信。实际上，引用全局存储器中的位置的许多CTA可能不会同时在GPU中执行;按照设计，在CUDA中，程序员不知道执行CTA的相对顺序。由于地址空间均匀分布在所有内存分区中，因此必须存在从任何流式多处理器到任何DRAM分区的读/写路径。 Access to global memory by different threads (and diﬀerent processors) is not guaranteed to have sequential consistency. Thread programs see a relaxed memory ordering model. Within a thread, the order of memory reads and writes to the same address is preserved, but the order of accesses to different addresses may not be preserved. Memory reads and writes requested by different threads are unordered. Within a CTA, the barrier synchronization instruction bar.sync can be used to obtain strict memory ordering among the threads of the CTA. The membar thread instruction provides a memory barrier/fence operation that commits prior memory accesses and makes them visible to other threads before proceeding. Threads can also use the atomic memory operations described in Section C.4 to coordinate work on memory they share.不同线程（和不同的处理器）对全局内存的访问不保证具有顺序一致性。 线程程序看到放松的内存排序模型。 在线程内，保留了对同一地址的内存读取和写入顺序，但可能无法保留对不同地址的访问顺序。 不同线程请求的内存读取和写入是无序的。 在CTA中，屏障同步指令bar.sync可用于在CTA的线程之间获得严格的内存排序。 membar线程指令提供了一个内存屏障/围栅操作，它提交先前的内存访问，并使其在继续之前对其他线程可见。 线程还可以使用第C.4节中描述的原子内存操作来协调它们共享的内存的工作。 Shared memoryPer-CTA shared memory is only visible to the threads that belong to that CTA, and shared memory only occupies storage from the time a CTA is created to the time it terminates. Shared memory can therefore reside on-chip. This approach has many benefits. First, shared memory traffic does not need to compete with limited off-chip bandwidth needed for global memory references. Second, it is practical to build very high-bandwidth memory structures on-chip to support the read/write demands of each streaming multiprocessor. In fact, the shared memory is closely coupled to the streaming multiprocessorPer-CTA共享内存仅对属于该CTA的线程可见，共享内存仅占用从创建CTA到终止时的存储。 因此，共享存储器可以驻留在芯片上。 这种方法有很多好处。 首先，共享内存流量不需要与全局内存引用所需的有限片外带宽竞争。 其次，在片上构建非常高带宽的存储器结构以支持每个流多处理器的读/写需求是实用的。 实际上，共享存储器与流式多处理器紧密耦合 Each streaming multiprocessor contains eight physical thread processors. During one shared memory clock cycle, each thread processor can process two threads’ worth of instructions, so 16 threads’ worth of shared memory requests must be handled in each clock. Because each thread can generate its own addresses, and the addresses are typically unique, the shared memory is built using 16 independently addressable SRAM banks. For common access patterns, 16 banks are sufcient to maintain throughput, but pathological cases are possible; for example, all 16 threads might happen to access a different address on one SRAM bank. It must be possible to route a request from any thread lane to any bank of SRAM, so a 16-by-16 interconnection network is required.每个流式多处理器包含八个物理线程处理器。 在一个共享内存时钟周期内，每个线程处理器可以处理两个线程的指令，因此必须在每个时钟中处理16个线程的共享内存请求。 由于每个线程都可以生成自己的地址，并且地址通常是唯一的，因此共享内存使用16个可独立寻址的SRAM bank构建。 对于常见的访问模式，16个银行足以维持吞吐量，但病理情况是可能的; 例如，所有16个线程可能碰巧访问一个SRAM组上的不同地址。 必须可以将来自任何线程通道的请求路由到任何SRAM组，因此需要16×16的互连网络。 Local MemoryPer-thread local memory is private memory visible only to a single thread. Local memory is architecturally larger than the thread’s register file, and a program can compute addresses into local memory. To support large allocations of local memory (recall the total allocation is the per-thread allocation times the number of active threads), local memory is allocated in external DRAM. Although global and per-thread local memory reside oﬀ-chip, they are wellsuited to being cached on-chip.每线程本地内存是仅对单个线程可见的私有内存。 本地存储器在体系结构上比线程的寄存器文件大，并且程序可以将地址计算到本地存储器中。 为了支持本地内存的大量分配（调用总分配是每线程分配乘以活动线程数），本地内存分配在外部DRAM中。 虽然全局和每线程本地内存驻留在芯片上，但它们非常适合在片上缓存。 Constant MemoryConstant memory is read-only to a program running on the SM (it can be written via commands to the GPU). It is stored in external DRAM and cached in the SM. Because commonly most or all threads in a SIMT warp read from the same address in constant memory, a single address lookup per clock is sufcient. The constant cache is designed to broadcast scalar values to threads in each warp.常量存储器对SM上运行的程序是只读的（可以通过命令写入GPU）。 它存储在外部DRAM中并缓存在SM中。 因为SIMT warp中的大多数或所有线程通常从常量存储器中的相同地址读取，所以每个时钟的单个地址查找是足够的。 常量缓存旨在向每个warp中的线程广播标量值。 Texture MemoryTexture memory holds large read-only arrays of data. Textures for computing have the same attributes and capabilities as textures used with 3D graphics. Although textures are commonly two-dimensional images (2D arrays of pixel values), 1D (linear) and 3D (volume) textures are also available.纹理内存包含大量只读数据数组。 用于计算的纹理具有与用于3D图形的纹理相同的属性和能力。 虽然纹理通常是二维图像（像素值的2D阵列），但也可以使用1D（线性）和3D（体积）纹理。 A compute program references a texture using a tex instruction. Operands include an identifer to name the texture, and 1, 2, or 3 coordinates based on the texture dimensionality. Te ﬂoating-point coordinates include a fractional portion that specifes a sample location, ofen in between texel locations. Noninteger coordinates invoke a bilinear weighted interpolation of the four closest values (for a 2D texture) before the result is returned to the program.计算程序使用tex指令引用纹理。 操作数包括用于命名纹理的标识符，以及基于纹理维度的1,2或3个坐标。 浮点坐标包括指定样本位置的小数部分，位于纹素位置之间。 在将结果返回到程序之前，非整数坐标调用四个最接近值（对于2D纹理）的双线性加权插值。 Texture fetches are cached in a streaming cache hierarchy designed to optimize throughput of texture fetches from thousands of concurrent threads. Some programs use texture fetches as a way to cache global memory.纹理提取缓存在流缓存层次结构中，旨在优化来自数千个并发线程的纹理提取的吞吐量。 一些程序使用纹理提取作为缓存全局内存的方法。 SurfacesSurface is a generic term for a one-dimensional, two-dimensional, or threedimensional array of pixel values and an associated format. A variety of formats are defned; for example, a pixel may be defned as four 8-bit RGBA integer components, or four 16-bit ﬂoating-point components. A program kernel does not need to know the surface type. A tex instruction recasts its result values as ﬂoating-point, depending on the surface format. Load/Store AccessLoad/store instructions with integer byte addressing enable the writing and compiling of programs in conventional languages like C and C++. CUDA programs use load/store instructions to access memory.带有整数字节寻址的加载/存储指令可以用C和C ++等传统语言编写和编译程序。 CUDA程序使用加载/存储指令来访问内存。 To improve memory bandwidth and reduce overhead, the local and global load/store instructions coalesce individual parallel thread requests from the same warp together into a single memory block request when the addresses fall in the same block and meet alignment criteria. Coalescing individual small memory requests into large block requests provides a signifcant performance boost over separate requests. Te large thread count, together with support for many outstanding load requests, helps cover load-to-use latency for local and global memory implemented in external DRAM.为了改善存储器带宽并减少开销，当地址落入同一块并满足对齐标准时，本地和全局加载/存储指令将来自相同warp的各个并行线程请求合并为单个存储器块请求。 将单个小内存请求合并到大块请求中可以显着提升单独请求的性能。 大线程数以及对许多未完成的负载请求的支持有助于覆盖外部DRAM中实现的本地和全局内存的负载使用延迟。 ROPAs shown in Figure C.2.5, NVIDIA Tesla architecture GPUs comprise a scalable streaming processor array (SPA), which performs all of the GPU’s programmabl calculations, and a scalable memory system, which comprises external DRAM control and fxed function Raster Operation Processors (ROPs) that perform color and depth framebuffer operations directly on memory. Each ROP unit is paired with a specifc memory partition. ROP partitions are fed from the SMs via an interconnection network. Each ROP is responsible for depth and stencil tests and updates, as well as color blending. The ROP and memory controllers cooperate to implement lossless color and depth compression (up to 8:1) to reduce external bandwidth demand. ROP units also perform atomic operations on memory.如图C.2.5所示，NVIDIA Tesla架构GPU包括一个可扩展的流处理器阵列（SPA），它执行所有GPU的programmabl计算，以及一个可扩展的存储器系统，包括外部DRAM控制和固定功能光栅操作处理器（ROP） ）直接在内存上执行颜色和深度帧缓冲操作。 每个ROP单元与特定的内存分区配对。 ROP分区通过互连网络从SM馈送。 每个ROP负责深度和模板测试和更新，以及颜色混合。 ROP和内存控制器协同工作，实现无损色彩和深度压缩（高达8：1），以减少外部带宽需求。 ROP单元还对内存执行原子操作。]]></content>
      <categories>
        <category>GPU相关</category>
      </categories>
      <tags>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4_Multithreaded_Multiprocessor_Architecture]]></title>
    <url>%2F2019%2F01%2F27%2FMultithreaded_Multiprocessor_Architecture%2F</url>
    <content type="text"><![CDATA[To address different market segments, GPUs implement scalable numbers of multiprocessors—in fact, GPUs are multiprocessors composed of multiprocessors. Furthermore, each multiprocessor is highly multithreaded to execute many fine-grained vertex and pixel shader threads efficiently. A quality basic GPU has two to four multiprocessors, while a gaming enthusiast’s GPU or computing platform has dozens of them. This section looks at the architecture of one such multithreaded multiprocessor, a simplifed version of the NVIDIA Tesla streaming multiprocessor (SM) described in Section C.7.为了解决不同的细分市场，GPU实现了可扩展数量的多处理器 - 实际上，GPU是由多处理器组成的多处理器。 此外，每个多处理器都是高度多线程的，可以有效地执行许多细粒度的顶点和像素着色器线程。 高质量的基本GPU有两到四个多处理器，而游戏爱好者的GPU或计算平台有几十个。 本节介绍一个这样的多线程多处理器的体系结构，这是第C.7节中描述的NVIDIA Tesla流多处理器（SM）的简化版本。 Why use a multiprocessor, rather than several independent processors? The parallelism within each multiprocessor provides localized high performance and supports extensive multithreading for the fine-grained parallel programming models described in Section C.3. The individual threads of a thread block execute together within a multiprocessor to share data. The multithreaded multiprocessor design we describe here has eight scalar processor cores in a tightly coupled architecture, and executes up to 512 threads (the SM described in Section C.7 executes up to 768 threads). For area and power effciency, the multiprocessor shares large complex units among the eight processor cores, including the instruction cache, the multithreaded instruction unit, and the shared memory RAM.为什么要使用多处理器，而不是几个独立的处理器？ 每个多处理器内的并行性提供了本地化的高性能，并支持C.3节中描述的细粒度并行编程模型的广泛多线程。 线程块的各个线程在多处理器内一起执行以共享数据。 我们在这里描述的多线程多处理器设计在紧密耦合(tightly coupled)的架构中有八个标量处理器内核，并执行多达512个线程（C.7节中描述的SM执行多达768个线程）。 对于面积和功率效率，多处理器在八个处理器内核之间共享大型复杂单元，包括指令高速缓存，多线程指令单元和共享内存RAM。 Massive MultithreadingGPU processors are highly multithreaded to achieve several goals:GPU处理器是高度多线程的，以实现几个目标： Cover the latency of memory loads and texture fetches from DRAM 覆盖DRAM中存储器加载和纹理提取的延迟 Support fine-grained parallel graphics shader programming models 支持细粒度并行图形着色器编程模型 Support fine-grained parallel computing programming models 支持细粒度并行计算编程模型 Virtualize the physical processors as threads and thread blocks to provide transparent scalability 将物理处理器虚拟化为线程和线程块，以提供透明的可伸缩性 Simplify the parallel programming model to writing a serial program for one thread 简化并行编程模型，为一个线程编写串行程序 Memory and texture fetch latency can require hundreds of processor clocks, because GPUs typically have small streaming caches rather than large working-set caches like CPUs. A fetch request generally requires a full DRAM access latency plus interconnect and buﬀering latency. Multithreading helps cover the latency with useful computing—while one thread is waiting for a load or texture fetch to complete, the processor can execute another thread. The fne-grained parallel programming models provide literally thousands of independent threads that can keep many processors busy despite the long memory latency seen by individual threads.内存和纹理提取延迟可能需要数百个处理器时钟，因为GPU通常具有小型流缓存，而不是像CPU那样的大型工作集缓存。 获取请求通常需要完整的DRAM访问延迟以及互连和缓冲延迟。 多线程有助于通过有用的计算来弥补延迟 - 当一个线程正在等待加载或纹理提取完成时，处理器可以执行另一个线程。 这些细粒度的并行编程模型提供了数千个独立的线程，即使各个线程看到的内存延迟很长，也可以使许多处理器保持忙碌状态。 A graphics vertex or pixel shader program is a program for a single thread that processes a vertex or a pixel. Similarly, a CUDA program is a C program for a single thread that computes a result. Graphics and computing programs instantiate many parallel threads to render complex images and compute large result arrays. To dynamically balance shifting vertex and pixel shader thread workloads, each multiprocessor concurrently executes multiple different thread programs and different types of shader programs.图形顶点或像素着色器程序是用于处理顶点或像素的单个线程的程序。 类似地，CUDA程序是用于计算结果的单个线程的C程序。 图形和计算程序实例化许多并行线程以渲染复杂图像并计算大型结果数组。 为了动态平衡移位顶点和像素着色器线程工作负载，每个多处理器同时执行多个不同的线程程序和不同类型的着色器程序。 To support the independent vertex, primitive, and pixel programming model of graphics shading languages and the single-thread programming model of CUDA C/C++, each GPU thread has its own private registers, private per-thread memory, program counter, and thread execution state, and can execute an independent code path. To efciently execute hundreds of concurrent lightweight threads, the GPU multiprocessor is hardware multithreaded—it manages and executes hundreds of concurrent threads in hardware without scheduling overhead. Concurrent threads within thread blocks can synchronize at a barrier with a single instruction. Lightweight thread creation, zero-overhead thread scheduling, and fast barrier synchronization effciently support very fne-grained parallelism.为了支持图形着色语言的独立顶点，原始和像素编程模型以及CUDA C / C ++的单线程编程模型，每个GPU线程都有自己的私有寄存器，私有每线程内存，程序计数器和线程执行状态，可以执行独立的代码路径。 为了有效地执行数百个并发轻量级线程，GPU多处理器是硬件多线程的 - 它在硬件中管理和执行数百个并发线程，而无需调度开销。 线程块内的并发线程可以使用单个指令在屏障上同步。 轻量级线程创建，零开销线程调度和快速屏障同步有效地支持非常细粒度的并行性。 Multiprocessor Architecture 多处理器架构A unified graphics and computing multiprocessor executes vertex, geometry, and pixel fragment shader programs, and parallel computing programs. As Figure C.4.1 shows, the example multiprocessor consists of eight scalar processor (SP) cores each with a large multithreaded register fle (RF), two special function units (SFUs), a multithreaded instruction unit, an instruction cache, a read-only constant cache,and a shared memory.统一的图形和计算多处理器执行顶点，几何和像素片段着色器程序以及并行计算程序。 如图C.4.1所示，示例多处理器由8个标量处理器（SP）内核组成，每个内核具有一个大型多线程寄存器（RF），两个特殊功能单元（SFU），一个多线程指令单元，一个指令高速缓存，一个读取器。 只有常量缓存和共享内存。 The 16 KB shared memory holds graphics data buﬀers and shared computing data. CUDA variables declared as __shared__ reside in the shared memory. To map the logical graphics pipeline workload through the multiprocessor multiple times, as shown in Section C.2, vertex, geometry, and pixel threads have independent input and output buffers, and workloads arrive and depart independently of thread execution.16 KB共享内存可存储图形数据缓冲区和共享计算数据。 声明为__shared__ 的CUDA变量驻留在共享内存中。 若要多次映射逻辑图形管道工作负载通过多处理器，如第C.2节所示，顶点，几何和像素线程具有独立的输入和输出缓冲区，并且工作负载独立于线程执行而到达和离开。 Each SP core contains scalar integer and ﬂoating-point arithmetic units that execute most instructions. The SP is hardware multithreaded, supporting up to 64 threads. Each pipelined SP core executes one scalar instruction per thread per clock, which ranges from 1.2 GHz to 1.6 GHz in diﬀerent GPU products. Each SP core has a large RF of 1024 general-purpose 32-bit registers, partitioned among its assigned threads. Programs declare their register demand, typically 16 to 64 scalar 32-bit registers per thread. The SP can concurrently run many threads that use a few registers or fewer threads that use more registers. The compiler optimizes register allocation to balance the cost of spilling registers versus the cost of fewer threads. Pixel shader programs ofen use 16 or fewer registers, enabling each SP to run up to 64 pixel shader threads to cover long-latency texture fetches. Compiled CUDA programs ofen need 32 registers per thread, limiting each SP to 32 threads, which limits such a kernel program to 256 threads per thread block on this example multiprocessor, rather than its maximum of 512 threads.每个SP内核包含执行大多数指令的标量整数和浮点运算单元。 SP是硬件多线程，最多支持64个线程。每个流水线SP核心每个时钟每个线程执行一个标量指令，在不同的GPU产品中，范围从1.2 GHz到1.6 GHz。每个SP内核都有一个1024个通用32位寄存器的大RF，在其分配的线程之间进行分区。程序声明它们的寄存器需求，通常每个线程有16到64个标量32位寄存器。 SP可以同时运行许多线程，这些线程使用少量寄存器或更少使用更多寄存器的线程。编译器优化寄存器分配以平衡溢出寄存器的成本与更少线程的成本。像素着色器程序使用16个或更少的寄存器，使每个SP能够运行多达64个像素着色器线程，以覆盖长延迟纹理提取。编译的CUDA程序每个线程需要32个寄存器，将每个SP限制为32个线程，这在这个示例多处理器上将每个线程块的内核程序限制为256个线程，而不是最多512个线程。 The pipelined SFUs execute thread instructions that compute special functions and interpolate pixel attributes from primitive vertex attributes. These instructions can execute concurrently with instructions on the SPs. The SFU is described later.流水线SFU执行计算特殊函数的线程指令，并从原始顶点属性插入像素属性。 这些指令可以与SP上的指令同时执行。 SFU将在后面描述。 The multiprocessor executes texture fetch instructions on the texture unit via the texture interface, and uses the memory interface for external memory load, store, and atomic access instructions. These instructions can execute concurrently with instructions on the SPs. Shared memory access uses a low-latency interconnection network between the SP processors and the shared memory banks.多处理器通过纹理接口在纹理单元上执行纹理获取指令，并使用存储器接口进行外部存储器加载，存储和原子访问指令。 这些指令可以与SP上的指令同时执行。 共享内存访问使用SP处理器和共享内存库之间的低延迟互连网络。 Single-Instruction Multiple-Thread (SIMT)To manage and execute hundreds of threads running several different programs effciently, the multiprocessor employs a single-instruction multiple-thread (SIMT) architecture. It creates, manages, schedules, and executes concurrent threads in groups of parallel threads called warps. The term warp originates from weaving, the first parallel thread technology. The photograph in Figure C.4.2 shows a warp of parallel threads emerging from a loom. This example multiprocessor uses a SIMT warp size of 32 threads, executing four threads in each of the eight SP cores over four clocks. The Tesla SM multiprocessor described in Section C.7 also uses a warp size of 32 parallel threads, executing four threads per SP core for effciency on plentiful pixel threads and computing threads. Thread blocks consist of one or more warps.为了有效地管理和执行运行多个不同程序的数百个线程，多处理器采用单指令多线程（SIMT）架构。 它在称为warps的并行线程组中创建，管理，调度和执行并发线程。 术语warp源于编织，这是第一个并行线程技术。 图C.4.2中的照片显示了从织机中出现的平行线的翘曲。 此示例多处理器使用32个线程的SIMT warp大小，在四个时钟内的八个SP内核中的每一个中执行四个线程。 第C.7节中描述的Tesla SM多处理器还使用32个并行线程的warp大小，每个SP核心执行四个线程，以便在丰富的像素线程和计算线程上实现效率。 线程块由一个或多个warp组成。 图C.4.2 SIMT多线程warp调度： 调度程序选择就绪warp并同步向组成warp的并行线程发出指令。 由于warp是独立的，因此调度程序可以每次选择不同的warp。 This example SIMT multiprocessor manages a pool of 16 warps, a total of 512 threads. Individual parallel threads composing a warp are the same type and start together at the same program address, but are otherwise free to branch and execute independently. At each instruction issue time, the SIMT multithreaded instruction unit selects a warp that is ready to execute its next instruction, and then issues that instruction to the active threads of that warp. A SIMT instruction is broadcast synchronously to the active parallel threads of a warp; individual threads may be inactive due to independent branching or predication. In this multiprocessor, each SP scalar processor core executes an instruction for four individual threads of a warp using four clocks, reﬂecting the 4:1 ratio of warp threads to cores. single-instruction multiple-thread (SIMT): A processor architecture that applies one instruction to multiple independent threads in parallel. 一种处理器体系结构，可将一条指令并行应用于多个独立线程。 warp: The set of parallel threads that execute the same instruction together in a SIMT architecture. 在SIMT体系结构中一起执行相同指令的并行线程集。 SIMT processor architecture is akin to single-instruction multiple data (SIMD) design, which applies one instruction to multiple data lanes, but diﬀers in that SIMT applies one instruction to multiple independent threads in parallel, not just to multiple data lanes. An instruction for a SIMD processor controls a vector ofmultiple data lanes together, whereas an instruction for a SIMT processor controls an individual thread, and the SIMT instruction unit issues an instruction to a warp of independent parallel threads for efciency. Te SIMT processor fnds data-level parallelism among threads at runtime, analogous to the way a superscalar processor finds instruction-level parallelism among instructions at runtime.此示例SIMT多处理器管理一个包含16个warp的池，总共512个线程。 组成warp的各个并行线程是相同的类型，并且在相同的程序地址处一起开始，但是可以独立地分支和执行。 在每个指令发布时，SIMT多线程指令单元选择准备执行其下一条指令的warp，然后将该指令发布到该warp的活动线程。 SIMT指令与warp的活动并行线程同步广播; 由于独立的分支或预测，各个线程可能不活动。 在这个多处理器中，每个SP标量处理器内核使用四个时钟执行一个经线的四个单独线程的指令，将经线的4：1比率反映到内核。 A SIMT processor realizes full efficiency and performance when all threads of a warp take the same execution path. If threads of a warp diverge via a datadependent conditional branch, execution serializes for each branch path taken, and when all paths complete, the threads converge to the same execution path. For equal length paths, a divergent if-else code block is 50% efficient. The multiprocessor uses a branch synchronization stack to manage independent threads that diverge and converge. Diﬀerent warps execute independently at full speed regardless of whether they are executing common or disjoint code paths. As a result, SIMT GPUs are dramatically more efcient and ﬂexible on branching code than earlier GPUs, as their warps are much narrower than the SIMD width of prior GPUs.当warp的所有线程采用相同的执行路径时，SIMT处理器实现全部效率和性能。 如果warp的线程通过数据相关的条件分支发散，则执行为所采用的每个分支路径进行序列化，并且当所有路径完成时，线程会聚到相同的执行路径。 对于等长路径，发散的if-else代码块效率为50％。 多处理器使用分支同步堆栈来管理分散和聚合的独立线程。 不同的warp全速独立执行，无论它们是执行公共还是不相交的代码路径。 因此，SIMT GPU在分支代码上比早期GPU更加高效和灵活，因为它们的经线比先前GPU的SIMD宽度窄得多。 In contrast with SIMD vector architectures, SIMT enables programmers to write thread-level parallel code for individual independent threads, as well as data-parallel code for many coordinated threads. For program correctness, the programmer can essentially ignore the SIMT execution attributes of warps; however, substantial performance improvements can be realized by taking care that the code seldom requires threads in a warp to diverge. In practice, this is analogous to the role of cache lines in traditional codes: cache line size can be safely ignored when designing for correctness but must be considered in the code structure when designing for peak performance.与SIMD向量体系结构相比，SIMT使程序员能够为各个独立线程编写线程级并行代码，并为许多协调线程编写数据并行代码。 对于程序的正确性，程序员基本上可以忽略warp的SIMT执行属性; 然而，通过注意代码很少需要经线中的线程发散，可以实现显着的性能改进。 实际上，这类似于传统代码中缓存行的作用：在设计正确性时可以安全地忽略缓存行大小，但在设计峰值性能时必须在代码结构中考虑。 SIMT Warp Execution and Divergence 谁能告诉我这个怎么翻译？The SIMT approach of scheduling independent warps is more ﬂexible than the scheduling of previous GPU architectures. A warp comprises parallel threads of the same type: vertex, geometry, pixel, or compute. The basic unit of pixel fragment shader processing is the 2-by-2 pixel quad implemented as four pixel shader threads. The multiprocessor controller packs the pixel quads into a warp. It similarly groups vertices and primitives into warps, and packs computing threads into a warp. A thread block comprises one or more warps. The SIMT design shares the instruction fetch and issue unit efciently across parallel threads of a warp, but requires a full warp of active threads to get full performance effciency.调度独立warp的SIMT方法比先前GPU架构的调度更灵活。 扭曲包括相同类型的并行线程：顶点，几何，像素或计算。 像素片段着色器处理的基本单位是实现为四个像素着色器线程的2×2像素四边形。 多处理器控制器将像素四边形打包成扭曲。 它类似地将顶点和基元分组为warp，并将计算线程打包成warp。 线程块包括一个或多个warp。 SIMT设计在warp的并行线程之间有效地共享指令获取和发布单元，但需要完整的活动线程warp才能获得完全的性能效率。 This unifed multiprocessor schedules and executes multiple warp types concurrently, allowing it to concurrently execute vertex and pixel warps. Its warp scheduler operates at less than the processor clock rate, because there are four thread lanes per processor core. During each scheduling cycle, it selects a warp to execute a SIMT warp instruction, as shown in Figure C.4.2. An issued warp-instruction executes as four sets of eight threads over four processor cycles of throughput. The processor pipeline uses several clocks of latency to complete each instruction. If the number of active warps times the clocks per warp exceeds the pipeline latency, the programmer can ignore the pipeline latency. For this multiprocessor, a round-robin schedule of eight warps has a period of 32 cycles between successive instructions for the same warp. If the program can keep 256 threads active per multiprocessor, instruction latencies up to 32 cycles can be hidden from an individual sequential thread. However, with few active warps, the processor pipeline depth becomes visible and may cause processors to stall.这个统一的多处理器同时调度和执行多个warp类型，允许它同时执行顶点和像素warp。它的warp调度程序以低于处理器时钟速率运行，因为每个处理器内核有四个线程通道。在每个调度周期中，它选择一个warp来执行SIMT warp指令，如图C.4.2所示。发出的warp-instruction在吞吐量的四个处理器周期内作为四组八个线程执行。处理器流水线使用几个延迟时钟来完成每条指令。如果每个warp的时钟的活动warp数乘以管道延迟，则程序员可以忽略管道延迟。对于这种多处理器，八个warp的循环调度在相同warp的连续指令之间具有32个周期的周期。如果程序可以在每个多处理器中保持256个线程处于活动状态，则可以从单个顺序线程中隐藏最多32个周期的指令延迟。但是，由于几乎没有活动warp，处理器管道深度变得可见，并可能导致处理器停止。 A challenging design problem is implementing zero-overhead warp scheduling for a dynamic mix of diﬀerent warp programs and program types. The instruction scheduler must select a warp every four clocks to issue one instruction per clock per thread, equivalent to an IPC of 1.0 per processor core. Because warps are independent, the only dependences are among sequential instructions from the same warp. The scheduler uses a register dependency scoreboard to qualify warps whose active threads are ready to execute an instruction. It prioritizes all such ready warps and selects the highest priority one for issue. Prioritization must consider warp type, instruction type, and the desire to be fair to all active warps.一个具有挑战性的设计问题是为不同的warp程序和程序类型的动态组合实现零开销warp调度。 指令调度程序必须每四个时钟选择一个warp，每个线程每个时钟发出一条指令，相当于每个处理器内核的IPC为1.0。 由于warp是独立的，唯一的依赖是来自同一warp的顺序指令。 调度程序使用寄存器依赖性记分板来限定其活动线程已准备好执行指令的warp。 它优先考虑所有这些准备好的warp并选择最优先的warp。 优先级必须考虑warp类型，指令类型以及对所有活动warp公平的愿望。 Managing Threads and Thread Blocks 管理线程和线程块The multiprocessor controller and instruction unit manage threads and thread blocks. The controller accepts work requests and input data and arbitrates access to shared resources, including the texture unit, memory access path, and I/O paths. For graphics workloads, it creates and manages three types of graphics threads concurrently: vertex, geometry, and pixel. Each of the graphics work types has independent input and output paths. It accumulates and packs each of these input work types into SIMT warps of parallel threads executing the same thread program. It allocates a free warp, allocates registers for the warp threads, and starts warp execution in the multiprocessor. Every program declares its perthread register demand; the controller starts a warp only when it can allocate the requested register count for the warp threads. When all the threads of the warp exit, the controller unpacks the results and frees the warp registers and resources.多处理器控制器和指令单元管理线程和线程块。 控制器接受工作请求和输入数据，并仲裁对共享资源的访问，包括纹理单元，内存访问路径和I / O路径。 对于图形工作负载，它同时创建和管理三种类型的图形线程：顶点，几何和像素。 每个图形工作类型都有独立的输入和输出路径。 它将这些输入工作类型中的每一个累积并打包到执行相同线程程序的并行线程的SIMT warp中。 它分配一个自由warp，为warp线程分配寄存器，并在多处理器中启动warp执行。 每个程序都声明其寄存器需求; 只有当控制器可以为经线分配所请求的寄存器计数时，控制器才会启动warp。 当warp的所有线程退出时，控制器将解压缩结果并释放warp寄存器和资源。 The controller creates cooperative thread arrays (CTAs) which implement CUDA thread blocks as one or more warps of parallel threads. It creates a CTA when it can create all CTA warps and allocate all CTA resources. In addition to threads and registers, a CTA requires allocating shared memory and barriers. The program declares the required capacities, and the controller waits until it can allocate those amounts before launching the CTA. Then it creates CTA warps at the warp scheduling rate, so that a CTA program starts executing immediately at full multiprocessor performance. The controller monitors when all threads of a CTA have exited, and frees the CTA shared resources and its warp resources.控制器创建协作线程阵列（CTA），其将CUDA线程块实现为一个或多个并行线程的warp。 它可以在创建所有CTA warp并分配所有CTA资源时创建CTA。 除线程和寄存器外，CTA还需要分配共享内存和障碍。 程序声明所需的容量，控制器等待，直到它可以在启动CTA之前分配这些数量。 然后它以warp调度速率创建CTA warp，以便CTA程序在完全多处理器性能时立即开始执行。 Te控制器监视CTA的所有线程何时退出，并释放CTA共享资源及其warp资源。 cooperative thread array (CTA) : A set of concurrent threads that executes the same thread program and may cooperate to compute a result. A GPU CTA implements a CUDA thread block. 一组并发线程，它们执行相同的线程程序并可协作计算结果。 GPU CTA实现了CUDA线程块。 Thread Instructions 线程指令The SP thread processors execute scalar instructions for individual threads, unlike earlier GPU vector instruction architectures, which executed four-component vector instructions for each vertex or pixel shader program. Vertex programs generally compute (x, y, z, w) position vectors, while pixel shader programs compute (red, green, blue, alpha) color vectors. However, shader programs are becoming longer and more scalar, and it is increasingly difcult to fully occupy even two components of a legacy GPU four-component vector architecture. In effect, the SIMT architecture parallelizes across 32 independent pixel threads, rather than parallelizing the four vector components within a pixel. CUDA C/C++ programs have predominantly scalar code per thread. Previous GPUs employed vector packing (e.g., combining subvectors of work to gain efciency) but that complicated the scheduling hardware as well as the compiler. Scalar instructions are simpler and compiler friendly. Texture instructions remain vector based, taking a source coordinate vector and returning a filtered color vector.SP线程处理器执行各个线程的标量指令，不像早期的GPU矢量指令架构，后者为每个顶点或像素着色器程序执行四分量矢量指令。顶点程序通常计算（x，y，z，w）位置矢量，而像素着色器程序计算（红色，绿色，蓝色，alpha）颜色矢量。然而，着色器程序变得越来越长并且越来越标量化，并且甚至完全占据传统GPU四分量矢量体系结构的两个组件也变得越来越困难。实际上，SIMT架构在32个独立像素线程之间并行化，而不是并行化像素内的四个矢量分量。 CUDA C / C ++程序每个线程主要有标量代码。先前的GPU采用向量打包（例如，组合工作的子向量以获得效率）但是使调度硬件以及编译器复杂化。标量指令更简单，编译友好。纹理指令保持基于矢量，采用源坐标向量并返回滤波后的颜色向量。 To support multiple GPUs with diﬀerent binary microinstruction formats, highlevel graphics and computing language compilers generate intermediate assemblerlevel instructions (e.g., Direct3D vector instructions or PTX scalar instructions), which are then optimized and translated to binary GPU microinstructions. The NVIDIA PTX (parallel thread execution) instruction set defnition [2007] provides a stable target ISA for compilers, and provides compatibility over several generations of GPUs with evolving binary microinstruction-set architectures. The optimizer readily expands Direct3D vector instructions to multiple scalar binary microinstructions. PTX scalar instructions translate nearly one to one with scalar binary microinstructions, although some PTX instructions expand to multiple binary microinstructions, and multiple PTX instructions may fold into one binary microinstruction. Because the intermediate assembler-level instructions use virtual registers, the optimizer analyzes data dependencies and allocates real registers. The optimizer eliminates dead code, folds instructions together when feasible, and optimizes SIMT branch diverge and converge points.为了支持具有不同二进制微指令格式的多个GPU，高级图形和计算语言编译器生成中间汇编级指令（例如，Direct3D向量指令或PTX标量指令），然后将其优化并转换为二进制GPU微指令。 NVIDIA PTX（并行线程执行）指令集定义[2007]为编译器提供了稳定的目标ISA，并提供了几代GPU与不断发展的二进制微指令集架构的兼容性。优化器很容易将Direct3D向量指令扩展为多个标量二进制微指令。尽管一些PTX指令扩展到多个二进制微指令，但PTX标量指令几乎一对一地转换为标量二进制微指令，并且多个PTX指令可折叠成一个二进制微指令。由于中间汇编程序级指令使用虚拟寄存器，优化程序会分析数据依赖性并分配实际寄存器。优化器消除了死代码，在可行时将指令折叠在一起，并优化SIMT分支发散和收敛点。 Instruction Set Architecture (ISA) 指令集架构The thread ISA described here is a simplifed version of the Tesla architecture PTX ISA, a register-based scalar instruction set comprising ﬂoating-point, integer, logical, conversion, special functions, ﬂow control, memory access, and texture operations. Figure C.4.3 lists the basic PTX GPU thread instructions; see the NVIDIA PTX specifcation [2007] for details. The instruction format is:这里描述的线程ISA是特斯拉架构PTX ISA的简化版本，这是一种基于寄存器的标量指令集，包括浮点，整数，逻辑，转换，特殊函数，流控制，存储器访问和纹理操作。 图C.4.3列出了基本的PTX GPU线程指令; 有关详细信息，请参阅NVIDIA PTX规范[2007]。 指令格式为： 1opcode.type d, a, b, c; where d is the destination operand, a, b, c are source operands, and .type is one of:其中d 是目标操作数，a，b，c是源操作数，而.type是以下之一： Type .type Specifer Untyped bits 8, 16, 32, and 64 bits .b8, .b16, .b32, .b64 Unsigned integer 8, 16, 32, and 64 bits .u8, .u16, .u32, .u64 Signed integer 8, 16, 32, and 64 bits .s8, .s16, .s32, .s64 Floating-point 16, 32, and 64 bits .f16, .f32, .f64 Source operands are scalar 32-bit or 64-bit values in registers, an immediate value, or a constant; predicate operands are 1-bit Boolean values. Destinations are registers, except for store to memory. Instructions are predicated by prefxing them with @p or @!p, where p is a predicate register. Memory and texture instructions transfer scalars or vectors of two to four components, up to 128 bits in total. PTX instructions specify the behavior of one thread.源操作数是寄存器中的标量32位或64位值，立即值或常量; 谓词操作数是1位布尔值。 目标是寄存器，除了存储到存储器。 通过使用@p或@！p对它们进行预处理来预测指令，其中p是谓词寄存器。 内存和纹理指令传输两到四个组件的标量或向量，总共最多128位。 PTX指令指定一个线程的行为。 The PTX arithmetic instructions operate on 32-bit and 64-bit ﬂoating-point, signed integer, and unsigned integer types. Recent GPUs support 64-bit double precision ﬂoating-point; see Section C.6. On current GPUs, PTX 64-bit integer and logical instructions are translated to two or more binary microinstructions that perform 32-bit operations. The GPU special function instructions are limited to 32-bit ﬂoating-point. The thread control ﬂow instructions are conditional branch, function call and return, thread exit, and bar.sync (barrier synchronization). The conditional branch instruction @p bra target uses a predicate register p (or !p) previously set by a compare and set predicate setp instruction to determine whether the thread takes the branch or not. Other instructions can also be predicated on a predicate register being true or false.PTX算术指令对32位和64位浮点，有符号整数和无符号整数类型进行操作。 最近的GPU支持64位双精度浮点; 见C.6节。 在当前的GPU上，PTX 64位整数和逻辑指令被转换为两个或更多个执行32位操作的二进制微指令。 GPU特殊功能指令仅限于32位浮点。 线程控制流程指令是条件分支，函数调用和返回，线程退出和bar.sync（屏障同步）。 条件分支指令@p bra target使用先前由compare和set predicate setp指令设置的谓词寄存器p（或！p）来确定线程是否接受分支。 其他指令也可以在谓词寄存器为真或假的情况下进行预测。 Memory Access Instructions 内存访问指令The tex instruction fetches and filters texture samples from 1D, 2D, and 3D texture arrays in memory via the texture subsystem. Texture fetches generally use interpolated ﬂoating-point coordinates to address a texture. Once a graphics pixel shader thread computes its pixel fragment color, the raster operations processor blends it with the pixel color at its assigned (x, y) pixel position and writes the final color to memory.tex指令通过纹理子系统从内存中的1D，2D和3D纹理数组中提取和过滤纹理样本。 纹理提取通常使用插值的浮点坐标来寻址纹理。 一旦图形像素着色器线程计算其像素片段颜色，光栅操作处理器将其与其指定的（x，y）像素位置处的像素颜色混合，并将最终颜色写入存储器。To support computing and C/C++ language needs, the Tesla PTX ISA implements memory load/store instructions. It uses integer byte addressing with register plus oﬀset address arithmetic to facilitate conventional compiler code optimizations. Memory load/store instructions are common in processors, but are a signifcant new capability in the Tesla architecture GPUs, as prior GPUs provided only the texture and pixel accesses required by the graphics APIs.为了支持计算和C / C ++语言需求，Tesla PTX ISA实现了内存加载/存储指令。 它使用整数字节寻址和寄存器加o ff设置地址算法来促进传统的编译器代码优化。 内存加载/存储指令在处理器中很常见，但在Tesla架构GPU中是一项重要的新功能，因为之前的GPU仅提供图形API所需的纹理和像素访问。For computing, the load/store instructions access three read/write memory spaces that implement the corresponding CUDA memory spaces in Section C.3:对于计算，加载/存储指令访问在C.3节中实现相应CUDA存储空间的三个读/写存储空间： Local memory for per-thread private addressable temporary data (implemented in external DRAM) 每线程专用可寻址临时数据的本地内存（在外部DRAM中实现） Shared memory for low-latency access to data shared by cooperating threads in the same CTA/thread block (implemented in on-chip SRAM) 共享内存，用于对同一CTA /线程块中的协作线程共享的数据进行低延迟访问（在片上SRAM中实现） Global memory for large data sets shared by all threads of a computing application (implemented in external DRAM) 计算应用程序的所有线程共享的大型数据集的全局内存（在外部DRAM中实现） The memory load/store instructions ld.global, st.global, ld.shared, st.shared, ld.local, and st.local access the global, shared, and local memory spaces. Computing programs use the fast barrier synchronization instruction bar.sync to synchronize threads within a CTA/thread block that communicate with each other via shared and global memory.内存加载/存储指令ld.global，st.global，ld.shared，st.shared，ld.local和st.local访问全局，共享和本地内存空间。 计算程序使用快速屏障同步指令bar.sync来同步CTA /线程块内的线程，这些线程通过共享和全局内存相互通信。 To improve memory bandwidth and reduce overhead, the local and global load/store instructions coalesce individual parallel thread requests from the same SIMT warp together into a single memory block request when the addresses fall in the same block and meet alignment criteria. Coalescing memory requests provides a signifcant performance boost over separate requests from individual threads. The multiprocessor’s large thread count, together with support for many outstanding load requests, helps cover load-to-use latency for local and global memory implemented in external DRAM.为了改善存储器带宽并减少开销，当地址落在同一块中并满足对齐标准时，本地和全局加载/存储指令将来自相同SIMT warp的各个并行线程请求合并为单个存储器块请求。 合并内存请求相对于来自各个线程的单独请求提供了显着的性能提升。 多处理器的大线程数以及对许多未完成的负载请求的支持有助于覆盖外部DRAM中实现的本地和全局内存的负载使用延迟。 The latest Tesla architecture GPUs also provide efcient atomic memory operations on memory with the atom.op.u32 instructions, including integer operations add, min, max, and, or, xor, exchange, and cas (compare-and-swap) operations, facilitating parallel reductions and parallel data structure management.最新的Tesla架构GPU还通过atom.op.u32指令在内存上提供有效的原子内存操作，包括整数运算add，min，max和，或者xor，exchange和cas（比较和交换）操作， 促进并行减少和并行数据结构管理。 Barrier Synchronization for Thread Communication 线程通信的屏障同步Fast barrier synchronization permits CUDA programs to communicate frequently via shared memory and global memory by simply calling __syncthreads(); as part of each interthread communication step. The synchronization intrinsic function generates a single bar.sync instruction. However, implementing fast barrier synchronization among up to 512 threads per CUDA thread block is a challenge.快速屏障同步允许CUDA程序通过简单地调用__syncthreads（）;来经常通过共享内存和全局内存进行通信。 作为每个线程交流步骤的一部分。 同步内部函数生成单个bar.sync指令。 但是，在每个CUDA线程块中最多512个线程之间实现快速屏障同步是一项挑战。Grouping threads into SIMT warps of 32 threads reduces the synchronization difculty by a factor of 32. Treads wait at a barrier in the SIMT thread scheduler so they do not consume any processor cycles while waiting. When a thread executes a bar.sync instruction, it increments the barrier’s thread arrival counter and the scheduler marks the thread as waiting at the barrier. Once all the CTA threads arrive, the barrier counter matches the expected terminal count, and the scheduler releases all the threads waiting at the barrier and resumes executing threads.将线程分组为32个线程的SIMT warp可将同步困难减少32倍.Tread在SIMT线程调度程序中等待障碍，以便它们在等待时不消耗任何处理器周期。 当一个线程执行bar.sync指令时，它会递增屏障的线程到达计数器，并且调度程序将该线程标记为在屏障处等待。 一旦所有CTA线程到达，屏障计数器匹配预期的终端计数，并且调度程序释放在屏障处等待的所有线程并继续执行线程。 Streaming Processor (SP) 流处理器（SP）The multithreaded streaming processor (SP) core is the primary thread instruction processor in the multiprocessor. Its register fle (RF) provides 1024 scalar 32-bit registers for up to 64 threads. It executes all the fundamental ﬂoating-point operations, including add.f32, mul.f32, mad.f32 (ﬂoating multiply-add), min.f32, max.f32, and setp.f32 (ﬂoating compare and set predicate). Te ﬂoatingpoint add and multiply operations are compatible with the IEEE 754 standard for single precision FP numbers, including not-a-number (NaN) and infnity values. Te SP core also implements all of the 32-bit and 64-bit integer arithmetic, comparison, conversion, and logical PTX instructions shown in Figure C.4.3.多线程流处理器（SP）内核是多处理器中的主要线程指令处理器。 其寄存器文件（RF）提供1024个标量32位寄存器，最多可支持64个线程。 它执行所有基本的浮点运算，包括add.f32，mul.f32，mad.f32（浮动乘法 - 加法），min.f32，max.f32和setp.f32（浮点数比较和设置谓词）。 对于单精度FP编号，包括非数字（NaN）和无穷大值，Te floatingpoint加法和乘法运算与IEEE 754标准兼容。 Te SP内核还实现了图C.4.3中所示的所有32位和64位整数运算，比较，转换和逻辑PTX指令。 The ﬂoating-point add and mul operations employ IEEE round-to-nearest-even as the default rounding mode. Te mad.f32 ﬂoating-point multiply-add operation performs a multiplication with truncation, followed by an addition with roundto-nearest-even. The SP ﬂushes input denormal operands to sign-preserved-zero. Results that underﬂow the target output exponent range are ﬂushed to signpreserved-zero after rounding.浮点加法和mul运算采用IEEE舍入到最近 - 甚至作为默认舍入模式。 Te mad.f32浮点乘法加法运算执行与截断的乘法运算，然后使用roundto-nearest-even进行加法运算。 SP将输入非正规操作数用于符号保留为零。 在舍入之后，将目标输出指数范围下的结果浮动到符号保留为零 Special Function Unit (SFU) 特殊功能单元（SFU）Certain thread instructions can execute on the SFUs, concurrently with other thread instructions executing on the SPs. The SFU implements the special function instructions of Figure C.4.3, which compute 32-bit ﬂoating-point approximations to reciprocal, reciprocal square root, and key transcendental functions. It also implements 32-bit ﬂoating-point planar attribute interpolation for pixel shaders, providing accurate interpolation of attributes such as color, depth, and texture coordinates.某些线程指令可以在SFU上执行，与在SP上执行的其他线程指令同时执行。 SFU实现了图C.4.3中的特殊函数指令，它们计算倒数，倒数平方根和关键超越函数的32位浮点近似。 它还为像素着色器实现了32位浮点平面属性插值，提供了颜色，深度和纹理坐标等属性的精确插值。 Each pipelined SFU generates one 32-bit ﬂoating-point special function result per cycle; the two SFUs per multiprocessor execute special function instructions at a quarter the simple instruction rate of the eight SPs. The SFUs also execute the mul.f32 multiply instruction concurrently with the eight SPs, increasing the peakcomputation rate up to 50% for threads with a suitable instruction mixture.每个流水线SFU在每个周期产生一个32位浮点特殊功能结果; 每个多处理器的两个SFU以八个SP的简单指令速率的四分之一执行特殊功能指令。 SFU还与8个SP同时执行mul.f32乘法指令，对于具有合适指令混合的线程，峰值计算速率提高了50％。 For functional evaluation, the Tesla architecture SFU employs quadratic interpolation based on enhanced minimax approximations for approximating the reciprocal, reciprocal square-root, log2x, 2x, and sin/cos functions. Te accuracy of the function estimates ranges from 22 to 24 mantissa bits. See Section C.6 for more details on SFU arithmetic.对于功能评估，特斯拉架构SFU采用基于增强的极小极大近似的二次插值来近似倒数，倒数平方根，log2x，2x和正弦/余弦函数。 功能估计的准确度范围从22到24个尾数位。 有关SFU算法的更多详细信息，请参见第C.6节。 Comparing with Other Multiprocessors 与其他多处理器比较Compared with SIMD vector architectures such as x86 SSE, the SIMT multiprocessor can execute individual threads independently, rather than always executing them together in synchronous groups. SIMT hardware fnds data parallelism among independent threads, whereas SIMD hardware requires the sofware to express data parallelism explicitly in each vector instruction. A SIMT machine executes a warp of 32 threads synchronously when the threads take the same execution path, yet can execute each thread independently when they diverge. Te advantage is signifcant because SIMT programs and instructions simply describe the behavior of a single independent thread, rather than a SIMD data vector of four or more data lanes. Yet the SIMT multiprocessor has SIMD-like efciency, spreading the area and cost of one instruction unit across the 32 threads of a warp and across the eight streaming processor cores. SIMT provides the performance of SIMD together with the productivity of multithreading, avoiding the need to explicitly code SIMD vectors for edge conditions and partial divergence.与SIM86矢量体系结构（如x86 SSE）相比，SIMT多处理器可以独立执行各个线程，而不是始终在同步组中一起执行它们。 SIMT硬件支持独立线程之间的数据并行性，而SIMD硬件要求软件在每个向量指令中明确表达数据并行性。当线程采用相同的执行路径时，SIMT机器同步执行32个线程的warp，但是当它们发散时可以独立地执行每个线程。优点是显着的，因为SIMT程序和指令简单地描述了单个独立线程的行为，而不是四个或更多数据通道的SIMD数据向量。然而，SIMT多处理器具有类似SIMD的效率，在一个扭曲的32个线程和八个流处理器内核之间扩展了一个指令单元的面积和成本。 SIMT提供SIMD的性能以及多线程的生产率，无需为边缘条件和部分发散明确编码SIMD向量。 The SIMT multiprocessor imposes little overhead because it is hardware multithreaded with hardware barrier synchronization. That allows graphics shaders and CUDA threads to express very fne-grained parallelism. Graphics and CUDA programs use threads to express fne-grained data parallelism in a perthread program, rather than forcing the programmer to express it as SIMD vector instructions. It is simpler and more productive to develop scalar single-thread code than vector code, and the SIMT multiprocessor executes the code with SIMD-like effciency.SIMT多处理器的开销很小，因为它是具有硬件屏障同步的硬件多线程。 这允许图形着色器和CUDA线程表达非常细致的并行性。 图形和CUDA程序使用线程在perthread程序中表达细粒度数据并行性，而不是强迫程序员将其表达为SIMD向量指令。 开发标量单线程代码比矢量代码更简单，更高效，而SIMT多处理器以类似SIMD的效率执行代码。 Coupling eight streaming processor cores together closely into a multiprocessor and then implementing a scalable number of such multiprocessors makes a twolevel multiprocessor composed of multiprocessors. The CUDA programming model exploits the two-level hierarchy by providing individual threads for fne-grained parallel computations, and by providing grids of thread blocks for coarse-grained parallel operations. The same thread program can provide both fine-grained and coarse-grained operations. In contrast, CPUs with SIMD vector instructions must use two diﬀerent programming models to provide fne-grained and coarse-grained operations: coarse-grained parallel threads on different cores, and SIMD vector instructions for fne-grained data parallelism.将八个流处理器核心紧密地耦合到多处理器中，然后实现可扩展数量的这种多处理器，使得由多处理器组成的两级多处理器成为可能。 CUDA编程模型通过为细粒度并行计算提供单独的线程，并通过为粗粒度并行操作提供线程块网格来利用两级层次结构。 相同的线程程序可以提供细粒度和粗粒度操作。 相反，具有SIMD向量指令的CPU必须使用两种不同的编程模型来提供细粒度和粗粒度操作：不同内核上的粗粒度并行线程，以及用于细粒度数据并行性的SIMD向量指令。 Multithreaded Multiprocessor Conclusion 多线程多处理器结论The example GPU multiprocessor based on the Tesla architecture is highly multithreaded, executing a total of up to 512 lightweight threads concurrently to support fne-grained pixel shaders and CUDA threads. It uses a variation on SIMD architecture and multithreading called SIMT (single-instruction multiple-thread) to effciently broadcast one instruction to a warp of 32 parallel threads, while permitting each thread to branch and execute independently. Each thread executes its instruction stream on one of the eight streaming processor (SP) cores, which are multithreaded up to 64 threads.基于Tesla架构的示例GPU多处理器是高度多线程的，同时执行总共多达512个轻量级线程，以支持细粒度像素着色器和CUDA线程。 它使用SIMD架构的变体和称为SIMT（单指令多线程）的多线程来有效地将一条指令广播到32个并行线程的warp，同时允许每个线程独立地分支和执行。 每个线程在八个流处理器（SP）内核之一上执行其指令流，这些内核是多线程的，最多64个线程。 The PTX ISA is a register-based load/store scalar ISA that describes the execution of a single thread. Because PTX instructions are optimized and translated to binary microinstructions for a specifc GPU, the hardware instructions can evolve rapidly without disrupting compilers and sofware tools that generate PTX instructions.PTX ISA是一个基于寄存器的加载/存储标量ISA，用于描述单个线程的执行。 由于PTX指令经过优化并转换为特定GPU的二进制微指令，因此硬件指令可以快速发展，而不会中断生成PTX指令的编译器和软件工具]]></content>
      <categories>
        <category>GPU相关</category>
      </categories>
      <tags>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3_Programming_GPUs]]></title>
    <url>%2F2019%2F01%2F24%2FProgramming_GPUs%2F</url>
    <content type="text"><![CDATA[Programming multiprocessor GPUs is qualitatively different than programming other multiprocessors like multicore CPUs. GPUs provide two to three orders of magnitude more thread and data parallelism than CPUs, scaling to hundreds of processor cores and tens of thousands of concurrent threads. GPUs continue to increase their parallelism, doubling it about every 12 to 18 months, enabled by Moore’s law [1965] of increasing integrated circuit density and by improving architectural efciency. To span the wide price and performance range of different market segments, different GPU products implement widely varying numbers of processors and threads. Yet users expect games, graphics, imaging, and computing applications to work on any GPU, regardless of how many parallel threads it executes or how many parallel processor cores it has, and they expect more expensive GPUs (with more threads and cores) to run applications faster. As a result, GPU programming models and application programs are designed to scale transparently to a wide range of parallelism.编程多处理器GPU与编程其他多处理器（如多核CPU）的质量不同。 GPU比CPU提供两到三个数量级的线程和数据并行性，可扩展到数百个处理器内核和数万个并发线程。随着集成电路密度的提高和提高架构效率的摩尔定律[1965]，GPU每12到18个月就会继续增加并行性，并且会增加一倍。为了跨越不同细分市场的广泛价格和性能范围，不同的GPU产品实现了大量不同数量的处理器和线程。然而，用户期望游戏，图形，成像和计算应用程序可以在任何GPU上运行，无论它执行多少并行线程或它有多少并行处理器核心，他们期望更多昂贵的GPU（具有更多线程和核心）可以更快地运行应用程序。因此，GPU编程模型和应用程序旨在透明地扩展到各种并行性。 The driving force behind the large number of parallel threads and cores in a GPU is real-time graphics performance—the need to render complex 3D scenes with high resolution at interactive frame rates, at least 60 frames per second. Correspondingly, the scalable programming models of graphics shading languages such as Cg (C for graphics) and HLSL (high-level shading language) are designed to exploit large degrees of parallelism via many independent parallel threads and to scale to any number of processor cores. The CUDA scalable parallel programming model similarly enables general parallel computing applications to leverage large numbers of parallel threads and scale to any number of parallel processor cores, transparently to the application.GPU中大量并行线程和核心背后的驱动力是实时图形性能 - 需要以交互式帧速率（至少每秒60帧）渲染具有高分辨率的复杂3D场景。 相应地，图形着色语言（如Cg（图形用C）和HLSL（高级着色语言））的可伸缩编程模型旨在通过许多独立的并行线程利用大程度的并行性，并扩展到任意数量的处理器内核。 CUDA可扩展并行编程模型同样使通用并行计算应用程序能够利用大量并行线程，并扩展到任意数量的并行处理器内核，对应用程序透明。 In these scalable programming models, the programmer writes code for a single thread, and the GPU runs myriad thread instances in parallel. Programs thus scale transparently over a wide range of hardware parallelism. Tis simple paradigm arose from graphics APIs and shading languages that describe how to shade one vertex or one pixel. It has remained an effective paradigm as GPUs have rapidly increased their parallelism and performance since the late 1990s.在这些可伸缩的编程模型中，程序员为单个线程编写代码，GPU并行运行无数的线程实例。 因此，程序在广泛的硬件并行性上透明地扩展。 这是一种简单的范例，它来自描述如何遮蔽一个顶点或一个像素的图形API和着色语言。 自从20世纪90年代末以来，GPU一直在迅速提高其并行性和性能，这仍然是一种有效的范例。This section brieﬂy describes programming GPUs for real-time graphics applications using graphics APIs and programming languages. It then describes programming GPUs for visual computing and general parallel computing applications using the C language and the CUDA programming model.本节简要介绍如何使用图形API和编程语言为实时图形应用程序编程GPU。 然后，它描述了使用C语言和CUDA编程模型编程用于可视计算和通用并行计算应用程序的GPU。 Programming Real-Time Graphics 实时图形编程APIs have played an important role in the rapid, successful development of GPUs and processors. There are two primary standard graphics APIs: OpenGL and Direct3D, one of the Microsoft DirectX multimedia programming interfaces. OpenGL, an open standard, was originally proposed and defined by Silicon Graphics Incorporated. Te ongoing development and extension of the OpenGL standard [Segal and Akeley, 2006], [Kessenich, 2006] is managed by Khronos, an industry consortium. Direct3D [Blythe, 2006], a de facto standard, is definedand evolved forward by Microsoft and partners. OpenGL and Direct3D are similarly structured, and continue to evolve rapidly with GPU hardware advances. They defne a logical graphics processing pipeline that is mapped onto the GPU hardware and processors, along with programming models and languages for the programmable pipeline stages.API在GPU和处理器的快速而成功的发展中发挥了重要作用。 现在有两个主要的标准图形API：OpenGL 和 Direct3D。 Direct3D是微软 DirectX 多媒体编程接口之一。 OpenGL是一种开放标准，最初是由Silicon Graphics Incorporated提出并定义的。 OpenGL标准的持续发展和扩展[Segal和Akeley，2006]，[Kessenich，2006]由行业协会Khronos管理。 Direct3D [Blythe，2006]是事实上的标准，由微软和合作伙伴定义和发展。 OpenGL和Direct3D结构相似，并且随着GPU硬件的发展而不断发展。 它们定义了映射到GPU硬件和处理器的逻辑图形处理流水线，以及可编程流水线级的编程模型和语言。 OpenGL :An open standard graphics API. Direct3D A graphics API defined by Microsoft and partners. 一个开放标准的图形API。 Direct3D: A graphics API defined by Microsof and partners. 由Microsoft和合作伙伴定义的图形API。 译注：DirectX中 Direct3D接口负责3D效果显示，DirectDraw负责2D图像加速 Logical Graphics Pipeline 逻辑图形管道Figure C.3.1 illustrates the Direct3D 10 logical graphics pipeline. OpenGL has a similar graphics pipeline structure. The API and logical pipeline provide a streaming dataﬂow infrastructure and plumbing for the programmable shader stages, shown in blue. The 3D application sends the GPU a sequence of vertices grouped into geometric primitives—points, lines, triangles, and polygons. The input assembler collects vertices and primitives. The vertex shader program executes per-vertex processing including transforming the vertex 3D position into a screen position and lighting the vertex to determine its color. The geometry shader program executes per-primitive processing and can add or drop primitives. The setup and rasterizer unit generates pixel fragments (fragments are potential contributions to pixels) that are covered by a geometric primitive. The pixel shader program performs per-fragment processing, including interpolating per-fragment parameters, texturing, and coloring. Pixel shaders make extensive use of sampled and filtered lookups into large 1D, 2D, or 3D arrays called textures, using interpolated ﬂoating-point coordinates. Shaders use texture accesses for maps, functions, decals, images, and data. The raster operations processing (or output merger) stage performs Z-buffer depth testing and stencil testing, which may discard a hidden pixel fragment or replace the pixel’s depth with the fragment’s depth, and performs a color blending operation that combines the fragment color with the pixel color and writes the pixel with the blended color.图C.3.1说明了Direct3D 10的逻辑图形管道。 OpenGL具有类似的图形管道结构。 API和逻辑管道为可编程着色器阶段提供流数据流基础结构和管道，以蓝色显示。 3D应用程序向GPU发送一系列顶点，这些顶点被分组为几何图元 - 点，线，三角形和多边形。输入汇编程序收集顶点和基元。顶点着色器程序执行每顶点处理，包括将顶点3D位置变换为屏幕位置并点亮顶点以确定其颜色。几何着色器程序执行每个基元处理，并可以添加或删除基元。设置和光栅化器单元生成由几何图元覆盖的像素片段（片段是对像素的潜在贡献）。像素着色器程序执行每片段处理，包括内插每片段参数，纹理和着色。像素着色器使用插值的浮点坐标，将采样和滤波查找广泛用于称为纹理的大型1D，2D或3D阵列。着色器使用纹理访问地图，函数，贴花，图像和数据。光栅操作处理（或输出合并）阶段执行Z缓冲深度测试和模板测试，它可以丢弃隐藏的像素片段或用片段的深度替换像素的深度，执行将片段颜色与像素颜色组合在一起的混合操作，并将混合的颜色写入像素。 The graphics API and graphics pipeline provide input, output, memory objects, and infrastructure for the shader programs that process each vertex, primitive, and pixel fragment.图形API和图形管道为处理每个顶点，基元和像素片段的着色器程序提供输入，输出，存储器对象和基础结构。 texture: A 1D, 2D, or 3D array that supports sampled and filtered lookups with interpolated coordinates. 支持带插值坐标的采样和滤波查找的1D，2D或3D阵列。 Graphics Shader Programs 图形着色器程序Real-time graphics applications use many diﬀerent shader programs to model how light interacts with diﬀerent materials and to render complex lighting and shadows. Shading languages are based on a dataﬂow or streaming programming model that corresponds with the logical graphics pipeline. Vertex shader programs map the position of triangle vertices onto the screen, altering their position, color, or orientation. Typically a vertex shader thread inputs a ﬂoating-point (x, y, z, w) vertex position and computes a ﬂoating-point (x, y, z) screen position. Geometry shader programs operate on geometric primitives (such as lines and triangles) defined by multiple vertices, changing them or generating additional primitives. Pixel fragment shaders each “shade” one pixel, computing a ﬂoating-point red, green, blue, alpha (RGBA) color contribution to the rendered image at its pixel sample (x, y) image position. Shaders (and GPUs) use ﬂoating-point arithmetic for all pixel color calculations to eliminate visible artifacts while computing the extreme range of pixel contribution values encountered while rendering scenes with complex lighting, shadows, and high dynamic range. For all three types of graphics shaders, many program instances can be run in parallel, as independent parallel threads, because each works on independent data, produces independent results, and has no side effects. Independent vertices, primitives, and pixels further enable the same graphics program to run on diﬀerently sized GPUs that process different numbers of vertices, primitives, and pixels in parallel. Graphics programs thus scale transparently to GPUs with different amounts of parallelism and performance. shader: A program that operates on graphics data such as a vertex or a pixel fragment. 一种对图形数据（如顶点或像素片段）进行操作的程序。 shading language: A graphics rendering language, usually having a dataﬂow or streaming programming model.一种图形渲染语言，通常具有数据流或流编程模型。 Users program all three logical graphics threads with a common targeted highlevel language. HLSL (high-level shading language) and Cg (C for graphics) are commonly used. They have C-like syntax and a rich set of library functions for matrix operations, trigonometry, interpolation, and texture access and filtering, but are far from general computing languages: they currently lack general memory access, pointers, fle I/O, and recursion. HLSL and Cg assume that programs live within a logical graphics pipeline, and thus I/O is implicit. For example, a pixel fragment shader may expect the geometric normal and multiple texture coordinates to have been interpolated from vertex values by upstream fxed-function stages and can simply assign a value to the COLOR output parameter to pass it downstream to be blended with a pixel at an implied (x, y) position.用户使用共同的目标高级语言对所有三个逻辑图形线程进行编程。 通常使用HLSL（高级着色语言）和Cg（图形用C）。 它们具有类似C语法和丰富的库函数，用于矩阵运算，三角函数，插值和纹理访问和过滤，但远不是通用计算语言：它们目前缺少通用内存访问，指针，文件I / O和递归。 HLSL和Cg假设程序存在于逻辑图形管道中，因此I / O是隐含的。 例如，像素片段着色器可以预期几何法线和多个纹理坐标已经通过上游固定功能阶段从顶点值插值，并且可以简单地将值分配给COLOR输出参数以将其传递到下游以与像素混合。 在隐含的（x，y）位置。The GPU hardware creates a new independent thread to execute a vertex, geometry, or pixel shader program for every vertex, every primitive, and every pixel fragment. In video games, the bulk of threads execute pixel shader programs, as there are typically 10 to 20 times or more pixel fragments than vertices, and complex lighting and shadows require even larger ratios of pixel to vertex shader threads. The graphics shader programming model drove the GPU architecture to effciently execute thousands of independent fne-grained threads on many parallel processor cores.GPU硬件创建一个新的独立线程，为每个顶点，每个基元和每个像素片段执行顶点，几何或像素着色器程序。 在视频游戏中，大部分线程执行像素着色器程序，因为通常存在比顶点多10到20倍或更多的像素片段，并且复杂的光照和阴影需要甚至更大比例的像素到顶点着色器线程。 图形着色器编程模型推动GPU架构在许多并行处理器内核上有效地执行数千个独立的细粒度线程。 Pixel Shader ExampleConsider the following Cg pixel shader program that implements the “environment mapping” rendering technique. For each pixel thread, this shader is passed five parameters, including 2D ﬂoating-point texture image coordinates needed to sample the surface color, and a 3D ﬂoating-point vector giving the refection of the view direction off the surface. The other three “uniform” parameters do not vary from one pixel instance (thread) to the next. The shader looks up color in two texture images: a 2D texture access for the surface color, and a 3D texture access into a cube map (six images corresponding to the faces of a cube) to obtain the external world color corresponding to the refection direction. Then the final four-component (red, green, blue, alpha) ﬂoating-point color is computed using a weighted average called a “lerp” or linear interpolation function.考虑以下Cg像素着色器程序，该程序实现“环境映射”渲染技术。 对于每个像素线程，该着色器传递五个参数，包括采样表面颜色所需的2D浮点纹理图像坐标，以及3D浮点矢量，从而使视图方向偏离表面。 其他三个“统一”参数不会从一个像素实例（线程）到下一个像素实例。 着色器在两个纹理图像中查找颜色：表面颜色的2D纹理访问，以及立方体贴图中的3D纹理访问（对应于立方体的面的六个图像），以获得与反射方向对应的外部世界颜色。 然后使用称为“lerp”或线性插值函数的加权平均来计算最终的四分量（红色，绿色，蓝色，α）浮点颜色。123456789101112131415void refection(float2 texCoord : TEXCOORD0,float3 refection_dir : TEXCOORD1,out float4 color : COLOR,uniform float shiny,uniform sampler2D surfaceMap,uniform samplerCUBE envMap)&#123;// Fetch the surface color from a texturefloat4 surfaceColor = tex2D(surfaceMap, texCoord);// Fetch reflected color by sampling a cube mapfloat4 reflectedColor = texCUBE(environmentMap, refection_dir);// Output is weighted average of the two colorscolor = lerp(surfaceColor, refectedColor, shiny);&#125; Although this shader program is only three lines long, it activates a lot of GPU hardware. For each texture fetch, the GPU texture subsystem makes multiple memory accesses to sample image colors in the vicinity of the sampling coordinates, and then interpolates the final result with ﬂoating-point fltering arithmetic. The multithreaded GPU executes thousands of these lightweight Cg pixel shader threads in parallel, deeply interleaving them to hide texture fetch and memory latency.虽然这个着色器程序只有三行，但它激活了很多GPU硬件。 对于每次纹理提取，GPU纹理子系统对采样坐标附近的采样图像颜色进行多次存储器访问，然后使用浮点运算算法对最终结果进行插值。 多线程GPU并行执行数千个这些轻量级Cg像素着色器线程，深度交错以隐藏纹理获取和内存延迟。Cg focuses the programmer’s view to a single vertex or primitive or pixel, which the GPU implements as a single thread; the shader program transparently scales to exploit thread parallelism on the available processors. Being applicationspecifc, Cg provides a rich set of useful data types, library functions, and language constructs to express diverse rendering techniques.Cg将程序员的视图聚焦到单个顶点或基元或像素，GPU将其实现为单个线程; 着色器程序透明地扩展以利用可用处理器上的线程并行性。 作为应用程序规范，Cg提供了丰富的有用数据类型，库函数和语言结构，以表达各种呈现技术。Figure C.3.2 shows skin rendered by a fragment pixel shader. Real skin appears quite different from ﬂesh-color paint because light bounces around a lot before re-emerging. In this complex shader, three separate skin layers, each with unique subsurface scattering behavior, are modeled to give the skin a visual depth and translucency. Scattering can be modeled by a blurring convolution in a fattened “texture” space, with red being blurred more than green, and blue blurred less. The compiled Cg shader executes 1400 instructions to compute the color of one skin pixel.图C.3.2显示了由片段像素着色器渲染的外观。 真正的皮肤看起来与粉红色涂料完全不同，因为在重新出现之前，光线会在很多地方反弹。 在这个复杂的着色器中，三个独立的皮肤层（每个都具有独特的次表面散射行为）被建模，以赋予皮肤视觉深度和半透明度。 散射可以通过在肥胖的“纹理”空间中的模糊卷积来建模，其中红色比绿色更模糊，而蓝色模糊得更少。 编译的Cg着色器执行1400条指令以计算一个皮肤像素的颜色。 As GPUs have evolved superior ﬂoating-point performance and very high streaming memory bandwidth for real-time graphics, they have attracted highly parallel applications beyond traditional graphics. At frst, access to this power was available only by couching an application as a graphics-rendering algorithm, but this GPGPU approach was ofen awkward and limiting. More recently, the CUDA programming model has provided a far easier way to exploit the scalable high-performance ﬂoating-point and memory bandwidth of GPUs with the C programming language.由于GPU已经为实时图形提供了出色的浮点性能和非常高的流存储器带宽，因此它们吸引了超越传统图形的高度并行应用。 首先，只有通过将应用程序作为图形渲染算法进行访问才能获得这种功能，但是这种GPGPU方法非常笨拙且有限。 最近，CUDA编程模型提供了一种更简单的方法，可以利用C编程语言利用GPU的可扩展高性能浮点和存储器带宽。 Programming Parallel Computing ApplicationsCUDA, Brook, and CAL are programming interfaces for GPUs that are focused on data parallel computation rather than on graphics. CAL (Compute Abstraction Layer) is a low-level assembler language interface for AMD GPUs. Brook is a streaming language adapted for GPUs by Buck et al. [2004]. CUDA, developed by NVIDIA [2007], is an extension to the C and C++ languages for scalable parallel programming of manycore GPUs and multicore CPUs. The CUDA programming model is described below, adapted from an article by Nickolls et al.[2008].CUDA，Brook和CAL是GPU的编程接口，专注于数据并行计算而非图形。 CAL（Compute Abstraction Layer）是AMD GPU的低级汇编语言接口。 Brook是一种适用于GPU等GPU的流媒体语言。[2004年]。 由NVIDIA [2007]开发的CUDA是C和C ++语言的扩展，用于多核GPU和多核CPU的可扩展并行编程。 下面描述了CUDA编程模型，改编自Nickolls等人[2008]的文章。 With the new model the GPU excels in data parallel and throughput computing, executing high performance computing applications as well as graphics applications.凭借新型号，GPU擅长数据并行和吞吐量计算，执行高性能计算应用程序以及图形应用程序。 Data Parallel Problem Decomposition 数据并行问题分解To map large computing problems effectively to a highly parallel processing architecture, the programmer or compiler decomposes the problem into many small problems that can be solved in parallel. For example, the programmer partitions a large result data array into blocks and further partitions each block into elements, such that the result blocks can be computed independently in parallel, and the elements within each block are computed in parallel. Figure C.3.3 shows a decomposition of a result data array into a 3 x 2 grid of blocks, where each block is further decomposed into a 5 x 3 array of elements. Te two-level parallel decomposition maps naturally to the GPU architecture: parallel multiprocessors compute result blocks, and parallel threads compute result elements.为了将大型计算问题有效地映射到高度并行的处理架构，程序员或编译器将问题分解为许多可以并行解决的小问题。 例如，程序员将大结果数据阵列分成块并进一步将每个块分成元素，使得结果块可以独立地并行计算，并且每个块内的元素是并行计算的。 图C.3.3显示了将结果数据阵列分解为3×2的块网格，其中每个块进一步分解为5×3的元素阵列。 两级并行分解自然地映射到GPU架构：并行多处理器计算结果块，并行线程计算结果元素。 The programmer writes a program that computes a sequence of result data grids, partitioning each result grid into coarse-grained result blocks that can be computed independently in parallel. The program computes each result block withan array of fine-grained parallel threads, partitioning the work among threads so that each computes one or more result elements.程序员编写一个程序来计算结果数据网格序列，将每个结果网格划分为可以并行独立计算的粗粒度结果块。 程序使用细粒度并行线程数组计算每个结果块，在线程之间对工作进行分区，以便每个都计算一个或多个结果元素。 Scalable Parallel Programming with CUDA 使用CUDA进行可扩展的并行编程The CUDA scalable parallel programming model extends the C and C++ languages to exploit large degrees of parallelism for general applications on highly parallel multiprocessors, particularly GPUs. Early experience with CUDA shows that many sophisticated programs can be readily expressed with a few easily understood abstractions. Since NVIDIA released CUDA in 2007, developers have rapidly developed scalable parallel programs for a wide range of applications, including seismic data processing, computational chemistry, linear algebra, sparse matrix solvers, sorting, searching, physics models, and visual computing. These applications scale transparently to hundreds of processor cores and thousands of concurrent threads. NVIDIA GPUs with the Tesla unifed graphics and computing architecture (described in Sections C.4 and C.7) run CUDA C programs, and are widely available in laptops, PCs, workstations, and servers. The CUDA model is also applicable to other shared memory parallel processing architectures, including multicore CPUs.CUDA可扩展并行编程模型扩展了C和C ++语言，以便在高度并行的多处理器（尤其是GPU）上为一般应用程序利用大程度的并行性。早期使用CUDA的经验表明，许多复杂的程序可以通过一些易于理解的抽象来表达。自NVIDIA于2007年发布CUDA以来，开发人员已迅速开发出可扩展的并行程序，适用于各种应用，包括地震数据处理，计算化学，线性代数，稀疏矩阵求解器，排序，搜索，物理模型和视觉计算。这些应用程序透明地扩展到数百个处理器核心和数千个并发线程。采用Tesla统一图形和计算架构的NVIDIA GPU（在C.4和C.7节中描述）运行CUDA C程序，并广泛用于笔记本电脑，PC，工作站和服务器。 CUDA模型也适用于其他共享内存并行处理体系结构，包括多核CPU。CUDA provides three key abstractions-a hierarchy of thread groups, shared memories, and barrier synchronization—that provide a clear parallel structure to conventional C code for one thread of the hierarchy. Multiple levels of threads, memory, and synchronization provide fine-grained data parallelism and thread parallelism, nested within coarse-grained data parallelism and task parallelism. The abstractions guide the programmer to partition the problem into coarse subproblems that can be solved independently in parallel, and then into fner pieces that can be solved in parallel. The programming model scales transparently to large numbers of processor cores: a compiled CUDA program executes on any number of processors, and only the runtime system needs to know the physical processor count.CUDA提供三个关键的抽象 - 线程组，共享存储器和屏障同步的层次结构 - 为层次结构的一个线程提供与传统C代码的清晰并行结构。 多级线程，内存和同步提供细粒度数据并行和线程并行，嵌套在粗粒度数据并行和任务并行中。 抽象指导程序员将问题划分为粗略的子问题，这些子问题可以并行独立解决，然后分成可以并行求解的更多部分。 编程模型透明地扩展到大量处理器内核：编译的CUDA程序在任意数量的处理器上执行，只有运行时系统需要知道物理处理器数量。 The CUDA Paradigm CUDA范式CUDA is a minimal extension of the C and C++ programming languages. The programmer writes a serial program that calls parallel kernels, which may be simple functions or full programs. A kernel executes in parallel across a set of parallel threads. The programmer organizes these threads into a hierarchy of thread blocks and grids of thread blocks. A thread block is a set of concurrent threads that can cooperate among themselves through barrier synchronization and through shared access to a memory space private to the block. A grid is a set of thread blocks that may each be executed independently and thus may execute in parallel.CUDA是C和C ++编程语言的最小扩展。 程序员编写一个调用并行内核的串行程序，可以是简单的函数或完整的程序。 内核跨一组并行线程并行执行。 程序员将这些线程组织成线程块和线程块网格的层次结构。 线程块是一组并发线程，它们可以通过屏障同步和通过对块专用的内存空间的共享访问来相互协作。 网格是一组线程块，每个线程块可以独立执行，因此可以并行执行。 kernel: A program or function for one thread, designed to be executed by many threads.一个程序或函数，用于一个线程，旨在由许多线程执行。 thread block: A set of concurrent threads that execute the same thread program and may cooperate to compute a result.一组并发线程，它们执行相同的线程程序并可以协作计算结果。 grid: A set of thread blocks that execute the same kernel program 一组执行相同内核程序的线程块 When invoking a kernel, the programmer specifes the number of threads per block and the number of blocks comprising the grid. Each thread is given a unique thread ID number threadIdx within its thread block, numbered 0, 1, 2, …, blockDim-1, and each thread block is given a unique block ID number blockIdx within its grid. CUDA supports thread blocks containing up to 512 threads. For convenience, thread blocks and grids may have 1, 2, or 3 dimensions, accessed via .x, .y, and .z index fields.在调用内核时，程序员指定每个块的线程数和构成网格的块数。 每个线程在其线程块内被赋予唯一的线程ID号threadIdx，编号为0,1,2，…，blockDim-1，并且每个线程块在其网格内被赋予唯一的块ID号blockIdx。 CUDA支持包含多达512个线程的线程块。 为方便起见，线程块和网格可以有1,2或3个维度，可通过.x，.y和.z索引字段访问。 As a very simple example of parallel programming, suppose that we are given two vectors x and y of n ﬂoating-point numbers each and that we wish to compute the result of y = ax + y for some scalar value a. This is the so-called SAXPY kernel defined by the BLAS linear algebra library. Figure C.3.4 shows C code for performing this computation on both a serial processor and in parallel using CUDA.作为并行编程的一个非常简单的例子，假设我们给出了两个向量x和y的n个浮点数，并且我们希望计算某些标量值a的y = ax + y的结果。 这是由BLAS线性代数库定义的所谓的SAXPY内核。 图C.3.4显示了使用CUDA在串行处理器和并行上执行此计算的C代码。 The __global__ declaration specifer indicates that the procedure is a kernelentry point. CUDA programs launch parallel kernels with the extended functioncall syntax:__global__声明说明符表明该过程是一个内核入口点。 CUDA程序使用扩展功能启动并行内核调用语法： 1kernel&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;(... parameter list ...); where dimGrid and dimBlock are three-element vectors of type dim3 that specify the dimensions of the grid in blocks and the dimensions of the blocks in threads, respectively. Unspecifed dimensions default to one.其中dimGrid和dimBlock是dim3类型的三元素向量，分别指定块中网格的尺寸和线程中块的尺寸。 未指定的维度默认为1。 In Figure C.3.4, we launch a grid of n threads that assigns one thread to each element of the vectors and puts 256 threads in each block. Each individual thread computes an element index from its thread and block IDs and then performs the desired calculation on the corresponding vector elements. Comparing the serial and parallel versions of this code, we see that they are strikingly similar. This represents a fairly common pattern. Te serial code consists of a loop where each iteration is independent of all the others. Such loops can be mechanically transformed into parallel kernels: each loop iteration becomes an independent thread. By assigning a single thread to each output element, we avoid the need for any synchronization among threads when writing results to memory.在图C.3.4中，我们启动了一个包含n个线程的网格，它为一个向量的每个元素分配一个线程，并在每个块中放入256个线程。每个单独的线程从其线程和块ID计算元素索引，然后对相应的向量元素执行所需的计算。比较此代码的串行和并行版本，我们发现它们非常相似。这代表了一种相当普遍的模式。 Te序列代码由一个循环组成，其中每个迭代独立于所有其他迭代。这样的循环可以机械地转换为并行内核：每个循环迭代成为一个独立的线程。通过为每个输出元素分配单个线程，我们避免了在将结果写入内存时线程之间的任何同步。 The text of a CUDA kernel is simply a C function for one sequential thread. Thus, it is generally straightforward to write and is typically simpler than writing parallel code for vector operations. Parallelism is determined clearly and explicitly by specifying the dimensions of a grid and its thread blocks when launching a kernel. CUDA内核的文本只是一个顺序线程的C函数。因此，编写通常很简单，并且通常比为向量操作编写并行代码更简单。通过在启动内核时指定网格及其线程块的尺寸，可以清楚明确地确定并行性。 Parallel execution and thread management is automatic. All thread creation, scheduling, and termination is handled for the programmer by the underlying system. Indeed, a Tesla architecture GPU performs all thread management directly in hardware. The threads of a block execute concurrently and may synchronize at a synchronization barrier by calling the __syncthreads() intrinsic. This guarantees that no thread in the block can proceed until all threads in the block have reached the barrier. Afer passing the barrier, these threads are also guaranteed to see all writes to memory performed by threads in the block before the barrier. Thus, threads in a block may communicate with each other by writing and reading per-block shared memory at a synchronization barrier.并行执行和线程管理是自动的。 所有线程创建，调度和终止都由底层系统为程序员处理。 实际上，Tesla架构GPU直接在硬件中执行所有线程管理。 块的线程并发执行，并且可以通过调用__syncthreads（）内在函数在同步屏障上同步。 这保证了块中的所有线程都到达屏障之前块中的任何线程都不能继续。 在通过屏障后，这些线程也可以保证在屏障之前看到块中线程执行的所有内存写入。因此，块中的线程可以通过在同步屏障处写入和读取每块共享存储器来彼此通信。 synchronization barrier: Threads wait at a synchronization barrier until all threads in the thread block arrive at the barrier. 线程在同步障碍处等待，直到线程块中的所有线程到达屏障。 Since threads in a block may share memory and synchronize via barriers, they will reside together on the same physical processor or multiprocessor. The number of thread blocks can, however, greatly exceed the number of processors. The CUDA thread programming model virtualizes the processors and gives the programmer the ﬂexibility to parallelize at whatever granularity is most convenient. Virtualization into threads and thread blocks allows intuitive problem decompositions, as the number of blocks can be dictated by the size of the data being processed rather than by the number of processors in the system. It also allows the same CUDA program to scale to widely varying numbers of processor cores.由于块中的线程可以共享内存并通过障碍进行同步，因此它们将一起驻留在同一物理处理器或多处理器上。 但是，线程块的数量可以大大超过处理器的数量。 CUDA线程编程模型虚拟化处理器，并使程序员能够灵活地以最方便的粒度进行并行化。 虚拟化到线程和线程块允许直观的问题分解，因为块的数量可以由正在处理的数据的大小而不是由系统中的处理器的数量决定。 它还允许相同的CUDA程序扩展到各种数量的处理器内核。 To manage this processing element virtualization and provide scalability, CUDA requires that thread blocks be able to execute independently. It must be possible to execute blocks in any order, in parallel or in series. Different blocks have no means of direct communication, although they may coordinate their activities using atomic memory operations on the global memory visible to all threads—by atomically incrementing queue pointers, for example. This independence requirement allows thread blocks to be scheduled in any order across any number of cores, making the CUDA model scalable across an arbitrary number of cores as well as across a variety of parallel architectures. It also helps to avoid the possibility of deadlock. An application may execute multiple grids either independently or dependently. Independent grids may execute concurrently, given sufcient hardware resources. Dependent grids execute sequentially, with an implicit interkernel barrier between them, thus guaranteeing that all blocks of the first grid complete before any block of the second, dependent grid begins.为了管理此处理元素虚拟化并提供可伸缩性，CUDA要求线程块能够独立执行。必须能够以任何顺序，并行或串行执行块。不同的块没有直接通信的手段，尽管它们可以使用原子内存操作在所有线程可见的全局内存上协调它们的活动 - 例如通过原子递增的队列指针。这种独立性要求允许在任意数量的内核上以任何顺序调度线程块，使CUDA模型可以跨任意数量的内核以及各种并行体系结构进行扩展。它还有助于避免死锁的可能性。应用程序可以独立地或依赖地执行多个网格。在给定足够的硬件资源的情况下，独立网格可以同时执行。依赖网格顺序执行，它们之间具有隐式内核屏障，从而保证第一网格的所有块在第二依赖网格的任何块开始之前完成。 atomic memory operation: A memory read, modify, write operation sequence that completes without any intervening access.内存读取，修改，写入操作序列，无需任何中间访问即可完成。 Threads may access data from multiple memory spaces during their execution. Each thread has a private local memory. CUDA uses local memory for threadprivate variables that do not ft in the thread’s registers, as well as for stack frames and register spilling. Each thread block has a shared memory, visible to all threads of the block, which has the same lifetime as the block. Finally, all threads have access to the same global memory. Programs declare variables in shared and global memory with the shared and device type qualifers. On a Tesla architecture GPU, these memory spaces correspond to physically separate memories: per-block shared memory is a low-latency on-chip RAM, while global memory resides in the fast DRAM on the graphics board.线程可以在执行期间从多个存储空间访问数据。 每个线程都有一个私有本地内存。 CUDA将本地内存用于线程私有变量，这些变量不在线程寄存器中，也不用于堆栈帧和寄存器溢出。 每个线程块都有一个共享内存，对块的所有线程都是可见的，它与块的生命周期相同。 最后，所有线程都可以访问相同的全局内存。 程序使用shared和device类型的限定符在共享和全局内存中声明变量。 在Tesla架构GPU上，这些存储空间对应于物理上独立的存储器：每块共享存储器是低延迟片上RAM，而全局存储器驻留在图形板上的快速DRAM中。 local memory: Per-thread local memory private to the thread. 每线程本地内存对线程是私有的。shared memory: Per-block memory shared by all threads of the block. 块的所有线程共享的每块内存。global memory: Per-application memory shared by all threads. 所有线程共享的每个应用程序内存。 Shared memory is expected to be a low-latency memory near each processor, much like an L1 cache. It can therefore provide high-performance communication and data sharing among the threads of a thread block. Since it has the same lifetime as its corresponding thread block, kernel code will typically initialize data in shared variables, compute using shared variables, and copy shared memory results to global memory. Thread blocks of sequentially dependent grids communicate via global memory, using it to read input and write results.共享内存预计是每个处理器附近的低延迟内存，很像L1缓存。 因此，它可以在线程块的线程之间提供高性能通信和数据共享。 由于它与相应的线程块具有相同的生命周期，因此内核代码通常会初始化共享变量中的数据，使用共享变量进行计算，并将共享内存结果复制到全局内存中。 顺序相关网格的线程块通过全局存储器进行通信，使用它来读取输入和写入结果。Figure C.3.5 shows diagrams of the nested levels of threads, thread blocks, and grids of thread blocks. It further shows the corresponding levels of memory sharing: local, shared, and global memories for per-thread, per-thread-block, and per-application data sharing.图C.3.5显示了线程块的线程，线程块和网格的嵌套级别的图表。 它进一步显示了相应的内存共享级别：每个线程，每个线程块和每个应用程序数据共享的本地，共享和全局内存。 A program manages the global memory space visible to kernels through calls to the CUDA runtime, such as cudaMalloc() and cudaFree(). Kernels may execute on a physically separate device, as is the case when running kernels on the GPU. Consequently, the application must use cudaMemcpy() to copy data between the allocated space and the host system memory.程序通过调用CUDA运行时（例如cudaMalloc（）和cudaFree（））来管理内核可见的全局内存空间。 内核可以在物理上独立的设备上执行，就像在GPU上运行内核一样。 因此，应用程序必须使用cudaMemcpy（）在分配的空间和主机系统内存之间复制数据。 The CUDA programming model is similar in style to the familiar singleprogram multiple data (SPMD) model—it expresses parallelism explicitly, and each kernel executes on a fxed number of threads. However, CUDA is more ﬂexible than most realizations of SPMD, because each kernel call dynamically creates a new grid with the right number of thread blocks and threads for that application step. The programmer can use a convenient degree of parallelism for each kernel, rather than having to design all phases of the computation to use the same numberof threads. Figure C.3.6 shows an example of an SPMD-like CUDA code sequence. It first instantiates kernelF on a 2D grid of 3 x 2 blocks where each 2D thread block consists of 5 x 3 threads. It then instantiates kernelG on a 1D grid of four 1D thread blocks with six threads each. Because kernelG depends on the results of kernelF, they are separated by an interkernel synchronization barrier.CUDA编程模型的风格类似于熟悉的单程序多数据（SPMD）模型 - 它明确地表达并行性，并且每个内核在固定数量的线程上执行。 但是，CUDA比SPMD的大多数实现更灵活，因为每个内核调用动态地为该应用程序步骤创建具有正确数量的线程块和线程的新网格。 程序员可以为每个内核使用方便的并行度，而不必设计计算的所有阶段以使用相同数量的线程。 图C.3.6显示了类似SPMD的CUDA代码序列的示例。 它首先在3 x 2块的2D网格上实例化kernelF，其中每个2D线程块由5 x 3个线程组成。 然后，它在四个1D线程块的1D网格上实例化kernelG，每个线程块有6个线程。 因为kernelG依赖于kernelF的结果，所以它们被内核同步障碍隔开。 single-program multiple data (SPMD): A style of parallel programming model in which all threads execute the same program. SPMD threads typically coordinate with barrier synchronization.一种并行编程模型，其中所有线程都执行相同的程序。 SPMD线程通常与屏障同步协调。 The concurrent threads of a thread block express fne-grained data parallelism and thread parallelism. The independent thread blocks of a grid express coarse-grained data parallelism. Independent grids express coarse-grained task parallelism. A kernel is simply C code for one thread of the hierarchy.线程块的并发线程表示细粒度数据并行性和线程并行性。 网格的独立线程块表示粗粒度数据并行性。 独立网格表示粗粒度的任务并行性。 内核只是层次结构中一个线程的C代码 RestrictionsFor efficiency, and to simplify its implementation, the CUDA programming model has some restrictions. Threads and thread blocks may only be created by invoking a parallel kernel, not from within a parallel kernel. Together with the required independence of thread blocks, this makes it possible to execute CUDA programs with a simple scheduler that introduces minimal runtime overhead. In fact, the Tesla GPU architecture implements hardware management and scheduling of threads and thread blocks.为了提高效率并简化其实现，CUDA编程模型有一些限制。线程和线程块只能通过调用并行内核来创建，而不能通过并行内核来创建。与线程块所需的独立性一起，这使得使用简单的调度程序执行CUDA程序成为可能，该调度程序引入了最小的运行时开销。实际上，Tesla GPU架构实现了线程和线程块的硬件管理和调度。 Task parallelism can be expressed at the thread block level but is difficult to express within a thread block because thread synchronization barriers operate on all the threads of the block. To enable CUDA programs to run on any number of processors, dependencies among thread blocks within the same kernel grid are not allowed—blocks must execute independently. Since CUDA requires that thread blocks be independent and allows blocks to be executed in any order, combining results generated by multiple blocks must in general be done by launching a second kernel on a new grid of thread blocks (although thread blocks may coordinate their activities using atomic memory operations on the global memory visible to all threads—by atomically incrementing queue pointers, for example).任务并行性可以在线程块级别表示，但难以在线程块内表达，因为线程同步障碍在块的所有线程上运行。要使CUDA程序能够在任意数量的处理器上运行，不允许同一内核网格中的线程块之间的依赖关系 - 块必须独立执行。由于CUDA要求线程块是独立的并且允许以任何顺序执行块，因此通常必须通过在新的线程块网格上启动第二个内核来组合由多个块生成的结果（尽管线程块可以使用它来协调它们的活动）所有线程都可见的全局内存上的原子内存操作 - 例如，通过原子递增队列指针）。 Recursive function calls are not currently allowed in CUDA kernels. Recursion is unattractive in a massively parallel kernel, because providing stack space for the tens of thousands of threads that may be active would require substantial amounts of memory. Serial algorithms that are normally expressed using recursion, such asquicksort, are typically best implemented using nested data parallelism rather than explicit recursion.CUDA内核当前不允许递归函数调用。 递归在大规模并行内核中没有吸引力，因为为可能活跃的数万个线程提供堆栈空间将需要大量的内存。 通常使用递归表示的串行算法（例如快速排序）通常最好使用嵌套数据并行而不是显式递归来实现。 To support a heterogeneous system architecture combining a CPU and a GPU, each with its own memory system, CUDA programs must copy data and results between host memory and device memory. The overhead of CPU–GPU interaction and data transfers is minimized by using DMA block transfer engines and fast interconnects. Compute-intensive problems large enough to need a GPU performance boost amortize the overhead better than small problems.为了支持组合CPU和GPU的异构系统架构，每个架构都有自己的内存系统，CUDA程序必须在主机内存和设备内存之间复制数据和结果。 通过使用DMA块传输引擎和快速互连，可以最大限度地减少CPU-GPU交互和数据传输的开销。 大到足以需要GPU性能提升的计算密集型问题可以比小问题更好地分摊开销。 Implications for Architecture 对建筑的启示The parallel programming models for graphics and computing have driven GPU architecture to be different than CPU architecture. The key aspects of GPU programs driving GPU processor architecture are:用于图形和计算的并行编程模型驱动GPU架构与CPU架构不同。 GPU程序驱动GPU处理器架构的关键方面是： Extensive use of fne-grained data parallelism: Shader programs describe how to process a single pixel or vertex, and CUDA programs describe how to compute an individual result.广泛使用细粒度数据并行：着色器程序描述如何处理单个像素或顶点，而CUDA程序描述如何计算单个结果。 Highly threaded programming model: A shader thread program processes a single pixel or vertex, and a CUDA thread program may generate a single result. A GPU must create and execute millions of such thread programs per frame, at 60 frames per second. 高线程编程模型：着色器线程程序处理单个像素或顶点，CUDA线程程序可以生成单个结果。 GPU必须每帧创建并执行数百万个这样的线程程序，每秒60帧。 Scalability: A program must automatically increase its performance when provided with additional processors, without recompiling. 程序必须在提供额外的处理器时自动提高其性能，而无需重新编译。 Intensive ﬂoating-point (or integer) computation.强化浮点（或整数）计算。 Support of high throughput computations.支持高吞吐量计算。]]></content>
      <categories>
        <category>GPU相关</category>
      </categories>
      <tags>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2_GPU_System_Architectures]]></title>
    <url>%2F2019%2F01%2F23%2FGPU_System_Architectures%2F</url>
    <content type="text"><![CDATA[In this section, we survey GPU system architectures in common use today. We discuss system configurations, GPU functions and services, standard programming interfaces, and a basic GPU internal architecture.在本节中，我们将调查目前常用的GPU系统架构。 我们将讨论系统配置，GPU功能和服务，标准编程接口以及基本的GPU内部架构。 Heterogeneous CPU–GPU System Architecture 异构CPU-GPU系统架构A heterogeneous computer system architecture using a GPU and a CPU can be described at a high level by two primary characteristics: first, how many functional subsystems and/or chips are used and what are their interconnection technologies and topology; and second, what memory subsystems are available to these functional subsystems. See Chapter 6 for background on the PC I/O systems and chip sets.使用GPU和CPU的异构计算机系统架构可以通过两个主要特征在高级别描述：第一，使用多少功能子系统和/或芯片以及它们的互连技术和拓扑是什么; 第二，这些功能子系统可以使用哪些内存子系统。 有关PC I / O系统和芯片组的背景信息，请参见第6章。 The Historical PC(circa 1990) 历史PC（大约1990年）Figure C.2.1 shows a high-level block diagram of a legacy PC, circa 1990. The north bridge (see Chapter 6) contains high-bandwidth interfaces, connecting the CPU, memory, and PCI bus. The south bridge contains legacy interfaces and devices: ISA bus (audio, LAN), interrupt controller; DMA controller; time/counter. In this system, the display was driven by a simple framebuffer subsystem known as a VGA (video graphics array) which was attached to the PCI bus. Graphics subsystems with built-in processing elements (GPUs) did not exist in the PC landscape of 1990.图C.2.1显示了大约是1990年、的传统PC的高级框图。北桥（见第6章）包含高带宽接口，连接CPU，内存和PCI总线。 南桥包含传统接口和设备：ISA总线（音频，LAN），中断控制器; DMA控制器;定时/计数器。 在该系统中，显示器由称为VGA（视频图形阵列）的简单帧缓冲子系统驱动，该子系统连接到PCI总线。 1990年的PC环境中不存在具有内置处理元件（GPU）的图形子系统。 Figure C.2.2 illustrates two configurations in common use today. These are characterized by a separate GPU (discrete GPU) and CPU with respective memory subsystems. In Figure C.2.2a, with an Intel CPU, we see the GPU attached via a 16-lane PCI-Express 2.0 link to provide a peak 16 GB/s transfer rate, (peak of 8 GB/s in each direction). Similarly, in Figure C.2.2b, with an AMD CPU, the GPU is attached to the chipset, also via PCI-Express with the same available bandwidth. In both cases, the GPUs and CPUs may access each other’s memory, albeit with less available bandwidth than their access to the more directly attached memories. In the case of the AMD system, the north bridge or memory controller is integrated into the same die as the CPU.图C.2.2说明了目前常用的两种配置。 它们的特征在于单独的GPU（离散GPU）和具有相应存储器子系统的CPU。 在图C.2.2a中，使用Intel CPU，我们看到GPU通过16通道PCI-Express 2.0链路连接，以提供16 GB / s的峰值传输速率（每个方向的峰值为8 GB / s）。同样，在图C.2.2b中，使用AMD CPU，GPU也通过具有相同可用带宽的PCI-Express连接到芯片组。 在这两种情况下，GPU和CPU可以访问彼此的内存，尽管可用带宽少于访问更直接连接的内存。 在AMD系统的情况下，北桥或存储器控制器集成到与CPU相同的管芯中。 A low-cost variation on these systems, a unifed memory architecture (UMA) system, uses only CPU system memory, omitting GPU memory from the system. These systems have relatively low performance GPUs, since their achieved performance is limited by the available system memory bandwidth and increased latency of memory access, whereas dedicated GPU memory provides high bandwidth and low latency.这些系统的低成本变化，统一内存架构（UMA）系统，仅使用CPU系统内存，从系统中省略GPU内存。 这些系统具有相对低性能的GPU，因为它们实现的性能受可用系统存储器带宽和存储器访问延迟的限制，而专用GPU存储器提供高带宽和低延迟。A high performance system variation uses multiple attached GPUs, typically two to four working in parallel, with their displays daisy-chained. An example is the NVIDIA SLI (scalable link interconnect) multi-GPU system, designed for high performance gaming and workstations.高性能系统变体使用多个连接的GPU，通常两到四个并行工作，其显示器采用菊花链式连接。一个例子是NVIDIA SLI（可扩展链路互连）多GPU系统，专为高性能游戏和工作站而设计。The next system category integrates the GPU with the north bridge (Intel) or chipset (AMD) with and without dedicated graphics memory.下一个系统类别将GPU与北桥（Intel）或芯片组（AMD）集成，有或没有专用的图形内存Chapter 5 explains how caches maintain coherence in a shared address space. With CPUs and GPUs, there are multiple address spaces. GPUs can access their own physical local memory and the CPU system’s physical memory using virtual addresses that are translated by an MMU on the GPU. The operating system kernel manages the GPU’s page tables. A system physical page can be accessed using either coherent or noncoherent PCI-Express transactions, determined by an attribute in the GPU’s page table. The CPU can access GPU’s local memory through an address range (also called aperture) in the PCI-Express address space.第5章解释了缓存如何在共享地址空间中保持一致性。对于CPU和GPU，有多个地址空间。 GPU可以使用由GPU上的MMU转换的虚拟地址访问自己的物理本地内存和CPU系统的物理内存。操作系统内核管理GPU的页表。可以使用由GPU页面表中的属性确定的相干或非相干PCI-Express事务来访问系统物理页面。 CPU可以通过PCI-Express地址空间中的地址范围（也称为孔径）访问GPU的本地存储器。 Game Consoles 游戏主机Console systems such as the Sony PlayStation 3 and the Microsof Xbox 360 resemble the PC system architectures previously described. Console systems are designed to be shipped with identical performance and functionality over a lifespan that can last five years or more. During this time, a system may be reimplemented many times to exploit more advanced silicon manufacturing processes and thereby to provide constant capability at ever lower costs. Console systems do not need to have their subsystems expanded and upgraded the way PC systems do, so themajor internal system buses tend to be customized rather than standardized.诸如Sony PlayStation 3和Microsof Xbox 360之类的控制台系统类似于先前描述的PC系统架构。 控制台系统设计为在相同的使用寿命期内具有相同的性能和功能，可以使用五年或更长时间。 在此期间，系统可以多次重新实现以利用更先进的硅制造工艺，从而以更低的成本提供恒定的能力。 控制台系统不需要像PC系统那样扩展和升级子系统，所以主要的内部系统总线往往是定制的而不是标准化的。 GPU Interfaces and DriversIn a PC today, GPUs are attached to a CPU via PCI-Express. Earlier generations used AGP. Graphics applications call OpenGL [Segal and Akeley, 2006] or Direct3D [Microsof DirectX Specifcation] API functions that use the GPU as a coprocessor. The APIs send commands, programs, and data to the GPU via a graphics device driver optimized for the particular GPU.在今天的PC中，GPU通过PCI-Express连接到CPU。 早期的几代人使用AGP。 图形应用程序调用OpenGL [Segal和Akeley，2006]或Direct3D [Microsof DirectX规范] API函数，这些函数使用GPU作为协处理器。 API通过针对特定GPU优化的图形设备驱动程序将命令，程序和数据发送到GPU。 APG :An extended version of the original PCI I/O bus, which provided up to eight times the bandwidth of the original PCI bus to a single card slot. Its primary purpose was to connect graphics subsystems into PC systems.APG: 原始PCI I / O总线的扩展版本，其提供的带宽是原始PCI总线的八倍，达到单个卡插槽。 其主要目的是将图形子系统连接到PC系统。 Graphics Logical PipelineThe graphics logical pipeline is described in Section C.3. Figure C.2.3 illustrates the major processing stages, and highlights the important programmable stages (vertex, geometry, and pixel shader stages).图形逻辑流水线在C.3节中描述。 图C.2.3说明了主要的处理阶段，并重点介绍了重要的可编程阶段（顶点，几何和像素着色器阶段）。 Mapping Graphics Pipeline to Unified GPU ProcessorsFigure C.2.4 shows how the logical pipeline comprising separate independent programmable stages is mapped onto a physical distributed array of processors. Basic Unifed GPU ArchitectureUnifed GPU architectures are based on a parallel array of many programmable processors. They unify vertex, geometry, and pixel shader processing and parallel computing on the same processors, unlike earlier GPUs which had separate processors dedicated to each processing type. The programmable processor array is tightly integrated with fixed function processors for texture filtering, rasterization, raster operations, anti-aliasing, compression, decompression, display, video decoding, and high-defnition video processing. Although the fixed-function processors signifcantly outperform more general programmable processors in terms of absolute performance constrained by an area, cost, or power budget, we will focus on the programmable processors here.统一的GPU架构基于许多可编程处理器的并行阵列。 它们在相同的处理器上统一顶点，几何和像素着色器处理以及并行计算，这与早期的GPU不同，后者具有专用于每种处理类型的独立处理器。 可编程处理器阵列与固定功能处理器紧密集成，用于纹理过滤，光栅化，光栅操作，抗锯齿，压缩，解压缩，显示，视频解码和高清晰度视频处理。 虽然固定功能处理器在面积，成本或功率预算限制的绝对性能方面明显优于更多通用可编程处理器，但我们将专注于此处的可编程处理器。 Compared with multicore CPUs, manycore GPUs have a different architectural design point, one focused on executing many parallel threads effciently on many processor cores. By using many simpler cores and optimizing for data-parallel behavior among groups of threads, more of the per-chip transistor budget is devoted to computation, and less to on-chip caches and overhead.与多核CPU相比，多核GPU具有不同的架构设计点，一个侧重于在许多处理器内核上有效地执行许多并行线程。 通过使用许多更简单的内核并优化线程组之间的数据并行行为，更多的每芯片晶体管预算用于计算，而更少用于片上高速缓存和开销。 Processor ArrayA unifed GPU processor array contains many processor cores, typically organized into multithreaded multiprocessors. Figure C.2.5 shows a GPU with an array of 112 streaming processor (SP) cores, organized as 14 multithreaded streaming multiprocessors (SMs). Each SP core is highly multithreaded, managing 96 concurrent threads and their state in hardware. The processors connect with four 64-bit-wide DRAM partitions via an interconnection network. Each SM has eight SP cores, two special function units (SFUs), instruction and constant caches, a multithreaded instruction unit, and a shared memory. This is the basic Tesla architecture implemented by the NVIDIA GeForce 8800. It has a unifed architecture in which the traditional graphics programs for vertex, geometry, and pixel shading run on the unifed SMs and their SP cores, and computing programs run on the same processors.统一GPU处理器阵列包含许多处理器内核，通常组织成多线程多处理器。 图C.2.5显示了一个具有112个流处理器（SP）内核阵列的GPU，组织为14个多线程流多处理器（SM）。 每个SP核心都是高度多线程的，管理96个并发线程及其硬件状态。 处理器通过互连网络连接四个64位宽的DRAM分区。 每个SM有8个SP内核，2个特殊功能单元（SFU），指令和常量高速缓存，多线程指令单元和共享存储器。 这是由NVIDIA GeForce 8800实现的基本Tesla架构。它采用统一架构，其中顶点，几何和像素着色的传统图形程序在统一的SM及其SP内核上运行，计算程序在相同的处理器上运行。The processor array architecture is scalable to smaller and larger GPU confgurations by scaling the number of multiprocessors and the number of memory partitions. Figure C.2.5 shows seven clusters of two SMs sharing a texture unit and a texture L1 cache. The texture unit delivers filtered results to the SM given a set of coordinates into a texture map. Because filter regions of support often overlap for successive texture requests, a small streaming L1 texture cache is effective to reduce the number of requests to the memory system. The processor array connects with raster operation processors (ROPs), L2 texture caches, external DRAM memories, and system memory via a GPU-wide interconnection network. The number of processors and number of memories can scale to design balanced GPU systems for different performance and market segments.通过扩展多处理器的数量和内存分区的数量，处理器阵列架构可扩展到越来越小的GPU配置。 图C.2.5显示了共享纹理单元和纹理L1缓存的两个SM的七个簇。 纹理单元将过滤结果传递给SM，给定一组坐标到纹理贴图中。 因为支持的过滤器区域经常与连续的纹理请求重叠，所以小的流式L1纹理高速缓存对于减少对存储器系统的请求的数量是有效的。 处理器阵列通过GPU范围的互连网络与光栅操作处理器（ROP），L2纹理高速缓存，外部DRAM存储器和系统存储器连接。 处理器的数量和存储器的数量可以扩展，以设计用于不同性能和细分市场的平衡GPU系统。]]></content>
      <categories>
        <category>GPU相关</category>
      </categories>
      <tags>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1_图形和计算GPU]]></title>
    <url>%2F2019%2F01%2F11%2FGraphics_and_Computing_GPUs%2F</url>
    <content type="text"><![CDATA[This appendix focuses on the GPU—the ubiquitous graphics processing unit in every PC, laptop, desktop computer, and workstation. In its most basic form, the GPU generates 2D and 3D graphics, images, and video that enable windowbased operating systems, graphical user interfaces, video games, visual imaging applications, and video. The modern GPU that we describe here is a highly parallel, highly multithreaded multiprocessor optimized for visual computing. To provide real-time visual interaction with computed objects via graphics, images, and video, the GPU has a unifed graphics and computing architecture that serves as both a programmable graphics processor and a scalable parallel computing platform. PCs and game consoles combine a GPU with a CPU to form heterogeneous systems. 本附录重点介绍GPU——每台PC，笔记本电脑，台式机和工作站中无处不在的图形处理单元。 GPU最基本的功能是生成2D和3D图形，图像和视频，以及支持基于窗口的操作系统，图形用户界面，视频游戏，视觉成像应用程序和视频。 我们在这里描述的现代GPU是一个高度并行，高度多线程的多处理器，针对视觉计算进行了优化。 为了通过图形，图像和视频提供与计算对象的实时可视交互，GPU具有统一的图形和计算架构，可用作可编程图形处理器和可扩展的并行计算平台。 PC和游戏主机（game console）将GPU与CPU相结合，形成异构系统。 graphics processing unit (gpu) ： a processor optimized for 2d and 3d graphics, video, visual computing, and display 一种针对2D和3D图形，视频，视觉计算和显示进行了优化的处理器 visual computing视觉计算 ：a mix of graphics processing and computing that lets you visually interact with computed objects via graphics, images, and video 一种图形处理和计算的混合，使你可以通过图形、图像和视频与计算对象进行可视化交互。 heterogeneous system: A system combining different processor types. A PC is a heterogeneous CPU–GPU system. 一种组合了不同处理器类型的系统。 PC就是一种异构CPU-GPU系统。 A Brief History of GPU Evolution GPU发展简史fifteen years ago, there was no such thing as a gpu. graphics on a pc were performed by a video graphics array (vga) controller. a vga controller was simply a memory controller and display generator connected to some DRAM. in the 1990s, semiconductor technology advanced sufciently that more functions could be added to the vga controller. by 1997, vga controllers were beginning to incorporate some three-dimensional (3d) acceleration functions, including hardware for triangle setup and rasterization (dicing triangles into individual pixels) and texture mapping and shading (applying “decals” or patterns to pixels and blending colors).十五年前，还没有像GPU这样的东西。 PC上的图形由视频图形阵列（video graphics array ,VGA）控制器展现。 VGA控制器只是一个连接到某些DRAM的存储器控制器和显示发生器。 在20世纪90年代，半导体技术充分发展，可以在VGA控制器中添加更多功能。 到1997年，VGA控制器开始采用一些三维（3d）加速功能，包括用于三角形设置（Triangle Setup）和光栅化(Rasterization)的硬件（将三角形切割成单个像素）和纹理映射和着色（将“贴花”或图案应用于像素和混合颜色）。 In 2000, the single chip graphics processor incorporated almost every detail of the traditional high-end workstation graphics pipeline and, therefore, deserved a new name beyond vga controller. the term gpu was coined to denote that the graphics device had become a processor.2000年，单芯片图形处理器几乎整合了传统高端工作站图形管道的每个细节，因此，它应当有一个除VGA外的全新的名称。 术语GPU被用来表示这个图形设备（graphics device）已成为一种处理器。 Over time, GPUs became more programmable, as programmable processors replaced fixed function dedicated logic while maintaining the basic 3D graphics pipeline organization. In addition, computations became more precise over time, progressing from indexed arithmetic, to integer and fixed point, to single precision ﬂoating-point, and recently to double precision ﬂoating-point. GPUs have become massively parallel programmable processors with hundreds of cores and thousands of threads. 随着时间的推移，GPU变得更加可编程，因为可编程处理器取代了固定功能专用逻辑，同时保持了基本的3D图形管道组织。此外，计算随着时间的推移变得更加精确，从索引算术(indexed arithmetic)，整数和固定点，到单精度浮点，最近又到双精度浮点。 GPU已成为具有数百个内核和数千个线程的大规模并行可编程处理器。 Recently, processor instructions and memory hardware were added to support general purpose programming languages, and a programming environment was created to allow GPUs to be programmed using familiar languages, including C and C++. This innovation makes a GPU a fully general-purpose, programmable, manycore processor, albeit still with some special benefits and limitations.最近，添加了处理器指令和存储器硬件以支持通用编程语言，并且创建了编程环境以允许使用熟悉的语言（包括C和C ++）对GPU进行编程。 这项创新使GPU成为一个完全通用的可编程多核处理器，尽管仍有一些特殊的好处和局限。 GPU Graphics Trends GPU图形的发展趋势GPUs and their associated drivers implement the OpenGL and DirectX models of graphics processing. OpenGL is an open standard for 3D graphics programming available for most computers. DirectX is a series of Microsof multimedia programming interfaces, including Direct3D for 3D graphics. Since these application programming interfaces (APIs) have well-defned behavior, it is possible to build effective hardware acceleration of the graphics processing functions defned by the APIs. This is one of the reasons (in addition to increasing device density) why new GPUs are being developed every 12 to 18 months that double the performance of the previous generation on existing applications.GPU及其相关驱动程序实现了图形处理的OpenGL和DirectX模型。 OpenGL是大多数计算机可用的3D图形编程的开放标准。 DirectX是一系列Microsof多媒体编程接口，包括用于3D图形的Direct3D。 由于这些应用程序编程接口（API）具有良好的行为，因此可以构建由API定义的图形处理功能的有效硬件加速。 这是为什么（除了增加设备密度之外）每12到18个月开发新GPU以使现有应用的前一代性能翻倍的原因之一。 application programming interface (API) : A set of function and data structure definitions providing aninterface to a library of functions. 一组函数和数据结构定义，提供了函数库的接口。 Frequent doubling of GPU performance enables new applications that were not previously possible. The intersection of graphics processing and parallel computing invites a new paradigm for graphics, known as visual computing. It replaces large sections of the traditional sequential hardware graphics pipeline model with programmable elements for geometry, vertex, and pixel programs.Visual computing in a modern GPU combines graphics processing and parallel computing in novel ways that permit new graphics algorithms to be implemented, and opens the door to entirely new parallel processing applications on pervasive high-performance GPUs.GPU性能的频繁加倍可实现以前无法实现的新应用程序。 图形处理和并行计算的交集引发了一种新的图形范例，称为视觉计算。 它将传统顺序硬件图形管道模型的大部分替换为几何，顶点和像素程序的可编程元素。现代GPU中的可视计算以新颖的方式将图形处理和并行计算相结合，允许实现新的图形算法，并打开 在普及的高性能GPU上实现全新并行处理应用的大门。 Heterogeneous System 异构系统Although the GPU is arguably the most parallel and most powerful processor in a typical PC, it is certainly not the only processor. The CPU, now multicore and soon to be manycore, is a complementary, primarily serial processor companion to the massively parallel manycore GPU. Together, these two types of processors comprise a heterogeneous multiprocessor system.虽然GPU可以说是典型PC中最并行，最强大的处理器，但它肯定不是唯一的处理器。 CPU，现在是多核(multicore)的，很快就会成为众核（manycore），是大规模并行多核GPU互补的，重要的串行处理器伙伴（好拗口）。 这两种类型的处理器一起构成了异构多处理器系统。 The best performance for many applications comes from using both the CPU and the GPU. Tis appendix will help you understand how and when to best split the work between these two increasingly parallel processors.许多应用程序的最佳性能来自于使用CPU和GPU。 附录将帮助您了解如何以及何时最好地分割这两个日益并行的处理器之间的工作。 GPU Evolves into Scalable Parallel Processor GPU发展成可扩展的并行处理器GPUs have evolved functionally from hardwired, limited capability VGA controllers to programmable parallel processors. This evolution has proceeded by changing the logical (API-based) graphics pipeline to incorporate programmable elements and also by making the underlying hardware pipeline stages less specialized and more programmable. Eventually, it made sense to merge disparate programmable pipeline elements into one unifed array of many programmable processors.GPU已经从硬连线，有限功能的VGA控制器发展到可编程并行处理器。 通过改变逻辑（基于API）的图形流水线以结合可编程元件以及通过使底层硬件流水线阶段不那么专业化和更可编程来进行这种演变。 最终，将不同的可编程流水线元件合并到一个由多个可编程处理器组成的统一阵列中是有意义的。In the GeForce 8-series generation of GPUs, the geometry, vertex, and pixel processing all run on the same type of processor. This unification allows for dramatic scalability. More programmable processor cores increase the total system throughput. Unifying the processors also delivers very eﬀective load balancing, since any processing function can use the whole processor array. At the other end of the spectrum, a processor array can now be built with very few processors, since all of the functions can be run on the same processors.在GeForce 8系列GPU中，几何，顶点和像素处理都在同一类型的处理器上运行。 这种统一允许显着的可扩展性。 更多可编程处理器内核可提高系统总吞吐量。 统一处理器还可以提供非常有效的负载平衡，因为任何处理功能都可以使用整个处理器阵列。 另一方面，处理器阵列现在可以用很少的处理器构建，因为所有功能都可以在相同的处理器上运行。 Why CUDA and GPU Computing? 为什么选择CUDA和GPU计算？This uniform and scalable array of processors invites a new model of programming for the GPU. The large amount of ﬂoating-point processing power in the GPU processor array is very attractive for solving nongraphics problems. Given the large degree of parallelism and the range of scalability of the processor array for graphics applications, the programming model for more general computing must express the massive parallelism directly, but allow for scalable execution.这种统一且可扩展的处理器阵列为GPU提供了一种新的编程模型。 GPU处理器阵列中的大量浮点处理能力对于解决非图形问题非常有吸引力。 鉴于用于图形应用程序的处理器阵列的高度并行性和可扩展性范围，用于更一般计算的编程模型必须直接表达大规模并行性，但允许可伸缩执行。 GPU computing is the term coined for using the GPU for computing via a parallel programming language and API, without using the traditional graphics API and graphics pipeline model. This is in contrast to the earlier General Purpose computation on GPU (GPGPU) approach, which involves programming the GPU using a graphics API and graphics pipeline to perform nongraphics tasks.GPU计算是通过并行编程语言和API使用GPU进行计算而创造的术语，而不使用传统的图形API和图形管道模型。 这与早期的GPU上通用计算（GPGPU）方法形成对比，后者涉及使用图形API和图形管道对GPU进行编程以执行非图形任务。 GPU computing : Using a GPU for computing via a parallel programming language and API. 使用GPU通过并行编程语言和API进行计算。GPGPU : Using a GPU for general-purpose computation via a traditional graphics API and graphics pipeline.通过传统的图形API和图形管道将GPU用于通用计算。 Compute Unifed Device Architecture (CUDA) is a scalable parallel programming model and sofware platform for the GPU and other parallel processors that allows the programmer to bypass the graphics API and graphics interfaces of the GPU and simply program in C or C++. The CUDA programming model has an SPMD (single-program multiple data) software style, in which a programmer writes a program for one thread that is instanced and executed by many threads in parallel on the multiple processors of the GPU. In fact, CUDA also provides a facility for programming multiple CPU cores as well, so CUDA is an environment for writing parallel programs for the entire heterogeneous computer system.计算统一设备架构（CUDA）是GPU和其他并行处理器的可扩展并行编程模型和软件平台，允许程序员绕过GPU的图形API和图形接口，只需用C或C ++编程。 CUDA编程模型具有SPMD（单程序多数据）的软件风格，其中程序员为一个线程编写程序，该程序由多个线程并行执行并由GPU的多个处理器执行。 实际上，CUDA也提供了编程多个CPU内核的工具，因此CUDA是一个为整个异构计算机系统编写并行程序的环境。 CUDA: A scalable parallel programming model and language based on C/C++. It is a parallel programming platform for GPUs and multicore CPUs 一种可扩展的并行编程模型和基于C / C ++的语言。 它是GPU和多核CPU的并行编程平台 GPU Unifes Graphics and Computing GPU统一了图形和计算With the addition of CUDA and GPU computing to the capabilities of the GPU, it is now possible to use the GPU as both a graphics processor and a computing processor at the same time, and to combine these uses in visual computing applications. The underlying processor architecture of the GPU is exposed in two ways: first, as implementing the programmable graphics APIs, and second, as a massively parallel processor array programmable in C/C++ with CUDA.通过将CUDA和GPU计算添加到GPU的功能，现在可以同时将GPU用作图形处理器和计算处理器，并将这些用途结合在视觉计算应用中。 GPU的底层处理器架构以两种方式暴露：第一，作为实现可编程图形API，第二，作为使用CUDA在C / C ++中编程的大规模并行处理器阵列。Although the underlying processors of the GPU are unified, it is not necessary that all of the SPMD thread programs are the same. The GPU can run graphics shader programs for the graphics aspect of the GPU, processing geometry, vertices, and pixels, and also run thread programs in CUDA.虽然GPU的底层处理器是统一的，但并不是所有的SPMD线程程序都是相同的。 GPU可以为GPU的图形方面运行图形着色器程序，处理几何，顶点和像素，还可以在CUDA中运行线程程序。The GPU is truly a versatile multiprocessor architecture, supporting a variety of processing tasks. GPUs are excellent at graphics and visual computing as they were specifcally designed for these applications. GPUs are also excellent at many generalpurpose throughput applications that are “first cousins” of graphics, in that they perform a lot of parallel work, as well as having a lot of regular problem structure. In general, they are a good match to data-parallel problems (see Chapter 6), particularly large problems, but less so for less regular, smaller problems.GPU是真正的多功能多处理器架构，支持各种处理任务。 GPU在图形和视觉计算方面非常出色，因为它们是专门为这些应用程序设计的。 GPU在许多通用吞吐量应用程序中也非常出色，这些应用程序是图形的“第一代表现形式”，因为它们执行大量并行工作，并且具有许多常规问题结构。 一般来说，它们与数据并行问题（见第6章）非常匹配，特别是大问题，但对于不那么规律，较小的问题则不那么重要。 GPU Visual Computing Applications GPU视觉计算应用程序Visual computing includes the traditional types of graphics applications plus many new applications. The original purview of a GPU was “anything with pixels,” but it now includes many problems without pixels but with regular computation and/or data structure. GPUs are effective at 2D and 3D graphics, since that is the purpose for which they are designed. Failure to deliver this application performance would be fatal. 2D and 3D graphics use the GPU in its “graphics mode”, accessing the processing power of the GPU through the graphics APIs, OpenGL™, and DirectX™. Games are built on the 3D graphics processing capability.视觉计算包括传统类型的图形应用程序以及许多新应用程序。 GPU的原始范围是“任何带有像素的东西”，但它现在包括许多没有像素但具有常规计算和/或数据结构的问题。 GPU在2D和3D图形上是有效的，因为这是它们的设计目的。 未能提供此应用性能(application performance)将是致命的。 2D和3D图形在其“图形模式”中使用GPU，通过图形API，OpenGL™和DirectX™来获取GPU的处理能力。 游戏是基于3D图形处理功能的。 Application performance, 这是什么？感觉像是在指“功能”，比如没有提供这个功能将是致命的 Beyond 2D and 3D graphics, image processing and video are important applications for GPUs. These can be implemented using the graphics APIs or as computational programs, using CUDA to program the GPU in computing mode. Using CUDA, image processing is simply another data-parallel array program. To the extent that the data access is regular and there is good locality, the program will be efficient. In practice, image processing is a very good application for GPUs. Video processing, especially encode and decode (compression and decompression according to some standard algorithms), is quite efficient.除了2D和3D图形，图像处理和视频是GPU的重要应用。 这些可以使用图形API或计算程序来实现，使用CUDA在计算模式下对GPU进行编程。 使用CUDA，图像处理只是另一种数据并行阵列程序。 如果数据访问是规则的并且具有良好的位置，则该程序将是有效的。 实际上，图像处理是GPU的一个非常好的应用程序。 视频处理，尤其是编码和解码（根据一些标准算法进行压缩和解压缩）非常有效。 The greatest opportunity for visual computing applications on GPUs is to “break the graphics pipeline.” Early GPUs implemented only specific graphics APIs, albeit at very high performance. This was wonderful if the API supported the operations that you wanted to do. If not, the GPU could not accelerate your task, because early GPU functionality was immutable. Now, with the advent of GPU computing and CUDA, these GPUs can be programmed to implement a different virtual pipeline by simply writing a CUDA program to describe the computation and data ﬂow that is desired. So, all applications are now possible, which will stimulate new visual computing approaches.GPU上可视化计算应用程序的最大的机遇是“打破图形管道。” 早期的GPU只实现了特定的图形API，尽管性能非常高。 如果API支持你想要执行的操作，那就太棒了。 如果没有，GPU就无法加速您的任务，因为早期的GPU功能是不可变的。 现在，随着GPU计算和CUDA的出现，这些GPU可以通过编写CUDA程序来编程实现不同的虚拟管道，以描述所需的计算和数据流。 因此，现在所有应用程序都可以实现，这将刺激新的视觉计算方法。]]></content>
      <categories>
        <category>GPU相关</category>
      </categories>
      <tags>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tello特洛无人机编程小结]]></title>
    <url>%2F2019%2F01%2F05%2FTello%2F</url>
    <content type="text"><![CDATA[研究了一下Tello无人机的编程，结果发现这玩具的编程还真的是简单。官方给了一个教程是使用scratch平台进行编程，然而局限性有点大，积木就那几个而SDK中的API要更多一些。对于有点编程基础的人来说，提供了API就意味着不必局限于任何平台了。 架构建立特洛 Tello 和 PC、Mac 或移动设备之间的 Wi-Fi 通信 发送命令和接收响应Tello IP：192.168.10.1 UDP PORT：8889 &lt;&lt; - - &gt;&gt; PC / Mac / Mobile 备注1：在PC，Mac或移动设备上设置UDP客户端，向特洛 Tello UDP 端口 8889 发送命令和接收响应。 备注2：在发送所有其他命令之前，向特洛 Tello UDP 端口 8889 发送“command” 命令以启动特洛 Tello 的 SDK 模式。 接收特洛 Tello 状态Tello IP：192.168.10.1 - &gt;&gt; PC / Mac / Mobile UDP Server：0.0.0.0 UDP PORT：8890 备注3：在 PC，Mac 或移动设备上建立 UDP 服务器，通过 UDP 端口 8890 从 IP 0.0.0.0收听消息。如果未进行备注1和2的操作，请先完成。 接收特洛 Tello 视频流Tello IP：192.168.10.1 - &gt;&gt; PC / Mac / Mobile UDP Server：0.0.0.0 UDP PORT：11111 备注4：在 PC，Mac 或移动设备上设置 UDP 服务器，通过服务器 UDP 端口 11111 从IP 0.0.0.0 收听消息。 备注5：先进行备注1和2的操作。然后向特洛 Tello UDP 端口 8889 发送 “streamon” 命令，开始接受特洛 Tello 视频流。 设置命令控制命令读取命令Tello状态 命令 描述 可能的响应 speed xx 设置当前速度为xx(1-100) okerror rc a b c d 设置遥控器的4个通道杆量，a:横滚（-100~100）b:俯仰（-100~100）c:油门（~100-100）d:旋转（-100~100） okerror wifi ssid pass 设置 WiFi SSID 密码 okerror 命令 描述 可能的响应 command 进入SDK命令模式 okerror takeoff 自动起飞 okerror land 自动降落 okerror streamon 打开视频流 okerror streamoff 关闭视频流 okerror emergency 停止电机转动 okerror up x 向上飞 x 厘米x = 20-500 okerror down x 向下飞 x 厘米x = 20-500 okerror left x 向左飞 x 厘米x = 20-500 okerror right x 向右飞x 厘米x = 20-500 okerror forward xx 向前飞 x 厘米x = 20-500 okerror back xx 向后飞 x 厘米x = 20-500 okerror cw xx 顺时针旋转x°x = 1-3600 okerror ccw 逆时针旋转 x°x = 1-3600 okerror flip x 朝 x 方向翻滚l = (left)r =(right)f = (forwardb = (back) okerror go x y z speed 以设置速度（cm/s）飞往坐标（x,y,z）x: 20-500y: 20-500z: 20-500speed: 10-100 okerror curve x1 y1 z1 x2 y2 z2 speed 以设置速度（ cm/s ）飞弧线，经过（x1,y1,z1）到（x2,y2,z2）如果弧线半径不在 0.5-10 米范围内，则返回相应提醒。x1, x2: -500 - 500y1, y2: -500 - 500z1, z2: -500 - 500speed: 10-60x、y、z 不能同时在-20 ~ 20 之间 okerror speed? 获取当前速度 xx battery? 获取电量信息 xx(0~100) 命令 描述 可能的响应 speed? 获取当前设置速度（cm/s） xx = (10-100) battery? 获取当前电池剩余电量的百分比值 xx = (0-100) time? 获取电机运转时间时间（s） x height? 获取相对高度 (cm) x: 10-3000 temp? 获取主板最高和最低温度(℃) x: 0-90 attitude? 获取 IMU 三轴姿态数据 pitch roll yawpitch=（-89°- 89°）roll=（-179°- 179°）yaw=（-179°- 179°） baro? 获取气压计高度(m) x acceleration? 获取 IMU 三轴加速度数据(0.001g) x y z tof? 获取 ToF 的高度值(cm) x: 10-400 &amp; 6553返回 6553 意味着测量值超过ToF 量程。 wifi? 获得 Wi-Fi 信噪比 snr 数据类型：字符串 例如“pitch:%d;roll:%d;yaw:%d;vgx:%d;vgy%d;vgz:%d;templ:%d;temph:%d;tof:%d;h:%d;bat:%d;baro:%f;\r \n”说明： pitch：俯仰角度，度数 roll：横滚角度，度数 yaw：偏航偏航，度数 vgx：x 轴速度， vgy：y 轴速度， vgz：z 轴速度， templ：主板最低温度，摄氏度 temph：主板最高温度，摄氏度 tof：ToF 距离，厘米 h：相对起飞点高度，厘米 bat：当前电量百分比，％ baro：气压计测量高度，米 time: 电机运转时间，秒 agx: x 轴加速度 agy: y 轴加速度 agz: z 轴加速度,]]></content>
      <categories>
        <category>IoT</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Next主题个性化]]></title>
    <url>%2F2019%2F01%2F02%2FNext%E4%B8%BB%E9%A2%98%E4%B8%AA%E6%80%A7%E5%8C%96%2F</url>
    <content type="text"><![CDATA[这篇博客是对过去几天来折腾Next主题经验的一次大总结。本来用的是 yilia主题，可是不知道怎么着脑抽了想换一个主题玩玩，这下好了，一折腾折腾了好几天····博客嘛，当然是内容最重要···不过高颜值更能让我有动力哈哈哈😂没办法我就喜欢这些花里胡哨的东西 主题美化以下是我用到的Next主题的个性化参考链接。这两个已经很全面啦，更多的美化方案就看这两个吧。 打造个性超赞博客Hexo+NexT+GitHubPages的超深度优化 hexo的next主题个性化教程：打造炫酷网站 增加看板娘知道看板娘是什么意思的估计差不多都很宅吧。当然看板娘不一定非得是人，我的就是一直小黑猫哈哈哈详情请看下面的链接用Live2D让看板喵入住你的Hexo博客吧(^o^)/~ 增加鼠标点击特效浮现彩色桃心以下是所需js代码：未压缩123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051! function(e, t, a) &#123; function n() &#123; c( ".heart&#123;width: 10px;height: 10px;position: fixed;background: #f00;transform: rotate(45deg);-webkit-transform: rotate(45deg);-moz-transform: rotate(45deg);&#125;.heart:after,.heart:before&#123;content: '';width: inherit;height: inherit;background: inherit;border-radius: 50%;-webkit-border-radius: 50%;-moz-border-radius: 50%;position: fixed;&#125;.heart:after&#123;top: -5px;&#125;.heart:before&#123;left: -5px;&#125;"), o(), r() &#125; function r() &#123; for (var e = 0; e &lt; d.length; e++) d[e].alpha &lt;= 0 ? (t.body.removeChild(d[e].el), d.splice(e, 1)) : (d[e].y--, d[e].scale += .004, d[e].alpha -= .013, d[e].el.style.cssText = "left:" + d[e].x + "px;top:" + d[e].y + "px;opacity:" + d[e].alpha + ";transform:scale(" + d[e].scale + "," + d[e].scale + ") rotate(45deg);background:" + d[e].color + ";z-index:99999"); requestAnimationFrame(r) &#125; function o() &#123; var t = "function" == typeof e.onclick &amp;&amp; e.onclick; e.onclick = function(e) &#123; t &amp;&amp; t(), i(e) &#125; &#125; function i(e) &#123; var a = t.createElement("div"); a.className = "heart", d.push(&#123; el: a, x: e.clientX - 5, y: e.clientY - 5, scale: 1, alpha: 1, color: s() &#125;), t.body.appendChild(a) &#125; function c(e) &#123; var a = t.createElement("style"); a.type = "text/css"; try &#123; a.appendChild(t.createTextNode(e)) &#125; catch (t) &#123; a.styleSheet.cssText = e &#125; t.getElementsByTagName("head")[0].appendChild(a) &#125; function s() &#123; return "rgb(" + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + ")" &#125; var d = []; e.requestAnimationFrame = function() &#123; return e.requestAnimationFrame || e.webkitRequestAnimationFrame || e.mozRequestAnimationFrame || e.oRequestAnimationFrame || e.msRequestAnimationFrame || function(e) &#123; setTimeout(e, 1e3 / 60) &#125; &#125;(), n()&#125;(window, document); 压缩后：1!function(e,t,a)&#123;function n()&#123;c(".heart&#123;width: 10px;height: 10px;position: fixed;background: #f00;transform: rotate(45deg);-webkit-transform: rotate(45deg);-moz-transform: rotate(45deg);&#125;.heart:after,.heart:before&#123;content: '';width: inherit;height: inherit;background: inherit;border-radius: 50%;-webkit-border-radius: 50%;-moz-border-radius: 50%;position: fixed;&#125;.heart:after&#123;top: -5px;&#125;.heart:before&#123;left: -5px;&#125;"),o(),r()&#125;function r()&#123;for(var e=0;e&lt;d.length;e++)d[e].alpha&lt;=0?(t.body.removeChild(d[e].el),d.splice(e,1)):(d[e].y--,d[e].scale+=.004,d[e].alpha-=.013,d[e].el.style.cssText="left:"+d[e].x+"px;top:"+d[e].y+"px;opacity:"+d[e].alpha+";transform:scale("+d[e].scale+","+d[e].scale+") rotate(45deg);background:"+d[e].color+";z-index:99999");requestAnimationFrame(r)&#125;function o()&#123;var t="function"==typeof e.onclick&amp;&amp;e.onclick;e.onclick=function(e)&#123;t&amp;&amp;t(),i(e)&#125;&#125;function i(e)&#123;var a=t.createElement("div");a.className="heart",d.push(&#123;el:a,x:e.clientX-5,y:e.clientY-5,scale:1,alpha:1,color:s()&#125;),t.body.appendChild(a)&#125;function c(e)&#123;var a=t.createElement("style");a.type="text/css";try&#123;a.appendChild(t.createTextNode(e))&#125;catch(t)&#123;a.styleSheet.cssText=e&#125;t.getElementsByTagName("head")[0].appendChild(a)&#125;function s()&#123;return"rgb("+~~(255*Math.random())+","+~~(255*Math.random())+","+~~(255*Math.random())+")"&#125;var d=[];e.requestAnimationFrame=function()&#123;return e.requestAnimationFrame||e.webkitRequestAnimationFrame||e.mozRequestAnimationFrame||e.oRequestAnimationFrame||e.msRequestAnimationFrame||function(e)&#123;setTimeout(e,1e3/60)&#125;&#125;(),n()&#125;(window,document); 新建love.js文件并且将上面的代码复制进去。然后将love.js文件放到路径 /themes/next/source/js/src 下，然后打开\themes\next\layout\_layout.swig文件,在末尾添加以下代码：12&lt;!-- 鼠标桃心动画 --&gt;&lt;script type="text/javascript" src="/js/src/love.js"&gt;&lt;/script&gt; 浮现Emoji和其他文字原作者博客 以下是我稍微改了下自己用的版本😳，如果你成功加入了上面的桃心特效，那么这个就是换下代码而已。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071onload = function() &#123; var click_cnt = 0; var $html = document.getElementsByTagName("html")[0]; var $body = document.getElementsByTagName("body")[0]; $html.onclick = function(e) &#123; var $elem = document.createElement("b"); $elem.style.color = "#E94F06"; $elem.style.zIndex = 9999; $elem.style.position = "absolute"; $elem.style.select = "none"; var x = e.pageX; var y = e.pageY; $elem.style.left = (x - 10) + "px"; $elem.style.top = (y - 20) + "px"; clearInterval(anim); switch (++click_cnt) &#123; case 10: $elem.innerText = "🤩"; break; case 20: $elem.innerText = "😎"; break; case 30: $elem.innerText = "😏"; break; case 40: $elem.innerText = "😐"; break; case 50: $elem.innerText = "😑"; break; case 60: $elem.innerText = "😒"; break; case 70: $elem.innerText = "૮( ᵒ̌皿ᵒ̌ )ა"; break; case 80: $elem.innerText = "(╯°口°)╯(┴—┴"; break; case 90: $elem.innerText = "别点啦"; break; case 100: case 101: case 102: case 103: case 104: case 105: $elem.innerText = "休息会儿"; break; default: $elem.innerText = "🎈"; break; &#125; $elem.style.fontSize = Math.random() * 10 + 8 + "px"; var increase = 0; var anim; setTimeout(function() &#123; anim = setInterval(function() &#123; if (++increase == 150) &#123; clearInterval(anim); $body.removeChild($elem); &#125; $elem.style.top = y - 20 - increase + "px"; $elem.style.opacity = (150 - increase) / 120; &#125;, 8); &#125;, 70); $body.appendChild($elem); &#125;;&#125;; 压缩后 1onload=function()&#123;var click_cnt=0;var $html=document.getElementsByTagName("html")[0];var $body=document.getElementsByTagName("body")[0];$html.onclick=function(e)&#123;var $elem=document.createElement("b");$elem.style.color="#E94F06";$elem.style.zIndex=9999;$elem.style.position="absolute";$elem.style.select="none";var x=e.pageX;var y=e.pageY;$elem.style.left=(x-10)+"px";$elem.style.top=(y-20)+"px";clearInterval(anim);switch(++click_cnt)&#123;case 10:$elem.innerText="🤩";break;case 20:$elem.innerText="😎";break;case 30:$elem.innerText="😏";break;case 40:$elem.innerText="😐";break;case 50:$elem.innerText="😑";break;case 60:$elem.innerText="😒";break;case 70:$elem.innerText="૮( ᵒ̌皿ᵒ̌ )ა";break;case 80:$elem.innerText="(╯°口°)╯(┴—┴";break;case 90:$elem.innerText="别点啦";break;case 100:case 101:case 102:case 103:case 104:case 105:$elem.innerText="休息会儿";break;default:$elem.innerText="🎈";break&#125;$elem.style.fontSize=Math.random()*10+8+"px";var increase=0;var anim;setTimeout(function()&#123;anim=setInterval(function()&#123;if(++increase==150)&#123;clearInterval(anim);$body.removeChild($elem)&#125;$elem.style.top=y-20-increase+"px";$elem.style.opacity=(150-increase)/120&#125;,8)&#125;,70);$body.appendChild($elem)&#125;&#125;; 动态标签栏Hexo NexT主题中添加网页标题崩溃欺骗搞怪特效 算是一个小细节的美化吧，它可以在你切换页面的时候更改标签栏的文字 12345678910111213141516var OriginTitle = document.title;var titleTime;document.addEventListener('visibilitychange', function () &#123; if (document.hidden) &#123; // $('[rel="icon"]').attr('href', "/images/TEP.ico"); //如果需要图标一起变，那么就将这行取消注释并选择正确的图片路径 document.title = ' 😉不看了就关掉 ~';//要显示的信息 clearTimeout(titleTime); &#125; else &#123; //$('[rel="icon"]').attr('href', "/favicon.ico"); 同上 document.title = '😍欢迎回来~' + OriginTitle; titleTime = setTimeout(function () &#123; document.title = OriginTitle; &#125;, 2000); &#125;&#125;); 新建crash_cheat.js文件并且将上面的代码复制进去。然后将love.js文件放到路径 /themes/next/source/js/src 下，然后打开\themes\next\layout\_layout.swig文件,在末尾添加以下代码：12&lt;!--崩溃欺骗--&gt;&lt;script type="text/javascript" src="/js/src/crash_cheat.js"&gt;&lt;/script&gt; 排版相关tabs的使用tabs的详细用法 我认为tab可以起到节省页面空间的作用，把一些文字分页放置更加美观tab标题测试 1tab标题测试 2tab标题测试 3这是第一页第2页第3页 这个tab标签在放js代码块的时候有bug：首先它不能使用 “ ``` 代码块 ``` ” 这样的标签. 不然它就会显示 undefined。这时候要使用code标签。另外它只能在第一页插入代码块，插入之后第二页就翻不出来，总之插入代码的时候BUG一堆根本不能用😭 label的使用label测试label使用详情 Demo:所谓的label从效果上看神似荧光笔 反正我就是当荧光笔来划重点吧 这是Default 这是Primary 这是Success 这是Info 这是Warning 这是Danger 这是有删除线的Danger Code:1234567这是&#123;% label default@Default%&#125;这是&#123;% label primary@Primary%&#125;这是&#123;% label success@Success%&#125;这是&#123;% label info@Info%&#125;这是&#123;% label warning@Warning%&#125;这是&#123;% label danger@Danger%&#125;这是有删除线的~~&#123;% label danger@Danger%&#125;~~ Button的使用button的详细用法Demo:按钮我也不经常用，但是如果像这样分享下载链接的时候可能会有点用吧 点击会下载老婆！慎点😜点击下载 好多bug啊····如果这里加一个note标签下面的code和标题就不会渲染了，😶 Code: 1&#123;% btn https://cooguyan-1252810309.cos.ap-chengdu.myqcloud.com/beaupic/gakki/5267d628b0f0b81855f15b80494d36c2.jpg, 点击下载, download fa-lg fa-fw %&#125; note的使用note标签详细用法 Demo: 默认 用来替代引用标签还行 默认 有图标的引用标签吧 可以补充一些信息 Primary，不知道怎么用 Warning，写一些警告信息 Danger,就是这样很危险吧 Success，成功是什么鬼啊 没有图标的样子 Code:12345678&#123;% note %&#125;默认 用来替代引用标签还行&#123;%endnote%&#125;&#123;% note default %&#125; 默认 有图标的引用标签吧&#123;%endnote%&#125;&#123;% note info %&#125;可以补充一些信息&#123;%endnote%&#125;&#123;% note primary%&#125;Primary，不知道怎么用&#123;%endnote%&#125;&#123;% note warning%&#125;Warning，写一些警告信息&#123;%endnote%&#125;&#123;% note danger %&#125;Danger,就是这样很危险吧&#123;% endnote%&#125;&#123;% note success%&#125;Success，成功是什么鬼啊&#123;%endnote%&#125;&#123;% note success no-icon%&#125;没有图标的样子&#123;%endnote%&#125; 引用文本居中显示详细用法 Demo: 我们能体验的最美好的东西是神秘的事物。他是所有真正艺术和科学的来源。——阿尔伯特·爱因斯坦 《我的世界观》，1930 增多我们不加思索就能完成的重要工作的数量，文明便是如此进步的。——Alfred North Whitehead，An Introduction to Mathematics，1911 我对上帝说西班牙语，对女人说意大利语，对男人说法语，对我的马说德语。——查理五世，法国国王（1337~1380） Code:123456789101112&lt;!-- HTML方式: 直接在 Markdown 文件中编写 HTML 来调用 --&gt;&lt;!-- 其中 class="blockquote-center" 是必须的 --&gt;&lt;blockquote class="blockquote-center"&gt;我们能体验的最美好的东西是神秘的事物。他是所有真正艺术和科学的来源。——阿尔伯特·爱因斯坦 《我的世界观》，1930&lt;/blockquote&gt;&lt;!-- 标签 方式，要求版本在0.4.5或以上 --&gt;&#123;% centerquote %&#125;增多我们不加思索就能完成的重要工作的数量，文明便是如此进步的。——Alfred North Whitehead，An Introduction to Mathematics，1911&#123;% endcenterquote %&#125;&lt;!-- 标签别名 --&gt;&#123;% cq %&#125;我对上帝说西班牙语，对女人说意大利语，对男人说法语，对我的马说德语。——查理五世，法国国王（1337~1380） &#123;% endcq %&#125;]]></content>
      <categories>
        <category>Hexo相关</category>
      </categories>
      <tags>
        <tag>Next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RAID(Reduntant Arrays of Inexpensive Disks)]]></title>
    <url>%2F2018%2F12%2F30%2FRAID%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[以下是《计算机组成与设计》第四版原文,我摘录了其中了关于RAID的部分 无冗余 (RAID 0) 仅仅把数据分做到多个磁盘，称为条带化，自动把访问强制分布到几个磁盘上。在一组磁盘上进行条带化使得这一组磁盘对于软件来说是一个大磁盘，从面简化了存储管理。而且对多个同时的访问来说有利于改进性能，因为多个磁盘可以同时操作。例如，视频编辑系统经常对它们的数据进行条带化，不需要像数据库那样关心可靠性问题。 RAID 0的称谓有些不妥，因为它根本没有冗余。然而，RAID的级别通常由操作员在创建系统时设置，而RAIDO经常被列为其中一个选项。因此，RAID 0的说法就被广泛使用了。 镜像(RAID 1) 这种传统的容忍磁盘失效的方法，被称为镜像”或者影像(shadowing), 使用比RAID O 多一倍的磁盘数。数据写人某个盘时，同样的数据会写人其冗余盘，因此始终存在信息的两份副本。如果一个磁盘出现故障，系统就转向其“镜像”读取内容以获得所需信息。镜像是最昂贵的RAID方案，因为它需要最多的磁盘。 错误检测和纠错码 (RAID 2) RAID 2借用了主存常用的错误校验和恢复技术(参见光盘中的附录C)。RAID 2已经不再使用了，因此我们这里不做介绍。 位交叉奇偶校验 (RAID 3) 增加可用性的开销可以减至I/n,这里n为保护组“内磁盘的数目。我们不再为每个磁盘做一个原始数据的完全备份，面只需要加入足够的冗余信息以便在出错的时候恢复丢失的信息。读写操作在组内所有磁盘上进行，一个额外的磁盘存有校验信息以防错误的发生。RAID 3在使用大数据集的应用( 如多媒体和科学计算)中报流行。 奇偶校验(parity) 就是这样的一个策略。不熟悉奇偶校验的读者可以把冗余磁盘想象成保存有其他磁盘所有数据的和。当.个磁盘出错时，用奇偶校验盘减去正常破盘的数据的和;余数就是丢失的信息。奇偶校验就是模2下的求和。 与RAID 1不同，RAID3 必须读很多磁盘才能确定丟失的数据。该技术背后的假设就是用更长的时间来恢复错误而用更少的冗余存储得到个好的平衡。 块交叉奇偶校验 (RAID 4) RAID 4使用同RAID3数目比率- -样大的数据磁盘和校验盘,但是访问数据的方式不同。奇偶校验码以块为单位存储，和-组数据块相关。 在RAID 3中，每次访向都用到所有磁盘。然面，某些应用偏重于较小的数据访问，允许并行地发生多个独立访问。这就是发明RAID4 - RAID 6的目的。由于读操作需要校验每个扇区的错误检测信息来判断数据正确与否，只要少量的访问数据仍为同一个扇区，各磁盘上这些“小)数据量的读操作”就可以独立地进行。在RAID环境中，小数据访向在保护组中的一个磁盘发生，而大数据量访问需要用到保护组中的所有磁盘。 写操作是另外个问题。看上去似乎每-次小数据量的写操作都需要访问其他磁盘信息，使用这些信息计算新的奇偶校验值，如图所示。一次“小数据量的写操作”需要读取旧数据和旧奇偶校验，添加新信息，接着把新的奇偶校验写入校验盘，把新的数据写入数据盘。 小数据量写更新在RAID 3 和 RAID 4 上的比较 对小数据量写操作的优化减少了磁盘访问的数量，也减少了占用磁盘空间的数量。本图假设有4块数据和1块校验码。图左侧的RAID 3校验计算在加人块D0’之前要读数据块D1、D2和D3才能计算新校验码P’。(需要注意的是，新数据D0’直接来自CPU,所以不需要读磁盘来获取。)图右侧的RAID 4优化方法是读取旧值DO并与新值DO’比较看是否改变。然后读取旧校验码P,修改对应的位,形成新校验码P’。使用或逻辑操作即可实现。图中把三次读磁盘(D1、 D2、D3)和两次写磁盘(D0’, P’) 替换为两次读磁盘(DO, P)和两次写磁盘(D0’, P’),前者访问了所有磁盘，而后者仅访问其中的两个磁盘。随着校验组大小的增加将使得优化的效果更加明显。RAID 5亦使用同样的方式。 减小开销的关键在于校验码不过是信息的-一个总和;通过观察写人新信息后哪些位发生了变化，我们只需改变校验盘上的对应位的信息即可。图6-13的右图说明了该方法。我们必须从要写的磁盘读取旧数据,用旧数据和新数据比较,看哪些位发生了变化。读旧奇偶校验和,改变对应的位，然后写人新数据以及新的校验和。这样，一次小数据量的写操作包含对两个磁盘的4次访问，而不是访问所有的磁盘。这种组织结构就是RAID 4 分布式块交叉奇偶校验（RAID 5）RAID 4 有效的支持了大数据量读、大数据量写和小数据量读、小数据量写的混合操作。它的缺点是每次写操作都要更新校验盘、从而校验盘成为连续写的瓶颈。为了解决校验-写瓶颈，校验信息可由分布到所有盘上，是的写操作不存在单一的瓶颈。这种分布式的奇偶校验组织方式就是RAID 5。下图展示了数据在RAID 4 和 RAID 5 上是如何分布的。右图展示的是RAID 5 组织方式。其中数据块每行的校验信息不再限定在单个磁盘。只要校验块不在相同的磁盘上，这种组织方式就使得多 个写操作可以同时发生。例如，右侧第1写操作是向第8块写数据，需委同时访向P2中的奇偶值，从而需要访问第I个和第3个磁盘。右侧第2个写操作对第5块进行写，意味着要更新其校验块P, ,从而需要访问第2个和第4个磁盘,所以它可以和写第8个数据并发进行。对于左侧的组织结构来说，同样的写操作则需要修改第5个磁盘上的PI和P2,这就构成了瓶颈。 P+Q冗余(RAID 6) 基于奇偶校验的机制可使系统免受单个可自动识别的错误的破坏。当单个错误纠正机制不足以保护系统时，可利用奇偶校验对数据和另-个校验盘的信息进行二次计算。二次校验块可使系统从二次错误中恢复过来。因此，它的存储开销是RAID 5 的两倍。图6-13中的小数据方法还能成立，只是现在更新P和Q信息需要访向6个盘而不是访问4个盘。 RAID 小结 RAID 1 和RAID 5 广泛用于服务器；一项估计是服务器中 80% 的磁盘都使用了某种RAID. RAID 系统的弱点是修复。首先，为了避免在修复时数据不可用，阵列必须设计为不必美闭系统就能替换出错盘。RAID 拥有足够的冗余性以保证不间断的操作，但是热交换磁盘对阵列和磁盘接口的物理及电路设计提出了要求。其次，修复中可能出现另外的错误，这样修复时间会影响丢失数据的概率:修复时间越长，另一错误引起丢失数据的概率越大。某些系统并不用等待操作员来装上好的磁盘，它们包含应急备用”，这样一旦检测出错误，数据就可以立即重建。操作员就可轻松地更换出错磁盘。最后，操作人员最终决定撒掉哪个磁盘。如图6-3所示，注意，操作员是人，因此他们有时候会撒掉好的磁盘导致不可恢复的屯盘错误。 除了设计可以修复的RAID,还存在一些如何随着磁盘技术变化的问题。尽管磁盘厂商标称他们的产品具有很高的MTTF,但是这些数据是在假设的情况下得到的。如果某个特定磁盘阵列迎遇了由于空调系统故障、糟糕的磁盘架设计、构建或者安装引起震动面引起温度周期变化，出错率将大大增加，增加3-6倍(见6.12节)。RAD可靠性的计算假设多个磁盘失效之间是独立的，但实际上这些失效可能是相关的，因为环境引起的损伤可能会发生在阵列中的所有磁盘上。另一个问题是磁盘的带宽相对磁盘的容量变化得越来越慢，在个RAID系统中修复一个磁盘的时间变得越来越长，这一点反过来增加第二次故障出现的概率。例如，在假设没有干扰时，一个1000 GB SATA磁盘可能需要花费3个小时来顺序读。假设这个损坏的RAID 很可能被维续用来提供数据，重建过程就会被延长很多。除了增加时间外，另-个问题是在重建过程中一次读很多数据将意味者增加不可恢复的读媒体故障发生的概率，而不可恢复的故障将导致数据丢失。其他关于同时发生多个故障的看法是增加阵列中的磁盘数目以及使用SATA磁盘，这样比传统的商用磁盘慢-些，但具有更高的容量。 因此，这些趋势导致对防止系统免受多重故障的研究兴趣大大增加。所以RAID6成为一种可选项，在实际中被使用。 条带化(striping)：将逻辑上连续的数据块分布到不同的磁盘t,得到比单个微盘更高的性能。 镜像(mirroring)：将相同的数据写到客个数盘上，目的是增加数据的可用性。 保护组(protection group):共享一个公共校验磁的数据磁盘组或者数据块。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Tampermonkey的运行原理]]></title>
    <url>%2F2018%2F12%2F26%2FTem%2F</url>
    <content type="text"><![CDATA[TamperMonkey is a Google Chrome (and Opera and Chromium) plugin similar to GreaseMonkey for Firefox. It allows you to inject additional JavaScript into web pages you load in your browser, adding features, removing features, or in our case doing hacky, automated things]]></content>
      <categories>
        <category>Tampermonkey相关</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Chrome插件开发原理]]></title>
    <url>%2F2018%2F12%2F26%2FChrome%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[Extensions are small software programs that customize the browsing experience. They enable users to tailor Chrome functionality and behavior to individual needs or preferences. They are built on web technologies such as HTML, JavaScript, and CSS.]]></content>
      <categories>
        <category>Chrome相关</category>
      </categories>
      <tags>
        <tag>插件开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VSCode常用快捷键]]></title>
    <url>%2F2018%2F12%2F26%2FVSCode%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[记录几个快捷键了事···· 官方快捷键文档 快捷键 说明 Ctrl + Shift + P, F1 命令面板 Ctrl + , 用户设置 Ctrl + F 查找 Ctr + =/- 放大縮小]]></content>
      <categories>
        <category>VSCode相关</category>
      </categories>
      <tags>
        <tag>快捷键</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pycharm常用快捷键]]></title>
    <url>%2F2018%2F12%2F26%2FPycharm%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[记录一些Pycharm中常用的快捷键 创建和编辑 功能 描述 注释 Show Intention Actions Alt+Enter . Basic Code Completion Ctrl+Space . Smart Code Completion Ctrl+Shift+Space . Type Name Completion Ctrl+Alt+Space 类型名补全，几乎可以补全任何东西 Quick Definition Ctrl+Shift+I 可以在当前页面浏览定义.不可直接编辑 它会展示方法的内容 Quick/External Documentation Ctrl+Q / Shift+F1 可以快速查看函数文档,按两次q可以开一个单独的侧边窗口 ， Surround With… Ctrl+Alt+T 可以将选择的代码用什么框住。比如if语句 while语句 try catch之类 Extend/Shrink Selection Ctrl+W / Ctrl+Shift+W 从光标处逐渐扩大选区 Copy Document Path Ctrl+Shift+C 可以直接复制当前打开文件的绝对路径 Duplicate Current Line or Selection Ctrl+D 在需要连续复制代码的时候特别有用，比如需要连续写很多print函数 Move Line Up Ctrl+Shift+UpMove Line Down Ctrl+Shift+DownDelete Line at Caret Ctrl+YJoin/Split Line Ctrl+Shift+J / Ctrl+EnterStart New Line Shift+EnterToggle Case Ctrl+Shift+UExpand/Collapse Code Block Ctrl+NumPad +/-Expand/Collapse All Ctrl+NumPad +/-Save All Ctrl+S Analyze and ExploreShow Error Description Ctrl+F1Next/Previous Highlighted Error F2 / Shift+F2Run Inspection by Name… Ctrl+Alt+Shift+IType Hierarchy Ctrl+HCall Hierarchy Ctrl+Alt+H VERSION CONTROL 版本控制VCS Operations Popup… Alt+`Commit Ctrl+KUpdate Project Ctrl+TRecent Changes Alt+Shift+CRevert Ctrl+Alt+ZPush… Ctrl+Shift+KNext Change Ctrl+Alt+Shift+DownPrevious Change Ctrl+Alt+Shift+Up MASTER YOUR IDE 管理IDEFind Action… Ctrl+Shift+AOpen a Tool Window Alt+[0-9]Synchronize Ctrl+Alt+YQuick Switch Scheme… Ctrl+`可以快速切换主题 我觉得挺实用的 Settings… Ctrl+Alt+S 打开设置Jump to Source/Navigation Bar F4 / Alt+HomeJump to Last Tool Window F12Hide Active/All Tool Windows Shift+Esc / Ctrl+Shift+F12Go to Next/Previous Editor Tab Alt+Right / Alt+LeftGo to Editor (from a Tool Window) EscClose Active Tab/Window Ctrl+Shift+F4 / Ctrl+F4 FIND EVERYTHING 查找 功能 描述 注释 Search Everywhere Double Shift 按两下shift Declaration Ctrl+B 可以转到函数和类等的声明处,与下面的快捷键不同，如果声明的函数不在同一个文件则会开一个新的页面去查看，并且可以编辑 Find Usages / Find Usages in File Alt+F7 / Ctrl+F7 查找引用，这个查找是全局的，比如查找print的引用就会发现有数百个引用 Find/Replace Ctrl+F / Ctrl+RFind/Replace in Path Ctrl+Shift+F / Ctrl+Shift+RNext/Previous Occurence F3 / Shift+F3Find Word at Caret Ctrl+F3Go to Class/File Ctrl+N / Ctrl+Shift+NGo to File Member Ctrl+F12Go to Symbol Ctrl+Alt+Shift+N NAVIGATE FROM SYMBOLS 从符号处定位 Type Declaration (JavaScript only) Ctrl+Shift+BSuper Method Ctrl+UImplementation(s) Ctrl+Alt+B Highlight Usages in File Ctrl+Shift+F7 把引用高亮显示出来Show Usages Ctrl+Alt+F7 用一个小框直接展示引用，看起来比较方便NAVIGATE IN CONTEXT 在上下文中定位Select In… Alt+F1Recently Viewed/Changed Files Ctrl+E / Ctrl+Shift+ELast Edit Location Ctrl+Shift+BackNavigate Back/Forward Ctrl+Alt+Left / Ctrl+Alt+RightGo to Previous/Next method Alt+Up / Alt+DownLine/Column… Ctrl+GGo to Code Block End/Start Ctrl+] / Ctrl+[Add to Favorites Alt+Shift+FToggle Bookmark F11Toggle Bookmark with Mnemonic Ctrl+F11Go to Numbered Bookmark Ctrl+[0-9]Show Bookmarks Shift+F BUILD, RUN, AND DEBUG 构建 运行和调试Run context configuration Ctrl+Shift+F10Run/Debug Selected Configuration Alt+Shift+F10 / Alt+Shift+F9Run/Debug Current Configuration Shift+F10 / Shift+F9Step Over F8Step Into F7Smart Step Into Shift+F7Step Out Shift+F8Run to Cursor Alt+F9Force Run to Cursor Ctrl+Alt+F9Show Execution Point Alt+F10Evaluate Expression… Alt+F8Stop Ctrl+F2Stop Background Processes… Ctrl+Shift+F2Resume Program F9Toggle Line Breakpoint Ctrl+F8Toggle Temporary Line Breakpoint Ctrl+Alt+Shift+F8Edit breakpoint Ctrl+Shift+F8View Breakpoints… Ctrl+Shift+F8REFACTOR AND CLEAN UPRefactor This… Ctrl+Alt+Shift+TCopy… F5Move… F6Safe Delete… Alt+DeleteRename… Shift+F6Change Signature… Ctrl+F6Inline… Ctrl+Alt+NExtract Method Ctrl+Alt+MIntroduce Variable Ctrl+Alt+VIntroduce Field Ctrl+Alt+FIntroduce Constant Ctrl+Alt+CIntroduce Parameter Ctrl+Alt+PReformat Code Ctrl+Alt+L]]></content>
      <categories>
        <category>Python相关</category>
      </categories>
      <tags>
        <tag>快捷键</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MarkDown的原理]]></title>
    <url>%2F2018%2F12%2F26%2FMarkDown%E7%9A%84%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[有没有好奇过，为什么你用了这些简单的标记就可以对文章进行排版和美化？它是怎么做到的？]]></content>
      <categories>
        <category>MarkDown相关</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MarkDown常用语法和快捷键]]></title>
    <url>%2F2018%2F12%2F26%2FMarkDown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95%E5%92%8C%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[记录一些快捷键]]></content>
      <categories>
        <category>MarkDown相关</category>
      </categories>
      <tags>
        <tag>快捷键</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo的结构和原理]]></title>
    <url>%2F2018%2F12%2F26%2FHexo%E7%9A%84%E7%BB%93%E6%9E%84%E5%92%8C%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[名字有点吓人，其实我就是想搞明白Hexo的大致结构是什么，它是怎么运行起来的 :-D我不知道这需要多少专业的前端知识，只求尽量搞懂心中有数就好 Hexo的文件夹结构123456789.├── _config.yml ├── db.json├── node_modules ├── package.json├── public ├── scaffolds ├── source #所有文章文件放在这里└── themes #主题文件夹 Node.js Node.js® is a JavaScript runtime built on Chrome’s V8 JavaScript engine. npm npm is the package manager for JavaScript and the world’s largest software registry. Discover packages of reusable code — and assemble them in powerful new ways. yarn Yarn is a package manager for your code. It allows you to use and share code with other developers from around the world. Yarn does this quickly, securely, and reliably so you don’t ever have to worry. node包]]></content>
      <categories>
        <category>Hexo相关</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自用Chrome插件汇总]]></title>
    <url>%2F2018%2F12%2F25%2F%E8%87%AA%E7%94%A8Chrome%E6%8F%92%E4%BB%B6%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[在这里将自己逛应用商店发现的实用插件安利一下，包括个性化插件以及一些比较专业的工具。Chrome没了插件可不行，毕竟插件才是本体 :) 个性化 Infinity 新标签页 颜值很高的个性化主页。对我来说就是把我常用的几个网站放在上去。当然可以放在书签栏里不过我的书签栏实在太臃肿了，这样体验不是很好。 书签侧边栏 它就是为了拯救我臃肿的书签栏而来的。可隐藏的侧边栏设计特别有趣跟其他的都不一样。缺点就是有时候会误触。 开发者工具日常工具bilibili哔哩哔哩下载助手关于下载网页视频的工具很多，比如硕鼠。不过这个是B站专用的,功能单一用起来也就方便 :) 我用它下载了很多B站大会员专享的高清资源 Tampermonkey+GreasyFork一张图告诉你它们的作用： 感受到它的强大了吧？ Full Page Screen Capture一个截网页全屏的工具。 Chrome没有自带的网页截屏工具（我没找到）不放图了 Google Dictionary (by Google)谷歌出的网页词典插件，用起来很顺手。另外它还可以把查词历史记录下来同步到云端 编码解码Hasher一款可以各种字符串hash值的工具，种类很全偶尔用用 网站开发接口测试工具Restlet Client - REST API Testing颜值很高的一个REST API 测试工具。有评论说 “better than postman“,我觉得还好吧，功能都差不多只不过插件更方便。 取色工具两款取色工具各有千秋吧，感觉差不多ColorPick Eyedropper ColorZilla]]></content>
      <categories>
        <category>杂货铺</category>
      </categories>
      <tags>
        <tag>chrome</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于ss节点费率]]></title>
    <url>%2F2018%2F07%2F07%2F%E5%85%B3%E4%BA%8ESS%E7%9A%84%E8%B4%B9%E7%8E%87%2F</url>
    <content type="text"><![CDATA[以下内容来自客服回复： 我們限制流量的初衷，是爲了防止客戶分享自己的配置信息以及濫用我們的服務。如果您在月底前使用流量超過了 50GB， 系統會自動暫停您的服務。您可以通過工單聯繫我們重置您的流量我們目前也更新了流量統計政策，您的實際可使用流量并不是 50GB ，與您所使用的節點的流量統計倍率有關。服務器詳細的統計倍率請見您的服務器詳情備注，部分服務器流量統計倍率如下：hk1 -&gt; 100%jp1 -&gt; 150%us2 -&gt; 40%us1 -&gt; 1%hk3 -&gt; 20%ali-hk2 -&gt; 150%ali-jp2 -&gt; 120%ali-sg1 -&gt; 120%ult 中轉節點 -&gt; 200%您使用的流量根據您使用的服務器會按照上述倍率統計，如果您需要使用 1GB 流量，使用 hk1 (100%) 的話，流量統計為正常的 1GB , 使用 jp1 (150%) 則會統計為 1.5GB ，使用 us1 (1%) 則衹會統計為 10M 流量計入您的縂使用流量。如果您在月底前使用超过 50GB 流量，我们的系统会自动暂停您的服务。但是您请不要担心，如果您在月底前使用的流量将接近于 50GB 时，请联系我们，我们会手动为您增加流量，确保您的正常使用。 建議您進行大流量的操作時使用低倍率的服務器（如 us2 ）。如果您还有更多疑问，请不要犹豫联系我们谢谢Best regardsFuse MidoriShadowsocks.com Team 也就是说在每个月有50G流量的情况下，使用1.0倍率的节点代表你用1GB流量服务器就扣你1GB，使用1.5倍费率的节点用1GB则扣你1.5GB。依此类推]]></content>
      <categories>
        <category>杂货铺</category>
      </categories>
      <tags>
        <tag>科学上网</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客更新日志]]></title>
    <url>%2F2018%2F07%2F07%2F%E5%8D%9A%E5%AE%A2%E6%9B%B4%E6%96%B0%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[2018年7月7日： 1.增加好站：在线表格生成器 一个用于在线生成各种类型表格的工具，支持LaTex、HTML、Text(就是用加号和短横框起来的表格)、Markdown、MediaWiki 格式用起来很方便 2.增加好站：科学上网（付费） 我一直在用的翻墙工具。客户端使用的是ShadowSocks，节点很多，包括香港美国日本俄罗斯。支持支付宝，入门版年费只要98.74元，合一个月8块钱。每月限流50G，用完则断网，再用则需要联系客服增加流量。个人觉得50G足够刷油管和ins用了。目前我还没有用它下载过大文件，官方是禁止滥用的。 另外每个节点的费率不一样 关于费率的详情见我的文章 3.添加文章：关于ss节点费率 4. 启用了数学公式渲染的选项 2018年7月6日： 添加文章：MIPS常用表格]]></content>
      <tags>
        <tag>博客更新日志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MIPS常用表格]]></title>
    <url>%2F2018%2F07%2F06%2FMIPS%E5%B8%B8%E7%94%A8%E8%A1%A8%E6%A0%BC%2F</url>
    <content type="text"><![CDATA[以下是在学习和做题中经常要用到的MIPS汇编指令表格 R型指令 op rs rt rd shamt funct 6位 5位 5位 5位 5位 6位 I型指令 op rs rt constant or address 6位 5位 5位 16位 MIPS中32个通用寄存器 Name number Usage Reserved on call \$zero 0 constant value =0(恒为0) n.a \$at 1 reserved for assembler n.a. \$v0 ~ \$v1 2~3 values for results(过程调用返回值) no \$a0~\$a3 4~7 Arguments(过程调用参数) 否 \$t0~\$t7 8~15 Temporaries(临时变量) no \$s0~\$s7 16~23 Saved(保存) yes \$t8~\$t9 24~25 more temporaries(其他临时变量) no \$k0~\$k1 26~27 reserved for kernel(为OS保留) 不适用 \$gp 28 global pointer(全局指针) yes \$sp 29 stack pointer (栈指针) yes \$fp 30 frame pointer (帧指针) 是 \$ra 31 return address (过程调用返回地址) 是 算术运算指令 Instruction Example Meaning Comments add add \$1,\$2,\$3 \$1 = \$2 + \$3 3 operands; excep. possible subtract sub \$1,\$2,\$3 \$1 = \$2 – \$3 3 operands; excep. possible add immed. addi \$1,\$2,100 \$1 = \$2 + 100 + constant; excep. Possible multiply mult \$2,\$3 Hi, Lo = \$2×\$3 64-bit signed product divide div \$2,\$3 Lo = \$2 ÷ \$3 Hi = \$2 mod \$3 Lo = quotient,Hi = remainder 逻辑运算指令 Instruction Example Meaning Comments and and \$1,\$2,\$3 \$1 = \$2 &amp; \$3 Logical AND or immed. ori \$1,\$2,20 \$1 = \$2 &#124; 20 Bitwise-OR of constant xor xor \$1,\$2,\$3 \$1 = \$2∧\$3 Logical XOR nor nor \$1,\$2,\$3 \$1 = ~(\$2 &#124; \$3) Logical NOR 数据传输指令 Instruction Example Meaning Comments sw sw \$3, 500(\$4) \$3 →(\$4+ 500) Store word sh sh \$3, 502(\$2) Low Half of \$3 →(\$2+ 502) Store half sb sb \$2, 41(\$3) LQ of \$2 →(\$3+ 41) Store byte lw lw \$1, -30(\$2) (\$2-30) → \$1 Load word lh lh \$1, 40(\$3) (\$3+ 40) → LH of \$1 Load half lb lb \$1, 40(\$3) (\$3+ 40) → LQ of \$1 Load byte 条件分支指令 Instruction Example Meaning Comments beq beq \$1,\$2,100 if (\$1＝\$2) go to PC+4+100 branch on equal bne bne \$1,\$2,100 if (\$1 != \$2) go to PC+4+100 branch on not eq. slt slt \$1,\$2,\$3 if (\$2 &lt; \$3) \$1=1; else \$1=0 set on less than slti slti \$1,\$2,100 if (\$2 &lt; 100) \$1=1; else \$1=0 set less than imm. 无条件跳转指令 Instruction Example Meaning Comments j j 10000 go to 10000 jump jal jal 10000 \$31 = PC + 4; go to 10000 for procedure call jump and link jr jr \$31 go to \$31 for switch, procedure return jump register]]></content>
      <tags>
        <tag>MIPS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《编译原理中子集法的教学探讨》——蒋凌云-学习笔记]]></title>
    <url>%2F2018%2F05%2F21%2F%E3%80%8A%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E4%B8%AD%E5%AD%90%E9%9B%86%E6%B3%95%E7%9A%84%E6%95%99%E5%AD%A6%E6%8E%A2%E8%AE%A8%E3%80%8B%E2%80%94%E2%80%94%E8%92%8B%E5%87%8C%E4%BA%91-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[用识别的观点看子集法的定义设计子集法的目的是将转换系统构造出确定有穷自动机（DFA），所以可以从识别的观点理解子集法。对状态子 集I的ε-闭包和子集Ia进行重新定义。图1为正规式e＝(a｜ b)*(aa｜bb)(a｜b)*对应的转换系统。以图1为例来说明重 新定义的状态子集I的ε-闭包和子集Ia。 状态子集I的ε-闭包重新定义为“从状态子集I中的每个状态开始识别ε所达到的状态的全体”。因为ε＝εε＝ε…ε＝ε，所以从某个状态出发识 别一个ε和识别若干个ε，其本质是相同的，都是识别一个ε。例如，假设I＝{S}，图1中从S出发识别一个ε到达 5状态，即M(S,ε)＝5；从S出发识别2个ε到达1状态，即 M(S,εε)＝M(M(S,ε),ε)＝M(5,ε)＝1。而ε是一个空符号串，显然有M(S,ε)＝S。那么从S状态出发识别ε所到达 的状态全体为{S,5,1}。 子集Ia重新定义为“从状态子集I中的每个状态开始识别a符号所达到的状态的全体”。因为a＝εa＝aε＝ε…εaε…ε＝a，所以从某个状态出发识别一个a符号和识别ε…εaε…ε，其本质是相同的，都是识别一个a符号。例如，假设I＝{S,5,1}，首先从S出发识别一个εa到达5状态，即M(S,εa)＝M(M(S,ε),a)＝(5,a)＝5；从S出发识别εaε到达1状态，即M(S,εaε)＝M(M(S,ε),aε)＝M(5,aε)＝M(M(5,a),ε)＝M(5,ε)＝1，那么从S状态出发识别a所到达的状态全体为{5,1}。同理，从5状态出发识别a所到达的状态全体为{5,1}，从1状态出发识别a所到达的状态全体为{3}，综合得到 Ia＝{5,3,1}。 利用重新定义后的状态子集I的ε-闭包和子集Ia进行教学，学生只需要利用原来自动机状态转换图识别符号串的知识就可以求出子集I的ε-闭包和子集Ia，使原来抽象的定义变得更可操作，更容易掌握和理解。 利用子集法解决“从NFA转换到DFA”问题将转换系统构造出确定有穷自动机（DFA），其本质是将一个带空转的非确定的有穷自动机（NFA）进行确定化。因此，利用重新定义后的状态子集I的ε-闭包和子集Ia进行教学，可以将子集法推广到解决“从NFA转换到DFA”问题。 I Ia Ib K 0 1 {1} {0} {Ф} A B Ф {0} {0,1} {1} B C A {0,1} {0,1} {1} C C A 图3 子集法转换矩阵 例如，图2为一(NFA)M＝({0,1},{a,b},M,{1},{0})的状态转换图，子集法的第一行第一列为初始状态集{1}中的每个状态开始识别ε所达到的状态的全体，因NFA的状态转换图中没有ε，所以第一行第一列就为初始状态集{1}。第一行Ia和Ib分别是从1状态开始识别a符号与b符号所达到的状态的全体。其余转换参见图3。转换后的(DFA)M＝({A,B,C},{a,b},M,{1},{0})，M(A,0)＝B，M(B,0)＝C，M(B,1)＝A，M(C,0)＝C，M(C,1)＝A。]]></content>
      <tags>
        <tag>编译原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于Unity3D中的协程-Coroutine]]></title>
    <url>%2F2018%2F05%2F10%2F%E5%85%B3%E4%BA%8EUnity3D%E4%B8%AD%E7%9A%84%E5%8D%8F%E7%A8%8B-Coroutine%2F</url>
    <content type="text"><![CDATA[这学期（大三 下）学Unity3D游戏开发。然而我对U3D可以实现的那些华丽效果并不感兴趣······其实吧，也不是不感兴趣，而是实在没有艺术细胞，不知道怎么弄才能好看。所以我希（zhi）望(neng)多学习U3D的脚本编程技术。我大一开始就学的C#，所以一直以来没有遇到什么不理解的地方。可是我发现“协程（Coroutine,/kəru:’ti:n/）” 这个好东西，在我之前学习C#个过程中并没有遇见。这次就好好总结一下它的原理和用法。 占坑]]></content>
      <tags>
        <tag>Unity3D</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[练习项目：区块链在医院的应用]]></title>
    <url>%2F2018%2F05%2F07%2F%E7%BB%83%E4%B9%A0%E9%A1%B9%E7%9B%AE%EF%BC%9A%E5%8C%BA%E5%9D%97%E9%93%BE%E5%9C%A8%E5%8C%BB%E9%99%A2%E7%9A%84%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[概述首先声明：经过对项目的分析以及对区块链特性的了解，我认为：医院私有区块链是没有意义的。区块链的私有化，会导致区块链丧失其“去中心化”的特征，也就意味着第三方无法承认该链所包含的信息。 架构 设计 P2P服务模块 挖矿模块 P2P服务模块P2P服务模块负责与其他节点建立连接。程序运行后常驻内存，主要负责监听其他节点的广播信息，同时挖矿模块也通过它来宣布自己的挖矿成果。 节点列表：用来存放网络环境中所有节点的IP和端口号 监听线程：while(true) 监听所有节点广播的消息 文件接收线程：负责文件的接收和缓冲，文件按流接收 TCP协议发送文件的时候是发送的字节流，那么它是无法知道一个文件是否已经传送完了的。按照老师的设想，他打算在医院服务器向数据库传输文件的时候，通过某种方式获取到它。实现所谓的，上传一个处理一个。 挖矿模块想不到什么好名字，就叫挖矿模块吧。挖矿模块包括 挖矿线程（SM3运算） 区块有效性验证：当P2P服务模块监听到其他节点的区块广播后，立即暂停挖矿线程，并对传入的模块进行认证 文件队列 当文件队列为空的时候 区块结构区块头 12345678910&#123; "hash": "00000000d1145790a8694403d4063f323d499e655c83426834d4ce2f8dd4a2ee", "ver": 1, "prev_block": "000000002a22cfee1f2c846adbd12b3e183d4f97683f85dad08a79780a84bd55", "mrkl_root": "7dac2c5666815c17a3b36427de37bb9d2e2c5ccec3f8633eb91a4205cb4c10ff", "time": 1231731025, "bits": 486604799, "nonce": 1889418792 &#125; 区块体区块体中存放文件的Hash值，这个值可以使用任何散列函数得出，当然也可以用SM3。区块体中存放多少个文件的Hash值以及存放信息的具体结构设计暂未确定。另外，老师的意见是不保留区块体，所有节点只保留区块头以节省空间。我认为保留区块体可以使区块链与数据库的对应关系的建立变得简单。私有链的一个特点就是用户量小，产生的信息也相对较少。所以保留hash值以及其他辅助信息，并不会太占用空间。 技术疑难 区块链与数据库文件对应关系的建立 P2P网络发现。即如何实现机房内节点在启动时可以互相发现？ TCP传输大文件的处理 当传输文件较多，上传的速度大于所有节点的处理速度时，是要求服务器等待 挖矿原理 类型 名称 说明 int32_t nVersion 版本号，4字节 uint256 hashPrevBlock 前一个区块的区块头hash值，32字节 uint256 hashMerkleRoot 包含进本区块的所有交易构造的Merkle树根，32字节 uint32_t nTime Unix时间戳，4字节 uint32_t nBits 记录本区块难度，4字节 uint32_t nNonce 随机数，4字节 如上比特币每一次挖矿就是对这80个字节连续进行两次SHA256运算(SHA256D)，运算结果是固定的32字节(二进制256位)。 注:SHA256D即， SHA256D(x) =SHA256(SHA256(x)) 以上3个字段可以理解为是固定的，对于每个矿工来说都一样。矿工可以自由调整的地方是剩下的3个字段，nNonce，提供2^32种可能取值nTime，其实本字段能提供的值空间非常有限，因为合理的区块时间有一个范围，这个范围是根据前一个区块时间来定，比前一个区块时间太早或者太超前都会被其他节点拒绝。值得一提的是，后一个区块的区块时间略早于前一个区块时间，这是允许的。一般来说，矿工会直接使用机器当前时间戳。hashMerkleRoot，理论上提供2^256种可能，本字段的变化来自于对包含进区块的交易进行增删，或改变顺序，或者修改Coinbase交易的输入字段。 以上图文来自巴比特 我所要实现的这个区块链所使用的Hash函数，按照老师的要求，我们使用国密算法SM3，对80个字节进行两次SHA256运算大概也可以替换为对这80个字节进行两次SM3运算，即SM3(SM3(x)) SM3国密算法SM3是一个散列算法，在保障安全的前提下，综合性能指标于SHA-256同等条件下相当。SM3密码杂凑算法结构上与SHA-256相似，并且链接变量长度，消息分组大小和步数均与SHA-256相同。我们使用它来计算文件的Hash值 关于SM3的性能我想知道SM3对文件进行Hash的性能，于是生成了不同大小的文件进行多次测试，测试结果如下： 操作系统：windows10 CPU：4核 2.5GHz主频 内存：12GB 文件大小 耗时 （包括硬盘读取文件的时间） 1KB 0.004s 4KB 0.004s 1MB 0.026s 10MB 0.367s 20MB 0.723s 100MB 3.466s 200MB 6.853s 500MB 17.082s 1GB 34.894s 2GB 69.084s 根据测试结果我们认为，计算Hash值消耗的时间与文件的大小是成正比的。并且在当前测试环境下，SM3不适合用来计算大小在20MB以上的文件的Hash值。因为超过20MB之后，运算单个文件的时间会达到秒级，系统会有明显的等待。这样会降低区块链的运行效率。如果需要进一步缩短耗时，那么可以重点考虑使用某种算法缩短大文件的读取时间 注：再Windows下生成指定大小文件的命令为：fsutil file createnew (文件名) &lt;字节数&gt; 1fsutil file createnew 1KB.testfile 1024 另注: 以上的测试过程是一个小白随便弄的，下面的测试结果来自王小云院士发表的期刊文章 软硬件实现性能（专业） 通过专业的评测可以知道，选择SM3并没有什么不妥。因为SM3跟SHA-256难分伯仲。 区块链安全问题首先我们知道比特币区块链的安全问题有 “双花” “51%攻击” 当然上述问题再比特币区块链中都已经解决。那么医院私有区块链是否也存在这样的问题？ 双花双花的原理暂略。双花可以成功的关键在于交易的收钱方在交易没有被永久确认的情况下把自己的披萨给付钱方。双花必然不会成功，因为比特币的协议已经限制死，到时候两笔交易必然只能真正完成一笔。另外一笔会因为处于短链而被丢弃。造成收钱方在没有收到比特币的情况下就完成了交易本身，比如买一个披萨。对于卖披萨的人来说，就是亏损了。但是区块链并没有影响所以医院区块链也是不存在这个问题的。 51%攻击它是指一个人或者一个组织掌握了整个系统百分之51以上的算力，从而可以修改自己的交易记录等等。这对比特币来说几乎不可能发生，但是对于这么小型的一个区块链来说，还是很有可能的。所以着就关系到医院区块链是否要面向社会招募矿工了。一旦面向社会开放，而且规模又不够时，那么将大不足与抵御51%攻击。如果是封闭的局域网环境，并且网络安全做的够好，就可以避免来自外界的攻击。只需要做好医院内部的防范即可。并且，不对外开放，就意味着任何人替医院挖矿都是无利可图的，医院自负电费。 已经写入的信息是否可更改理论上当然可以更改。想要修改某一个记录的话，只要把医院百分之51以上的节点上的区块链信息做相应修改。然后把机房停电，让全部节点重启。这样，节点在初始化的时候会从其他节点获取最新的区块链信息。由于 51%的节点存放的都是篡改过的信息。那么剩余的49%的节点就会放弃自己存储的区块链信息而去选择相信另外的51%的节点。等全部节点初始化完成，那么一条崭新的链就出现了。是不是很简单？ 攻击的动机再来讨论一下攻击的动机。有动机对区块链进行修改的可能是开错药的医生，又或者科室之间合作的时候出现失误的一方。比如，A科室要求B部门提供某些数据，但是B部门发送的数据出错，导致A科室的治疗出现事故，此时需要追责，那么B部门就有了对区块链更改的动机。即使有动机，只要他们无法干预机房节点的运行，那么他们就基本不可能去修改。 总结在区块链规模不大的时候，最好使其运行在封闭的局域网环境下。这样既可以规避风险，又降低了开发难度。 共识机制占坑 工作量证明工作量证明是为了加大区块生成的难度，让单个节点不能连续的产生区块。因此节点之间是有竞争关系的 区块链的持久化我决定采用JSON格式来保存本地的区块链信息，它的优点很明显，结构清晰。因为有现成的库可以使用，所以特别方便。]]></content>
      <tags>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VSCode插件开发]]></title>
    <url>%2F2018%2F05%2F05%2FVSCode%E6%8F%92%E4%BB%B6%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[摘要： 想以后研究一下VSCode的插件开发，所以就决定把官方文档翻译一下。当然了，大部分是机器翻译，我只是把翻译的奇怪的地方和不通顺的地方稍微改改，不影响理解就成。🤣 概貌如果你有兴趣扩展VS Code，你是在正确的地方。 在这里，我们提供VS Code扩展性文档的概要以及如何快速构建您的第一个VS Code扩展。 如果您对我们的VS Code的扩展性设计方法感到好奇，可以在这里阅读。 如果您只想使用现有的扩展，请参阅Extension Marketplace主题，我们将向您展示如何从VS Code Marketplace中查找和安装扩展。 所有VS代码扩展共享贡献（注册），激活（加载）和访问VS代码扩展性API的通用模型。 然而，VS代码扩展有两种特殊的风格，语言服务器和调试器，它们都有自己的附加协议，并在文档的各个部分中进行了介绍。 扩展 - 基础构建块 语言服务器 - 用于高成本的IO或CPU密集型任务 调试器 - 通过调试适配器连接外部调试器 Extensions激活时所有扩展在我们的共享扩展宿主进程中运行。 这种扩展的单独流程可确保VS代码始终保持响应。 扩展包括支持： 激活 - 在检测到特定文件类型时，特定文件存在时，或通过命令选项板或组合键选择命令时加载扩展名 编辑 - 处理编辑的内容 - 阅读和操作文本，利用选择（s） 工作区 - 访问打开的编辑器，状态栏，信息消息等等 事件 - 连接到编辑器生命周期事件，例如：打开，关闭，更改等 演变编辑 - 为丰富的语言支持创建提供商，包括IntelliSense，Peek，悬停，诊断等等 我们有两个端到端的教程，让您了解扩展基础知识： Hello World - 生成基本扩展名，理解扩展的文件夹结构，扩展名清单，了解激活如何工作，运行和调试扩展并在本地安装。 字数 - 根据特定文件类型激活，更新状态栏，响应文本编辑器中的更改，并在离开文件时处置扩展名。 扩展性原则和模式也很有用，它描述了整个扩展性API使用的共享编程模式。 Language Servers语言服务器可让您为您的扩展程序创建专用流程。 当您的扩展程序运行高成本的CPU或IO密集型任务时，这可能会延缓其他扩展，这对于您的扩展是一个有用的设计选择。 这对于在工作区中的所有文件中工作的任务是很常见的，例如 (linters or static analysis suites)棉绒或静态分析套件详细了解语言服务器。 Debug AdapterVS Code实现了一个通用的调试器UI，并依赖于调试器扩展和所谓的“调试适配器”来将调试用户界面连接到真实的调试器或运行时。 调试适配器是一个专用进程，通过VS代码调试协议与VS代码进行通信，并且可以用任何语言实现。 了解更多关于创建调试器扩展的信息。 查看VS代码扩展的最简单方法是通过扩展市场。 你可以浏览有用的扩展，安装它们来试用它们，并了解如何为自己的开发场景扩展VS Code。 Language Extension Guidelines语言扩展指南主题可以帮助您决定您的扩展支持哪些语言功能。 它显示了VS Code中提供的各种语言功能（例如，代码建议和操作，格式设置，重命名），以及如何通过语言服务器协议或直接使用扩展API从您的扩展实现它们。 Themes, Snippets, and Colorizers您可以通过语法突出显示，有用的片段和精心设计的颜色主题等简单的东西，为编程语言提供出色的编辑体验。 TextMate自定义文件提供了这种支持，VS Code允许您轻松打包和重用这些文件，以便您可以在扩展中直接使用.tmTheme，.tmSnippets和.tmLanguage文件。 我们的主题，片段和着色器主题向您展示了如何包含TextMate文件，并就如何创建自己的主题，片段和语言着色器提供指导。 Writing an Extension有一个Yeoman扩展生成器，可以非常容易地创建简单的扩展项目。 这些对于开始很有用，您还可以找到现有的扩展示例。 扩展可以用TypeScript或JavaScript编写。 VS Code提供了一流的扩展开发经验，您可以在VS Code本身内开发，构建，运行，测试和调试所有内容。 Testing Extensions我们也非常支持为您的扩展程序编写和运行测试。 您可以轻松创建调用VS Code API的集成测试，并在运行的VS Code实例中测试您的代码。 Extension IdeasVS Code功能的许多伟大的社区理念更好地实现为扩展而不是核心产品的一部分。 这样用户就可以通过安装正确的扩展集来轻松选择他们想要的功能。 VS Code团队将可能的扩展跟踪为vscode存储库中标记为 * extension-candidate的GitHub问题。 如果你正在寻找一个伟大的扩展来构建，看看 * 扩展候选问题。 Next StepsYo Code - Extension GeneratorPrerequisitesInstall the GeneratorRun Yo CodeGenerator OptionsYour extensions folderNext Steps示例 - Hello World你的第一个插件本文档将指导您创建您的第一个VS代码扩展（“Hello World”）并解释基本的VS代码扩展性概念。 在本演练中，您将向VS Code添加一个新命令，该命令将显示一个简单的“Hello World”消息。 稍后在演练中，您将与VS Code编辑器交互并查询用户当前选定的文本。 先决条件（Prerequisites）您需要安装Node.js并在您的$ PATH中可用。 Node.js包含npm，即Node.js包管理器，它将用于安装扩展生成器。 生成一个新的扩展将自己的功能添加到VS Code的最简单方法是通过添加命令。 一个命令注册一个回调函数，该函数可以从命令面板或键盘绑定中调用。 我们已经写了一个 Yeoman generator 来帮助你开始。 安装Yeoman和Yeoman VS代码扩展生成器并搭建一个新的扩展： 12npm install -g yo generator-codeyo code 对于hello world扩展，您可以创建TypeScript扩展或JavaScript。 对于这个例子，我们选择一个TypeScript扩展。 Running your extension 启动VS代码，选择文件&gt;打开文件夹，然后选择您生成的文件夹。 按F5或单击调试图标，然后单击开始。 VS Code的新实例将以特殊模式（扩展开发主机）启动，并且此新实例现在知道您的扩展。 按下Ctrl + Shift + P并运行名为Hello World的命令。 恭喜！ 你刚刚创建并执行了你的第一个VS Code命令！ 扩展的结构After running, the generated extension should have the following structure: 123456789101112131415161718192021222324252627.├── .gitignore├── .vscode // VS Code integration│ ├── launch.json│ ├── settings.json│ └── tasks.json├── .vscodeignore // files ignored when publishing extension├── README.md├── src│ └── extension.ts // the source of the extension entry point├── test // test folder│ ├── extension.test.ts // extension.test.js, in case of JavaScript extension│ └── index.ts // index.js, in case of JavaScript extension├── node_modules│ ├── vscode // include vscode type definition file for extension development│ └── typescript // compiler for typescript (TypeScript only)├── out // compilation output (TypeScript only)│ ├── extension.js // the extension entry point│ ├── extension.js.map│ └── test│ ├── extension.test.js│ ├── extension.test.js.map│ ├── index.js│ └── index.js.map├── package.json // extension&apos;s manifest├── tsconfig.json // jsconfig.json, in case of JavaScript extension└── vsc-extension-quickstart.md // extension development quick start 让我们通过所有这些文件的目的，并解释他们做了什么： 扩展名清单：package.json 每个VS代码扩展必须有一个描述它及其功能的package.json文件。 VS代码在启动过程中读取此文件，并立即响应每个文件。 请阅读package.json扩展清单参考。 有关package.json贡献点的更多信息。 示例TYPESCRIPT EXTENSION MANIFEST1234567891011121314151617181920212223242526272829303132333435&#123; &quot;name&quot;: &quot;myFirstExtension&quot;, &quot;description&quot;: &quot;&quot;, &quot;version&quot;: &quot;0.0.1&quot;, &quot;publisher&quot;: &quot;&quot;, &quot;engines&quot;: &#123; &quot;vscode&quot;: &quot;^1.5.0&quot; &#125;, &quot;categories&quot;: [ &quot;Other&quot; ], &quot;activationEvents&quot;: [ &quot;onCommand:extension.sayHello&quot; ], &quot;main&quot;: &quot;./out/extension&quot;, &quot;contributes&quot;: &#123; &quot;commands&quot;: [&#123; &quot;command&quot;: &quot;extension.sayHello&quot;, &quot;title&quot;: &quot;Hello World&quot; &#125;] &#125;, &quot;scripts&quot;: &#123; &quot;vscode:prepublish&quot;: &quot;tsc -p ./&quot;, &quot;compile&quot;: &quot;tsc -watch -p ./&quot;, &quot;postinstall&quot;: &quot;node ./node_modules/vscode/bin/install&quot;, &quot;test&quot;: &quot;node ./node_modules/vscode/bin/test&quot; &#125;, &quot;devDependencies&quot;: &#123; &quot;typescript&quot;: &quot;^2.0.3&quot;, &quot;vscode&quot;: &quot;^1.5.0&quot;, &quot;mocha&quot;: &quot;^2.3.3&quot;, &quot;@types/node&quot;: &quot;^6.0.40&quot;, &quot;@types/mocha&quot;: &quot;^2.2.32&quot; &#125;&#125; Note: JavaScript扩展不需要脚本字段，因为不需要编译。 这个特定的package.json描述了一个扩展： 使用标签“Hello world”为Command Palette（Ctrl + Shift + P）作出贡献，该标签将调用命令“extension.sayHello”。 请求在调用“extension.sayHello”命令时加载（activationEvents）。 将其主要JavaScript代码放在名为“./out/extension.js”的文件中。 Note: VS代码不会在启动时急切地加载扩展的代码。 扩展必须通过activationEvents属性在什么条件下激活（加载）来描述。 生成的代码生成的扩展的代码位于extension.ts（或扩展名为JavaScript的扩展名的情况下）： 123456789101112131415161718192021222324// The module 'vscode' contains the VS Code extensibility API// Import the module and reference it with the alias vscode in your code belowimport * as vscode from 'vscode';// this method is called when your extension is activated// your extension is activated the very first time the command is executedexport function activate(context: vscode.ExtensionContext) &#123; // Use the console to output diagnostic information (console.log) and errors (console.error) // This line of code will only be executed once when your extension is activated console.log('Congratulations, your extension "my-first-extension" is now active!'); // The command has been defined in the package.json file // Now provide the implementation of the command with registerCommand // The commandId parameter must match the command field in package.json let disposable = vscode.commands.registerCommand('extension.sayHello', () =&gt; &#123; // The code you place here will be executed every time your command is executed // Display a message box to the user vscode.window.showInformationMessage('Hello World!'); &#125;); context.subscriptions.push(disposable);&#125; 每个扩展应从其主文件中导出一个名为activate（）的函数，当发生package.json文件中描述的任何激活事件时，该VS代码将只调用一次。 如果扩展使用OS资源（例如衍生进程），则扩展可以从其主文件中导出一个名为deactivate（）的函数，在该函数中它可以执行清理工作，VS代码将在关闭时调用该函数。 这个特定的扩展名导入了vscode API，然后注册一个命令，将命令“extension.sayHello”调用时关联一个函数。 该命令的实现在VS Code中显示“Hello world”消息。 注：package.json的contribution部分向Command Palette添加一个条目。 extension.ts / .js中的代码定义了“extension.sayHello”的实现。 另 注：对于TypeScript扩展，生成的文件out / extension.js将在运行时加载并由VS代码执行。 杂项文件(Miscellaneous files) .vscode / launch.json定义在扩展开发模式下启动VS代码。 它还使用preLaunchTask指向运行TypeScript编译器的.vscode / tasks.json中定义的任务。 .vscode / settings.json默认排除out文件夹。 您可以修改要隐藏的文件类型。 .gitignore - 告诉Git版本控制哪些模式要忽略。 .vscodeignore - 告知打包工具在发布扩展时忽略哪些文件。 README.md - 描述VS Code用户扩展的自述文件。 vsc-extension-quickstart.md - 快速入门指南。 test / extension.test.ts - 您可以将您的扩展单元测试放在这里，并针对VS Code API运行测试（请参阅测试您的扩展） 扩展激活 现在扩展中包含的文件的角色已经明确，下面是您的扩展如何激活： 扩展开发实例发现扩展并读取它的package.json文件。 稍后当您按Ctrl + Shift + P时： 注册的命令显示在命令面板中。 在这个列表中，现在有一个在package.json中定义的条目“Hello world”。 选择“Hello world”命令时： 命令“extension.sayHello”被调用： 激活事件“onCommand：extension.sayHello”被创建。 所有在激活事件中列出激活事件的扩展都会被激活。 ./out/extension.js中的文件被加载到JavaScript VM中。 VS代码查找导出的函数激活并调用它。 命令“extension.sayHello”已注册，现在定义了其实现。 调用命令“extension.sayHello”实现函数。 命令实现显示“Hello World”消息。 调试你的拓展例如，在注册的命令中设置断点，然后在Extension Development VS代码实例中运行“Hello world”命令。 注：对于TypeScript扩展，即使VS代码加载并执行out / extension.js，由于生成的源映射out / extension.js.map和VS Code的源代码映射器调试器支持，您实际上可以调试原始的TypeScript代码。提示：调试控制台将显示您登录到控制台的所有消息。 To learn more about the extension development environment. 一个简单的改变在extension.ts（或extension.js，在JavaScript扩展中），请尝试替换extension.sayHello命令实现以显示在编辑器中选择的字符数：1234567891011121314let disposable = vscode.commands.registerCommand('extension.sayHello', () =&gt; &#123; // The code you place here will be executed every time your command is executed let editor = vscode.window.activeTextEditor; if (!editor) &#123; return; // No open text editor &#125; let selection = editor.selection; let text = editor.document.getText(selection); // Display a message box to the user vscode.window.showInformationMessage('Selected characters: ' + text.length);&#125;); 提示：一旦您对扩展源代码进行更改，您需要重新启动VS Code的Extension Development Host实例。 您可以通过在Extension Development Host实例中使用Ctrl + R（macOS：Cmd + R）或通过单击主VS代码实例顶部的重启按钮来实现。 创建一个文件（文件&gt;新建文件），输入一些文本并选择它。 当您运行Hello World命令时，您现在应该看到所选字符的计数。 在本地安装您的扩展到目前为止，您所编写的扩展只在VS Code的一个特殊实例中运行，即扩展开发实例。 要让您的扩展程序在VS代码的所有实例中运行，您需要将其复制到本地扩展文件夹下的新文件夹中： Windows: %USERPROFILE%.vscode\extensions macOS/Linux: $HOME/.vscode/extensions 发布您的扩展阅读有关如何共享扩展的信息。 Next Steps在本演练中，我们看到了一个非常简单的扩展。 有关更详细的示例，请参阅字数统计示例，其中显示了如何定位特定语言（Markdown）并收听编辑器的文档更改事件。 如果您想更详细地阅读扩展API，请尝试以下主题： 扩展API概述 - 了解完整的VS代码扩展模型。 API原则和模式 - VS代码可扩展性基于几个指导原则和模式。 贡献点 - 关于各种VS Code贡献点的细节。 激活事件 - VS代码激活事件参考 其他扩展示例 - 查看我们的示例扩展项目列表。 Example - Word Count原文链接https://code.visualstudio.com/docs/extensions/example-word-count OverviewRun the ExtensionUpdate the Status BarSubscribing to EventsCustomizing the Status BarDisposing Extension ResourcesInstalling your Extension LocallyPublishing your ExtensionNext StepsExample - Language Server原文链接 https://code.visualstudio.com/docs/extensions/example-language-server Implement your own Language ServerExplaining the ‘Client’Explaining the ‘Server’Adding a Simple ValidationDebugging both Client and ServerUsing Configuration Settings in the ServerAdding additional Language FeaturesAdditional Language Server featuresIncremental Text Document SynchronizationNext StepsExample - Debug Adapter原文链接 The Mock Debug ExtensionDevelopment Setup for Mock DebugAnatomy of the package.json of a Debug ExtensionUsing a DebugConfigurationProviderPublishing your Debug AdapterAlternative approach to develop a Debug Extension]]></content>
      <categories>
        <category>VSCode相关</category>
      </categories>
      <tags>
        <tag>翻译</tag>
        <tag>VSCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Text Buffer Reimplementation]]></title>
    <url>%2F2018%2F05%2F05%2FText-Buffer-Reimplementation%2F</url>
    <content type="text"><![CDATA[Visual Studio Code 1.21版本包含一个全新的文本缓冲区实现，它在速度和内存使用方面性能更高。在这篇博文中，我想讲述一下我们如何选择和设计导致这些改进的数据结构和算法的故事。关于JavaScript程序的性能讨论通常涉及关于在本机代码中应该实现多少的讨论。对于VS代码文本缓冲区，这些讨论是在一年多前开始的。在深入探索过程中，我们发现文本缓冲区的C ++实现可以节省大量的内存，但是我们没有看到我们期望的性能增强。在自定义本地表示和V8的字符串之间转换字符串代价很高，在我们的情况下，会降低在C ++中实现文本缓冲操作所带来的性能。我们将在这篇文章结尾详细讨论这一点。 不是原生的，我们必须找到改进JavaScript / TypeScript代码的方法。像Vyacheslav Egorov这样的激动人心的博客文章展示了将JavaScript引擎推向极限并尽可能多地表现出性能的方法。即使没有低级别的引擎技巧，通过使用更合适的数据结构和更快的算法，仍然可以将速度提高一个或多个数量级。 Previous text buffer data structure编辑的心理模型(mental model)是基于行的。开发人员逐行读写源代码，编译器提供基于行/列的诊断，堆栈跟踪包含行号，标记化引擎逐行运行等。虽然简单，但支持VS代码的文本缓冲区实现并没有太大改变，因为第一天我们开始了摩纳哥项目。我们使用了一系列线条，并且它工作得很好，因为典型的文本文档相对较小。当用户输入时，我们找到要在数组中修改的行并将其替换。插入新行时，我们将新的行对象拼接到行数组中，JavaScript引擎将为我们完成繁重的工作。 但是，我们不断收到有关打开某些文件会导致VS代码中出现内存不足的报告。例如，一个用户无法打开一个35 MB的文件。根本原因是该文件的行数太多，为1,370万。我们将为每行和每个使用大约40-60个字节的对象创建一个ModelLine对象，因此行数组使用大约600MB内存来存储文档。这大约是最初文件大小的20倍！ 线阵列表示的另一个问题是打开文件的速度。为了构建线条数组，我们必须通过换行符分割内容，以便每行获得一个字符串对象。拆分本身会伤害你在基准测试中会看到的性能。 Finding a new text buffer implementation旧的线阵列表示可能需要很长时间才能创建并消耗大量内存，但它可以快速查找线路。 在完美的世界中，我们只会存储文件的文本并且不会存储额外的元数据。 因此，我们开始寻找需要较少元数据的数据结构。 在查看了各种数据结构之后，我发现该片断表可能是一个很好的候选者。 Avoiding too much meta-data by using a piece tablePiece table是一种数据结构，用于表示文本文档（TypeScript中的源代码）上的一系列编辑： 12345678910111213141516class PieceTable &#123; original: string; // original contents added: string; // user added contents nodes: Node[];&#125;class Node &#123; type: NodeType; start: number; length: number;&#125;enum NodeType &#123; Original, Added&#125; 文件最初加载后，该片段表在原始字段中包含整个文件内容。 添加的字段为空。 有一个NodeType.Original类型的单个节点。 当用户在文件末尾键入内容时，我们将新内容添加到添加的字段中，并且我们将在节点列表的末尾插入一个类型为NodeType.Added的新节点。 同样，当用户在节点中间进行编辑时，我们会根据需要拆分该节点并插入新节点。 下面的动画展示了如何在一个表格结构中逐行访问文档。 它有两个缓冲区（原始和添加）和三个节点（这是由原始内容中间插入引起的）。]]></content>
      <tags>
        <tag>翻译</tag>
        <tag>VSCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bing-powered settings search in VS Code]]></title>
    <url>%2F2018%2F05%2F05%2FBing-powered-settings-search-in-VS-Code%2F</url>
    <content type="text"><![CDATA[April 25, 2018 by Rob Lourens @roblourens and Ankith Karat ankar@microsoft.com 在VS Code中找到特定设置有没有困难？ 你不是一个人。 纵观常见的GitHub问题，我们已经完成的StackOverflow问题，推文和用户研究，我们看到许多用户在查找设置时遇到问题。 这毫不奇怪，因为VS Code包括超过400个开箱即用的设置，并且安装了扩展程序，许多用户可以拥有更多的设置。 如果您包含典型的用户错误（如错别字和挑选正确的搜索条件的挑战），用户就很难。 几个月前，我们开始与Bing团队谈论他们是否可以将他们的搜索专长应用于我们的问题。 两个月前，我们发布了结果 - 由Bing提供支持的智能设置搜索体验。 How it works经过一段时间的讨论和原型设计之后，我们决定安排Bing团队运行设置搜索服务，以便为用户在VS Code设置编辑器中搜索的查询提供智能模糊设置匹配。 将Bing的自然语言搜索功能整合到VS Code中证明具有挑战性。 为了在网络上搜索文档，Bing考虑了数千个与页面相似度，点击数据，用户行为数据等有关的信号。但是我们没有这种丰富的元数据可用于我们的设置 - 只是每个简要的名称和说明 一。 因此，Bing团队将定制服务和Bing的基本搜索功能结合在一起，创建了一个适合我们搜索场景的系统。 以下是该系统的高级概述：我们来看看每个部分。 这个系统基本上有两个方面 - 收集设置细节并将其编入索引，并在线提供结果。 第一部分由服务服务实施。 它负责创建包含VS代码本身和扩展的丰富索引。 由于我们希望查询响应时间尽可能短，因此我们在进行设置时尽可能多地完成工作，以减少处理查询时所要做的工作。 Bing Ingestion Service收集VS代码和扩展设置数据 在每次构建期间，VS代码将以所有配置写入JSON文件的模式启动。 我们必须实际启动VS Code，因为我们无法静态确定所有配置元数据。 该文件包含每个设置的几条信息 - 名称，说明，类型，默认值以及“枚举”类型设置，有效值列表及其说明。 然后，我们将文件上传到Azure存储。 如果你好奇，你可以在这里看到一个最近的例子：https://ticino.blob.core.windows.net/configuration/123000832/c1cd4378…/configuration.json 123000832是一个唯一的内部版本号，根据产品版本加上自上一版本以来的Git提交数量计算得出。 c1cd4378 …是构建版本的Git commit id。提契诺，你们的一些死忠粉丝可能记得，是我们最初的短命代号。 必应的轮询服务监视Azure存储容器，注意到一个新的版本，并通知摄取服务。同时，Bing不断地抓取VS Code扩展市场，等待扩展更新和新扩展。当找到它时，它下载它的package.json文件（对于扩展，所有配置元数据都包含在package.json中，不需要启动它），并将这些设置传递给Ingestion Service。 整个过程都是完全自动化的，并且不断更新我们每个稳定版本构建和我们每日内幕人员构建的实时索引设置。在构建完成的几分钟内，Bing的索引已更新为包含任何新添加的设置。1. Alternative Words Pipeline用户有时会搜索与我们在设置名称和说明中使用的词语不同但相同的词语。 为确保我们能够处理这些情况，我们整合了Bing的“Alternative Word”生成管道。 该管道使用用户行为，点击次数，在线排名和页面相似度等信号，从Bing的搜索数据中收集具有类似含义的单词。 例如，“更新”和“升级”被设置为“替代词”，并且搜索一个将返回包含另一个的设置。2. Stemmer and Speller Pipeline我们不想惩罚用户拼写错误的设置名称，但我们很早就发现，简单的模糊匹配可能会错过人类可以理解的英语单词的变体，或者会包含太多的错误肯定匹配。 因此，我们还提供了Speller和Stemmer服务，该服务是从Bing.com上使用的全套服务中提取的，这些服务使用相同词干的常见拼写错误和替代形式丰富索引。 例如，“格式化”，“格式化程序”，“格式化” - 将使用“格式化”一词进行索引。3. Natural Language Processing (NLP) Pipeline我们还希望用户能够以自己的自然语言描述他们的查询，因此我们添加了Bing的自然语言处理管道。 管道收集常用的语音和文本模式，并将它们添加到索引中。 例如，它使系统能够识别“如何禁用css验证”中的重要词语以找到“css.validate”。4. Feedback/Ranking Pipeline我们创建了一个反馈机制，可以让我们从用户反馈中学习和改进。 它允许我们手动指定新的单词对或提高某些查询的预期结果。 反馈被上传到服务中，并几乎立即反映在搜索结果中。Gating Module每一次进入索引都会通过门控模块，它只是确保索引由于某些编程错误而不会被破坏。 我们编写了测试用例来验证以下内容： 新的索引是向后兼容的，可用于所有VS代码构建 我们的Golden查询集返回预期结果 门控模块失败将阻止索引摄入并立即通知团队。 还创建了仪表板服务，使我们能够监测管道各个阶段的健康情况。 它具有警报机制并能够回滚到最后已知的良好状态，以确保能够以最短的停机时间快速解决任何问题。 Search Service最后，在运行时，来自用户的查询将访问Azure负载均衡器服务，该服务根据其物理接近度或当前负载选择我们的某个地理复制服务器来处理查询。 托管在该位置的搜索服务通过索引中的查找来检索相关结果，在某些情况下应用手动排序覆盖并将其返回给VS代码客户端。 Putting it all together我们现在有一个系统，可以更好地理解设置查询，并为许多以前没有任何返回的查询提供结果。这里有些例子： 如果您有类似的问题，并且没有搜索团队像Bing团队那样为您建立定制服务，我们仍然有一些好消息。 您可以开始使用Bing的认知服务，它可以帮助您在自己的应用中添加一些智能。 例如： Bing Spell Check API Language Understanding (LUIS) Bing Web Search API Bing Custom Search API A note about testing在开发这个系统时，我们需要一种定量评估结果的方法。我们决定建立一个基于标准折扣累积收益（NDCG）概念的测试框架。没有太多的杂草，这是一种评分搜索引擎结果的方法，给出查询，一组结果和这些结果的分数。我们手工编写了很多测试用例，但意识到我们需要一种自动化的方式来为所有设置生成测试用例，包括添加的新设置和扩展中的设置。所以我们编写了一个工具，可以为任何设置自动生成测试用例。它使用设置名称和描述中的单词，并通过不同的变换器运行它们，以模拟用户选择替代单词，制作拼写错误或使用自然语言模式进行搜索。我们还为一些常用扩展的设置生成了测试用例。 我们每6小时运行一次完整的测试套件，并且可以自动进行自我更新，以便始终测试最新版本的设置。测试套件向我们保证系统运行正常，并使我们相信，当我们在后端进行更改时，我们不会损害结果质量。 What’s next有几种方法可以继续改进系统。例如，我们还建立了一个基于用户行为的自动反馈循环。如果很多人搜索类似的查询，然后选择相同的结果，我们知道结果可能是好的，应该排在更高的位置。 目前该服务仅以英文编制索引，但我们希望为翻译的设置说明编制索引并支持以非英文语言进行搜索。还有一些配置元数据目前没有索引，例如“workbench.colorCustomizations”设置的可能值。并进一步搜索，我们想显示目前未安装的扩展的结果。如果您搜索“debug python”，并且没有与本地设置相匹配的强匹配项，那么我们希望引导您使用可以帮助您调试Python代码的扩展。我们也在VS Code中考虑过这种技术的其他应用。也许命令面板可以从类似的服务中受益。 We need your feedback现在更容易找到设置，这要感谢Bing团队中的朋友！ 用户反馈是我们改进结果的最佳方式，因此，如果您没有看到您期望的结果，那么在您搜索设置时，请在GitHub上提交问题。 事实上，如果你使用VS Code Insiders，你甚至会看到一个按钮，它会调用我们的新问题记者，使你更容易提交包含我们需要的所有细节的问题。 编码快乐！]]></content>
      <tags>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于Nlog在dotNet Core2.0控制台程序中的使用]]></title>
    <url>%2F2018%2F05%2F03%2F%E5%85%B3%E4%BA%8ENlog%E5%9C%A8dotNet-Core2.0%E6%8E%A7%E5%88%B6%E5%8F%B0%E7%A8%8B%E5%BA%8F%E4%B8%AD%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[摘要： 这只是Nlog的学习笔记。教程相关教程都很详细了，在此不赘述。 开始先占坑 踩到的雷Nlog不工作前提：配置文件内容没有错，代码没有错原因：配置文件高级属性中，复制到输出目录配置错。解决办法：将复制到输出目录 属性改为]]></content>
      <tags>
        <tag>原创</tag>
        <tag>教程</tag>
        <tag>Nlog</tag>
        <tag>.Net Core</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo——Yilia主题添加文章置顶]]></title>
    <url>%2F2018%2F04%2F29%2FHexo%E2%80%94%E2%80%94Yilia%E4%B8%BB%E9%A2%98%E7%9A%84%E5%BD%92%E6%A1%A3%E9%A1%B5%E7%BD%AE%E9%A1%B6%2F</url>
    <content type="text"><![CDATA[摘要： 其实就是记录一下Yilia主题的文章置顶怎么加。百度搜索靠前的关于文章置顶的博客都是关于NexT主题的。不得不承认还是NexT主题比较火一些。可是那个主题对我来说太单调了，虽然很简洁大气，功能也多。但是Yilia的界面风格真是Get到我的点了，不想换。话说这个主题好久没更新了，也不知道作者是不是不想搞了，这可是GayHub上面排名第二的主题啊。作者加油啊🤣 开始blog目录下执行以下命令。至于原因嘛，我也不知道🙃 12npm uninstall hexo-generator-index --savenpm install hexo-generator-index-pin-top --save 然后在文章头添加 top:true 如：12345678---title: 终于装好Hexo啦date: 2018-04-19 00:04:46tags: 心情top: truecategories:- 你好，世界--- 最终效果]]></content>
      <categories>
        <category>Hexo相关</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>教程</tag>
        <tag>hexo个性化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我对比特币与区块链的理解]]></title>
    <url>%2F2018%2F04%2F22%2F%E6%88%91%E5%AF%B9%E6%AF%94%E7%89%B9%E5%B8%81%E4%B8%8E%E5%8C%BA%E5%9D%97%E9%93%BE%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[记录一下学习区块链的知识点 区块因何产生区块是挖矿程序自动产生的。以比特币来说，一笔交易只有500Byte左右，而一个区块的大小为1MB因此可以存放2000多笔交易。全网所有产生的交易数据都会广播到所有矿工节点。由挖矿程序自动写入区块之中。区块不是立即就有的，而是每十分钟生成一个。 产生时间为什么是10分钟区块的生成间隔是代码中定义好的，矿工是不能改的。对矿工个人来说，也就是说十分钟之内，挖矿程序需要找到一个魔数，加到自己生成的区块链头里。并广播出去。这样对这个矿工来说才是确确实实记成了一笔账，其实不只是1笔而是很多笔账。取决于这10分钟之内，有多少交易信息到达矿工处。由于一个区块只能存放2000笔交易，如果此时 你的交易恰好是第2001个 那么对你来说你需要等20分钟。在等待期间，你的信息位于内存池中，也就是在内存里等待处理。等到第1个十分钟过去之后，新块出现。好，你是不是在想：第一个进等待池的是不是也会第一个进块？然而并不是，挖矿程序会选择手续费较多的那个写进块里。排序规则为（手续费/交易KB大小）如果网络交易量巨多，而你的手续费又巨少，你在所有矿工那里都是要被嫌弃的，因此你的交易会很久很久得不到确认，你就得等很久很久才行。 区块是如何连接起来的区块链的结构可以视为一个垂直的栈，首区块在栈底。这样就可以使用 高度 来描述 区块与首区块之间的距离。 对每个区块头进行SHA256加密哈希，可生成一个哈希值。通过这个哈希值，可以识别出区块链中的对应区块。同时，每一个区块都可以通过其区块头的“父区块哈希值”字段引用前一区块（父区块）。也就是说，每个区块头都包含它的父区块哈希值。这样把每个区块链接到各自父区块的哈希值序列就创建了一条一直可以追溯到第一个区块（创世区块）的链条。引用 区块头hash值是由机器算出来的，并非包含在区块头内。区块头内只保存了两个hash值: 父区块hash值与 Merkle树根父区块hash值用于指向父区块。Merkle树根用户指向区块体数据 Merkle树简单来讲，Merkle树根的作用就是保证区块中的记录不被篡改。一旦区块中的某一个记录被篡改，那么通过比较Merkle树根就可以检测到。 请注意，区块哈希值实际上并不包含在区块的数据结构里，不管是该区块在网络上传输时，抑或是它作为区块链的一部分被存储在某节点的永久性存储设备上时。相反，区块哈希值是当该区块从网络被接收时由每个节点计算出来的 区块链如何遍历我们知道 每一个区块的的头部都存放了上一块的hash值。那么我们下载下来当前所有数据之后该怎么遍历呢？不过我们要清楚一点，遍历操作本身取决于你本地存储区块所采用的数据结构。如果是数组存放，那么遍历就是简单来说for循环一遍。那么区块头部的hash值有什么用呢？那就是当你取下一块数据的时候可以验证下一块究竟是不是上一块的后继区块。将当前区块自身头部的Hash与下一个区块存放的前驱区块的hash做比较，就能知道这两个区块是不是一串。 区块的hash有什么用区块的hash的生成是 参考资料精通比特币]]></content>
      <categories>
        <category>学习笔记</category>
        <category>区块链</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>比特币</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用RSS]]></title>
    <url>%2F2018%2F04%2F22%2F%E4%BD%BF%E7%94%A8RSS%2F</url>
    <content type="text"><![CDATA[占坑]]></content>
      <categories>
        <category>Hexo相关</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用HexoEditor写博客]]></title>
    <url>%2F2018%2F04%2F21%2FhexoEditorTest%2F</url>
    <content type="text"><![CDATA[摘要： 哎怎么说呢，HexoEditor 太好用了，大大方便了写博客的效率。比如一键上传博客图片，让我省的打开腾讯云客户端手动上传和建立文件夹了。现在我要记录以下日常使用中一些经常用到的操作。 开始在windows下 以管理员身份运行以下命令123456789npm config delete proxynpm config set prefix "C:/Program Files/nodejs/npm_global"npm config set cache "C:/Program Files/nodejs/npm_cache" npm config set registry "https://registry.npm.taobao.org/"npm config set electron_mirror "https://npm.taobao.org/mirrors/electron/"git clone https://github.com/zhuzhuyule/HexoEditor.gitnpm install -g electron@1.8.1npm installnpm start 使用导入配置绑定图床]]></content>
      <categories>
        <category>Hexo相关</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>教程</tag>
        <tag>HexoEditor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo+yilia个性化之-添加背景音乐]]></title>
    <url>%2F2018%2F04%2F21%2Fhexo-yilia%E4%B8%AA%E6%80%A7%E5%8C%96%E4%B9%8B-%E6%B7%BB%E5%8A%A0%E8%83%8C%E6%99%AF%E9%9F%B3%E4%B9%90%2F</url>
    <content type="text"><![CDATA[添加背景音乐获取外链打开网易云音乐 点击图中按钮跳转到外链创建页面。 很多好听的音乐都因为版权原因无法创建外链，所以只能多换几个试试。 说明： 可以调整控件的长度。不过初始长度相对较长，直接添加会看起来不居中影响美观，后面再调 自动播放属性根据自己的习惯设置。 之后也可以通过直接修改箭头所指的数值来改变大小 之后也可以通过修改 0或1 来关闭或打开自动播放 粘贴代码打开路径 themes/yilia/layout/_partial/left-col.ejs 找到如图所示位置，将获取的外链粘贴上去。 当然不一定非得是这个地方，根据需要可以选择不同的安放位置 调整大小究竟要调整到多长才能看起来居中?我尝试了很多次长度，都不太满意。后来我就想到一个取巧的办法。如图所示： 由此确定我们最好将控件长度修改为 228px 完成居中效果看起来还是不错的。 另： 当用手机端查看的时候控件会消失，因此不能控制暂停。请注意这一点。 ipad布局没有测试，因为我没有ipad…. ( ￣へ￣) 每进入一个新的页面音乐都会重新开始播放，我还不知道怎么办。]]></content>
      <categories>
        <category>Hexo相关</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>教程</tag>
        <tag>hexo个性化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[https学习笔记]]></title>
    <url>%2F2018%2F04%2F21%2Fhttps%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[非专业解释，主要便于理解 HTTPS协议的简单理解流程描述HTTPS的通信流程可以简单描述一下 可以认为服务器有两把钥匙，一把叫公钥 一把叫私钥（服务器）。“公钥”的作用只有一个：让客户端对自己的信息加密。 客户端发送请求。 服务器返回证书。 客户端对证书进行验证。（防止冒充服务器） 客户端验证成功则进行第5步否则警告用户 客户端会产生一个随机数并结合某种算法生成一个临时私钥 客户端使用证书里面的公钥把临时私钥加密并传输给服务器 服务器使用私钥解密客户端消息获取临时私钥 客户端使用临时私钥加密并发送敏感信息（比如密码） 服务器使用临时私钥解密并获取敏感信息 在上述过程中，所有的信息都是加密传输的。即使抓包也只是一堆看不懂的密文：没有拿到服务器的私钥那就没办法查看客户端与服务器的临时私钥，因为临时私钥是用公钥加密过的，只能用服务器的私钥解密。因此中间过程不可能下得了手。 客户端将这个随机生成的临时私钥用服务器的公钥加密发给服务器，服务器用自己的私钥解密，这时候服务器也就获取了临时私钥。 接下来的对话就不是非对称加密的方式了，而是使用的对称加密，服务器用临时私钥加密信息发给客户端，客户端也用临时私钥把信息解密。 一些HTTPs的知识点 SSL/TLS协议 非对称加密 对称加密 单向散列函数 中间人攻击 域名劫持 签名 证书 关于HTTPs的好处用了它后台就可以不必煞费苦心进行传输信息的加密了，省劲儿。 关于根证书首先，一般系统会预置很多根证书，它们都是来自受信任的根证书颁发机构，并且全球也就那么几所机构而已。其他网站如果需要使用HTTPs，那么只能向这些机构购买证书，证书都有一个生效期以及失效期。 有时候使用机房的电脑上网总会提示证书警告，原因可能就是机房电脑的系统时间不对，要么还没到生效期要么就是过了失效期。没有该CA机构的根证书，那么任何由这个机构颁发的证书都会无法通过证书是可以自己生成，但是几乎所有的客户端都不信任你，想让客户端信任的话只能手动安装根证书才行 证书能不能伪造关于证书能不能伪造的问题已经由一个很合理的描述: 数字证书里有CA的数字签名，签名是由证书内容的哈希摘要用CA的私钥加密的。用CA的公钥验证签名的合法性就可以验证证书的真假 参考资料 12306.cn 购票为什么要安装根证书？ RSA的公钥和私钥到底哪个才是用来加密和哪个用来解密？ 私钥、公钥、数字签名、数字证书、HTTPS HTTPS必须在每次请求中都要先在SSL层进行握手传递秘钥吗？ 聊聊HTTPS和SSL/TLS协议 HTTPS 原理详解 浏览器如何验证HTTPS证书的合法性？ HTTPS 服务器和客户端如何进行加密解密的? 公钥与私钥，HTTPS详解 (推荐看看) 国内CA机构沃通错误颁发GitHub域名SSL证书]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>HTTPS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JWT学习笔记]]></title>
    <url>%2F2018%2F04%2F21%2FJWT%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[为一个自娱自乐的项目开发WebAPI的时候，我尝试使用了Token验证机制。对于我这样一个菜鸟来说，Token的验证机制在我理解中十分简单：先使用用户名和密码登录系统，服务器会返回一个字符串，约定好这个字符串就是系统出入的通行令牌客户端之后除了登录操作的所有请求只要带上这个字符串，系统就会放行。好，到现在就明白了，“Token”在当时的我看来只是一个字符串，我只需要保证这个字符串一人一个不重样即可。于是我就使用了GUID（全局变量标识符）来充当Token。但是使用过程中就有了问题。这个Token是生成了而且不重样，可我怎么确立它和用户之间的对应关系？于是我想到把Token存到用户表中，假设用户带着Token访问更新用户信息的API，服务器拿到Token去查询用户表，进而找到对应的用户名。至此我就知道了这个Token是哪位用户的了。拿着这个用户名，就可以更新该用户的表项了。那么其它的API也是这个这样，首先第一件事要做的就是去查询数据库找到对应的用户名，才能进行其他的操作。按照我的思路的话，这个方式虽然麻烦一点，但是还是能实现功能的。另一个观于Token的常见要求是，它得能设置有效期，总不能一个Token用一辈子吧。于是我又往用户表加了一列过期时间，每次验证Token都要从数据库中拿出到期时间与当前时间做比较来判断是不是过期了。 JWT的基本概念JWT（Json Web Token）本质上是一种Token的设计规范。用于实现Token机制的Token说到底也就是个字符串，重点是这个字符串该怎么写才会比较合理。我试过用GUID来充当这个Token实现简单的Token身份验证机制，完全没问题。可就是用起来有点别扭。而JWT就是一种更加合理的组织Token字符串的方式。它使用JSON格式，总体分为三个大块：Header .Payload. Signature,分别承担各自的责任。 Header 1234&#123; "alg": "HS256", "typ": "JWT"&#125; Payload 12345&#123; "sub": "1234567890", "name": "John Doe", "admin": true&#125; Signature 1234HMACSHA256( base64UrlEncode(header) + "." + base64UrlEncode(payload), secret) 整体结构为：header (base64)+payload (base64)+Signature有关那些Claim的说明官网上有详细介绍。 接下来从Signature出发看看可以挖到什么知识。↓ 关于Signature前两部分的处理都十分简单，关于Signature的处理有点让人眼花缭乱，特别是我这种对密码技术一无所知的小白。关于这个最后一部分我有过一点误解：以为使用SHA-256进行处理以后就可以看做是对JWT加密了别人就看不到了。其实并不是这样的。首先要声明，最后一部分“签名”并不是对Token进行加密处理。而HS256也不是一般意义上的加密函数，它的全称是HMAC using SHA-256，这牵扯到的就多了。 要理解它首先要知道一下几个概念： 1. 单向散列函数：单向散列函数也称信息摘要函数（Message Digest Function）,哈希（Hash）函数或者杂凑函数。 它是其余两个概念的基础。现在不考虑具体实现，把这个概念当成一个黑箱。 输入： 任意长度消息（可以是1bit 、1K、1M，甚至可以100G）输出： 一串固定长度的数据（散列值，也称消息摘要，指纹） 单项散列函数有如下几种特性： 根据任意长度消息得出的散列值长度是固定的。 散列值计算时间短 不同的消息有不同的散列值（如果两个不同消息的散列值相同，那就称为发生碰撞） 根据散列值无法还原消息（单向性，只能从消息到散列值，反之不成立） 关于单向散列函数的应用，很常见的一个就是文件的校验 图片中所使用的哈希函数是 SHA-1（也有使用MD5的）。有了它就看可以确定下载的文件是不是被动过手脚。因为软件在发布的时候会同时公布它散列值，正在下载的软件也可以计算散列值，两个散列值相同就说明是同一个软件。 常见的单项散列函数： MD4(Message Digest 4) MD5(Message Digest 5) SHA-1 SHA-256 数字代表散列值长度为256bit SHA-384 SHA-512 2. MAC 消息认证码MAC:Message Authentication Code 即消息认证码 它可以确认消息完整性并进行认证。 输入： 消息+发送者以及接收者之间共享的密钥 注：与单项散列函数不同之处就是它多了一个密钥的参与 输出： 固定长度的数据，称为MAC值 注：这就跟单向散列函数一样了 确切来说它指的是一种认证机制。这种机制有多种实现方法，单项散列函数就是其中之一。使用单向散列函数（也称Hash函数）实现的消息认证码就称为 HMAC，其中H就是Hash的意思。一次解决了单项散列函数虽然可以检测到篡改（完整性），但是却没有办法识别伪装的问题。 注：无法识别伪装是因为如果有第三者假装其中一方发消息，另一方根本无从知晓这个消息是不是对方发来的。 3.HMAC 哈希消息认证码上面也提到了，HMAC就是使用了单项散列函数来构造消息认证码的一种方法（RFC2104）。根据它所使用的散列函数不同，就出现了如下这么多种 HMAC HMAC 算法 备注 HS256 HMAC using SHA-256 HS384 HMAC using SHA-384 HS512 HMAC using SHA-512 注：使用消息认证码是无法保证消息的机密性的，它只能保证消息被正确的传送了。例如 传送的完整消息格式为 “123456”+“消息验证码”，消息验证码的作用就是在对方收到消息之后可以根据验证码来验证 “123456”是没有被修过的。至于机密性，那需要对“123456”进行加密，而这不关消息验证码什么事。 消息认证码有两个无法解决的问题： 对第三方证明 防止否认 数字签名可以解决上述问题，但是这与JWT 关系不大。现在我明白了，被在JWT中被称为 “Signature 签名”的部分，其实是前两部分的消息认证码（MAC），官方称之为数字签名我觉的其实并不怎么准确。在JWT中密钥并不与客户端共享，其为服务器独有。这样一来只有服务器可以发Token，而客户端因为缺少密钥而无法伪造 Token。服务器会对每个请求里面的Token用密钥来算MAC值来验证这个Token是不是自己发出去的。 而且为了确保Token不是一直有效，还要加一些时间戳来限制 Reserverd claims 说明 exp(Expiration time) 是一个时间戳，代表这个JWT的过期时间 nbf(Not Before) 是一个时间戳，代表这个JWT生效的开始时间，意味着在这个时间之前验证JWT是会失败的 iat(Issued at) 是一个时间戳，代表这个JWT的签发时间 jti(JWT ID) 是JWT的唯一标识 这些时间戳可以让服务器知道这个Token有没有过期。 关于所谓JWT的安全性对于Token的安全性，其实我觉得没什么好说的，Token实质上就是一个由服务器签发的无法伪造的令牌。JWT能够保证令牌无法伪造就已经足够安全了。至于什么“黑客拿到了令牌怎么办，要是有中间人劫持，拦截了怎么办”之类的安全问题，并不是JWT的锅，而是传输协议的锅。HTTP协议 明文传输信息而造成的安全问题，JWT能有什么责任？最简单的方法就是换HTTPS协议喽。 使用JWT来进行用户身份认证 C#中怎么生成JWT格式的TokenJWT在各个平台都有已经封装好的库可以使用在.NET平台下有如下几个命名空间可以引用： sharp123using System.Security.Claims;using System.IdentityModel.Tokens.Jwt;using Microsoft.IdentityModel.Tokens; 微软把这些类全都开源放在在Github上面可以供研究其实现过程 关于JWT的Claim Reserverd claims 说明 iss(Issuser) 代表这个JWT的签发主体 sub(Subject) 代表这个JWT的主体，即它的所有人 aud(Audience) 代表这个JWT的接收对象 exp(Expiration time) 是一个时间戳，代表这个JWT的过期时间 nbf(Not Before) 是一个时间戳，代表这个JWT生效的开始时间，意味着在这个时间之前验证JWT是会失败的 iat(Issued at) 是一个时间戳，代表这个JWT的签发时间 jti(JWT ID) 是JWT的唯一标识 哈希算法 alg 参数 Digital Signature or MAC 算法 HS256 HMAC using SHA-256 hash algorithm HS384 HMAC using SHA-384 hash algorithm HS512 HMAC using SHA- 5 12 hash algorithm RS256 RSASSA using SHA-256 hash algorithm RS384 RSASSA using SHA- 384 hash algorithm RS512 RSASSA using SHA-512 hash algorithm ES256 ECDSA using P-256 curve and SHA-256 hash algorithm ES384 ECDSA using P- 384 curve and SHA-384 hash algorithm ES512 ECDSA using P-521curve and SHA-512 hash algorithm none No digital signature or MAC value included 参考资料JWT实现token-based会话管理MAC算法廖雪峰Python]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>JWT</tag>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用腾讯云对象存储作为图床]]></title>
    <url>%2F2018%2F04%2F20%2F%E4%BD%BF%E7%94%A8%E8%85%BE%E8%AE%AF%E4%BA%91%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E4%BD%9C%E4%B8%BA%E5%9B%BE%E5%BA%8A%2F</url>
    <content type="text"><![CDATA[开始腾讯云的对象存储是有免费额度的，而且还不算少 七牛云的免费额度略有不同：写请求数为50万次每月 控制台配置注意有两个关键的配置不能忽略 存储桶（bucket）访问权限 防盗链设置 访问权限访问权限应设置为公有读私有写。很好理解，我们是要用COS来做图床的，必然是需要获取文件的直接链接才行，所以不能在读取图片的时候设置权限。 权限设置文档在此 防盗链如果被盗链会导致你的免费额度可能会快用尽，因此防盗链也是需要考虑的。下图以我的博客地址为例 开启之后即使其他人获取到链接也无法访问相应图片 上传取链上传图片官方也有文件管理软件COS Browser ，上传下载图片还是挺方便的。 当然如果觉得这样子还是不够方便的话，可以基于腾讯云API自己开发应用 获取链接要获取图片链接的话右键文件详情即可。将其复制下来即可使用。 注：因为开启了防盗链这设置，因此当你在本地写博客的时候会出现图片无法预览的情况。因为防盗链机制只允许白名单中指定域名或IP访问。也就是说只能在博客中看 后记关于图床，国内可以选择的有很多。 网上有很多使用微信以及微博来充当免费图床的。但是如你所见，微博微信想加一个防盗链来阻止外链访问是很容易的，把图放在那上面丝毫没有安全感。 因此可以考虑腾讯云或者阿里云的对象存储服务，不过阿里云好像没有免费额度，因此没有选用。 七牛云与腾讯云类似，都可以使用免费的对象存储服务来充当自己的图床。 国外的一个知名图床 imgur 实在是可惜被墙了,不然用起来还是十分方便的。]]></content>
      <categories>
        <category>Hexo相关</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>教程</tag>
        <tag>图床</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[终于装好Hexo啦]]></title>
    <url>%2F2018%2F04%2F19%2F%E7%BB%88%E4%BA%8E%E8%A3%85%E5%A5%BDHexo%E5%95%A6%2F</url>
    <content type="text"><![CDATA[大功告成！折腾了一天终于把相册功能加上啦。 待我考上研，一定好好维护这个博客！ 2018年4月19日晚12点 留 建站参考 以下是我在折腾博客的过程中对我有很大帮助的博文链接，在此十分感谢作者们的分享。 添加文章置顶2018年4月29日 完成hexo博客优化之文章置顶+置顶标签 作者: wangwlj Hexo高级教程Hexo高级教程之主题开发作者：Jamling Issue功能的使用github issue 的用法作者：XiChen 增加Gitment评论系统Hexo-Yilia中添加gitment评论功能 作者：好大一棵树 增加文章访问统计hexo yilia 主题添加文章访问统计 作者 枫之木落作者：枫之木落 原链接：给Hexo博客添加访问统计原作者：心彻 增加文章版权声明 在Hexo中自动为Yilia主题增加版权声明 作者：F!redent 增加ins相册模块Hexo博客创建ins相册模块 作者：Luojinghui 增加主题(Yilia)一个简洁优雅的hexo主题 作者：Litten Bug修复（坑）修复重新打包以后子标题不居中问题。原因： CSS中莫名奇妙缺失一个属性 -webkit-box-orient: vertical;解决办法： 在生成的CSS文件中找到 相应位置粘上去即可。 2018年4月29日 22点24分 补充：CSS文件的位置在1\themes\yilia\source CSS文件名称每次生成都不一样，一般是 main.%%%%%%.css。如果文件夹下有很多main开头的CSS文件，那么可以全删掉重新生成。这样就会只有一个main.css了。 打开之后可能会看到密密麻麻的字符，这因为生成的时候如果是执行的 1npm run dist 那么生成的css文件和js文件全部都是压缩以后的，它们的格式全都没了，所以从头连到尾。这时候你需要用使用文本编辑器的搜索功能，搜索关键字 header-subtitle123456789101112.header-subtitle&#123; text-align:center; color:#999; font-size:14px; line-height:25px; overflow:hidden; text-overflow:ellipsis; display:-webkit-box; -webkit-line-clamp:2;/*在此行后面添加*/ -webkit-box-orient: vertical; padding:0 24px &#125; 整个CSS文件中有两处需要这样改动，因为一处对应的是 桌面端布局生效。另一处则是移动端生效 修复Gitment初始化Comment失败的问题 2018年4月21日20点23分原因： Comments的lable字数超过最大长度（50个字符）解决办法： 使用文章创建时间当label就不会超长了添加Gitment评论系统踩过的坑作者：XiChen 注：在Yilia主题中，是需要进入此路径下进行更改id的： layout/_partial/post/gitment.ejs 配色方案蓝色代码：#00C3FF （0,195,255） 黄色代码：#FFE149（255,225,73）]]></content>
      <categories>
        <category>你好，世界</category>
      </categories>
      <tags>
        <tag>hexo个性化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VScode+Sphinx+ReadTheDocs从环境搭建到放弃]]></title>
    <url>%2F2017%2F12%2F21%2FVScode%2BSphinx%2BReadTheDocs%E4%BB%8E%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E5%88%B0%E6%94%BE%E5%BC%83%2F</url>
    <content type="text"><![CDATA[概述此篇博客用来记录在windows10中配置环境的过程，注意是Windows下 ，我没有在Linux下面尝试过配置。一下参考了各路教程加上自己亲测，应该是没有问题的。 ……..被掏空(◎_◎;) 材料清单 Python 3.4 Visual Studio Code Git GitHub仓库 GitHub Desktop 工具安装 安装Python3.4 安装Git 安装Visual Studio Code 安装GitHubDesktop 正确安装完上述软件之后接下来说明具体操作： 打开PowerShell 输入命令： 安装 sphinx1pip install sphinx sphinx-autobuild 安装 restructuredtext-lint1pip install restructuredtext-lint 注： To Python小白：如果没有正确的将Python添加到环境变量，那么powerShell是不会识别 pip 命令的。我也是个Python小白呵呵呵 VScode配置 安装插件 reStructuredText 它提供了.rst文件的预览功能十分便捷。 安装插件 Table Formatter 由于reStructuredText做表格特别麻烦，这个插件可以帮助你做表格，只需要把关键的标记写对，其余的都会自动补全而且效果十分美观。 注意： 插件安装完成之后需要点击重新加载方能生效 To ：VSCode小白 新建Sphinx项目 新建一个目录 比如就叫：sphinxtest 在此目录下打开VSCode 打开集成终端并输入命令：1sphinx-quickstart 过程如下： 在这么长的流程中，一般来说只有三项是需要你手动输入的，其余的均可以直接敲Enter Project name: sphinxtestProject （项目名称） Author name(s): Tom （作者） Project version []: 1.0.1 （项目版本） 注释： 文档根目录(Root path for the documentation)，默认为当前目录(.) 是否分离文档源代码与生成后的文档(Separate source and build directories): y 模板与静态文件存放目录前缀(Name prefix for templates and static dir):_ 项目名称(Project name) : EvaEngine 作者名称(Author name)：AlloVince 项目版本(Project version) : 1.0.1 文档默认扩展名(Source file suffix) : .rst 默认首页文件名(Name of your master document):index 是否添加epub目录(Do you want to use the epub builder):n 启用autodoc|doctest|intersphinx|todo|coverage|pngmath|ifconfig|viewcode：n 生成Makefile (Create Makefile)：y 生成windows用命令行(Create Windows command file):y 过程执行完成 选择 index.rst 之后选择预览 效果如下： 然而这个主题我个人感觉丑的不能直视 那么我们就换一个主题吧： 首先打开 Conf.py 将原本的 1html_theme = &apos;alabaster&apos; 换成 1html_theme = &apos;sphinx_rtd_theme&apos; 如图 接着打开终端 1pip install sphinx_rtd_theme 这样就好看多了 GitHub配置将刚才新建的 Shinxtest 文件夹 Push到GitHub仓库中，你可以单独为它建立一个仓库，也可以将它添加到你的一个项目仓库中作为项目文档。比如我就把它作为项目文档放进了我的项目仓库里。 GitHub 里选择仓库，然后依次点击 Setting =&gt; Webhooks &amp; Service =&gt; Add service =&gt; ReadTheDocs,激活这个选项。 Read The Docs 配置Read The Docs 主要是一个 进入RTD官网 注册并登陆 连接GitHub 选择Import a project 导入成功后，点击阅读文档，便可看到 Web 效果了。 完成到这里算是成功啦，你可以打开VScode 在本地对 文档进行编辑。编辑完之后，由于VSCode安装了Git 所以支持将本地做的更改同步到GitHub仓库。嗯， 啊··结束！ . 参考资料[1] http://avnpc.com/pages/writing-best-documentation-by-sphinx-github-readthedocs写最好的文档：Sphinx + Read the Docs [2] https://www.jianshu.com/p/78e9e1b8553a如何用 ReadtheDocs、Sphinx 快速搭建写书环境[3] http://www.sphinx-doc.org/en/stable/config.htmlThe build configuration file[4] https://github.com/vscode-restructuredtext/vscode-restructuredtext/blob/master/docs/sphinx.mdvscode-restructuredtext/vscode-restructuredtext]]></content>
      <tags>
        <tag>原创</tag>
        <tag>教程</tag>
        <tag>VScode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ESP32-DevKitC 入门指南（译）]]></title>
    <url>%2F2017%2F12%2F14%2FESP32-DevKitC-%E5%85%A5%E9%97%A8%E6%8C%87%E5%8D%97%EF%BC%88%E8%AF%91%EF%BC%89%2F</url>
    <content type="text"><![CDATA[ESP32-DevKitC 入门指南这篇指南展示了如何入门ESP32-DevKitC 开发板 需要 1 × ESP32-DevKitC 开发板 1 × micro USB 数据线 1 × 装有 Windows,Linux或 Mac OS的电脑 概述ESP32-DevKitC 是一个由乐鑫公司（Espressif）生产的的小型ESP32开发板。大部分I/O引脚由两侧排针引出以便于连接。开发者可以根据需要（as needed）将这些引脚连接到外围设备。当使用面包板时，标准化的排针也令开发变得容易且方便。 功能说明以下列表和图表介绍了ESP32-DevKitC板的关键组件、接口和控制 ESP-WROOM-32标准ESP-WROOM-32 模块焊接在ESP32-DevKitC 板 EN重置按钮：按下此按钮可以重置系统 Boot下载按钮：按住Boot按钮并按下EN按钮初始化固件下载模式。然后用户可以通过串口下载固件。 USBUSB接口。是给板子供电以及ESP-WROOM-32与PC通信的接口。 I/OESP-WROOM-32的大部分I/O引脚已由板上的两侧排针引出。用户可以对ESP32进行编程来实现各种功能，比如PWM,ADC,DAC,I2C,I2S,SPI,etc。 Esp32-DevKitC 开发板布局 供电配置以下选项可以给ESP32-PICO-KIT V4 供电： Micro USB 口。此为默认的供电连接 5V/GND 针脚 3V3/GND 针脚 警告：以上选项是互斥的，也就是说供电方式只能是以上其中一种。尝试同时使用多种连接方式给板子供电可能会损坏开发板或者电源。 开始编程在给ESP32-DevKitC 上电之前，请确保板子完好并没有明显的损坏迹象。要开始进行应用开发，跳转到Get Started 节，这将指导你进行一下几步： 在电脑上安装连接工具，使用C语言给ESP32开发应用 将模块连接到电脑并验证是否可用 给ESP32刷入示例程序 监视应用在做什么 先占坑 有空翻其他的]]></content>
      <categories>
        <category>IoT</category>
      </categories>
      <tags>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于华硕笔记本A400U进PE，改开机密码，硬盘无法识别的笔记]]></title>
    <url>%2F2017%2F10%2F10%2F%E5%85%B3%E4%BA%8E%E5%8D%8E%E7%A1%95%E7%AC%94%E8%AE%B0%E6%9C%ACA400U%E8%BF%9BPE%EF%BC%8C%E6%94%B9%E5%BC%80%E6%9C%BA%E5%AF%86%E7%A0%81%EF%BC%8C%E7%A1%AC%E7%9B%98%E6%97%A0%E6%B3%95%E8%AF%86%E5%88%AB%E7%9A%84%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[朋友的笔记本电脑忘了开机密码，让我给想想办法。我查了已有的百度经验，但是过程却一波三折。主要问题有：无法识别U盘，PE系统（win8pe）无法识别硬盘;所以我打算记录下来。所需工具：1.大白菜U盘启动盘制作工具（我用的是装机版）2.U盘 第1步 制作U盘启动盘略（参见大白菜官网教程） 第2步 重启电脑 进入BIOS 选择Advanced mode进入Bios的方法是按下电源键之后狂点 ESC键 直到出现Boot选项，然后选择Enter Setup即可 第3步 选择Advance，点击SATA configuration 第4步 SATA Mode改为AHCI 第5步 如图 选择Secure Boot 第6步 如图 将 secure boot control改为 Disable 第7步 如图 将CSM改为 Enable 第8步 如图 保存并退出 第9步 插入U盘 重启电脑从U盘启动如图，选择箭头所指的那一长串，其中第一个是正常从硬盘启动。如果选择你的U盘名的话会一直黑屏，不知道为什么 第10步 如图 如图可以重置windows开机密码 异常情况 ：硬盘无法识别原因就是没有进行第4步的操作 到此结束]]></content>
      <tags>
        <tag>原创</tag>
        <tag>修电脑2333</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UWP应用获取HTTP请求返回的MP3音频文件（以百度语音合成API为例）]]></title>
    <url>%2F2017%2F09%2F03%2FUWP%E5%BA%94%E7%94%A8%E8%8E%B7%E5%8F%96HTTP%E8%AF%B7%E6%B1%82%E8%BF%94%E5%9B%9E%E7%9A%84MP3%E9%9F%B3%E9%A2%91%E6%96%87%E4%BB%B6%EF%BC%88%E4%BB%A5%E7%99%BE%E5%BA%A6%E8%AF%AD%E9%9F%B3%E5%90%88%E6%88%90API%E4%B8%BA%E4%BE%8B%EF%BC%89%2F</url>
    <content type="text"><![CDATA[获取HTTP请求返回的MP3音频文件（以百度语音合成API为例）使用百度语音合成API时，与使用人脸识别API的最大不同之处在于：人脸识别API返回结果均为JSON格式的字符串，而语音合成API则是返回的二进制语音文件。因此在代码的编写上有很大的不同。在此之前我也上网查了好多，但是没有针对UWP的示例，经过一番摸索算是找到了可以用的办法 (～￣▽￣)～下面直接写出核心代码以供来日复习参考。注：示例代码均是从uwp项目中截取的，保留了异步用法，不清楚的话可以大致先了解一下异步编程。使用到的命名空间：12345using Windows.Web.Http;//HttpClient所属using System.Threading.Tasks;//Task所属using Windows.Storage.Streams;//IBuffer所属using Windows.Media.Playback;//MediaPlayer所属using Windows.Media.Core;//MediaSource所属 这是请求的参数列表：123456789101112List&lt;KeyValuePair&lt;String, String&gt;&gt; paralist = new List&lt;KeyValuePair&lt;string, string&gt;&gt; &#123; new KeyValuePair&lt;string, string&gt;("tex",tex_seting), new KeyValuePair&lt;string, string&gt;("lan",lan_setting), new KeyValuePair&lt;string, string&gt;("tok",access_Token), new KeyValuePair&lt;string, string&gt;("ctp",ctp_setting), new KeyValuePair&lt;string, string&gt;("cuid","cuid"), new KeyValuePair&lt;string, string&gt;("spd",spd_setting), new KeyValuePair&lt;string, string&gt;("pit",pit_setting), new KeyValuePair&lt;string, string&gt;("vol",vol_setting), new KeyValuePair&lt;string, string&gt;("per",per_setting) &#125;; 获取content 内容：12345678910private async Task&lt;IBuffer&gt; GetTtsResultAsync(string url, List&lt;KeyValuePair&lt;String, String&gt;&gt; list)// 获取文件 &#123; HttpClient hc = new HttpClient(); using (var content = new HttpFormUrlEncodedContent(list)) &#123; var response = await hc.PostAsync(new Uri(url), content); IBuffer buffer = await response.Content.ReadAsBufferAsync(); return buffer; &#125; &#125; 此处的关键点在于 使用1ReadAsBufferAsync() 来将content中的内容读取为 IBuffer 12345678910111213private async void PlayAudio(IBuffer result)//最终播放音频 &#123; folder = await KnownFolders.MusicLibrary.CreateFolderAsync("Greeting", CreationCollisionOption.ReplaceExisting);//创建文件夹 StorageFile x = await folder.CreateFileAsync("语音文件.mp3", CreationCollisionOption.ReplaceExisting);//创建文件 StorageFile storageFile = await folder.GetFileAsync("语音文件.mp3"); await FileIO.WriteBufferAsync(storageFile, result);//从缓冲写入文件 // storageFile = await folder.GetFileAsync("语音文件.mp3"); MediaPlayer _mediaPlayer = new MediaPlayer(); _mediaPlayer.Source = MediaSource.CreateFromStorageFile(storageFile); _mediaPlayer.Play(); &#125; 将content中的内容读取为缓冲类型之后，在写入文件时就可以使用1FileIO.WriteBufferAsync() 方法来将数据从缓冲区写入文件了。因为此处为mp3格式，所以在创建文件时，需要加上后缀名.mp3 1StorageFile x = await folder.CreateFileAsync("语音文件.mp3", CreationCollisionOption.ReplaceExisting); 其他获取其他类型的文件也可以同理吧 :-)]]></content>
      <tags>
        <tag>原创</tag>
        <tag>UWP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何免费获取windows10开发者账户（个人）]]></title>
    <url>%2F2017%2F08%2F31%2F%E5%A6%82%E4%BD%95%E5%85%8D%E8%B4%B9%E8%8E%B7%E5%8F%96windows10%E5%BC%80%E5%8F%91%E8%80%85%E8%B4%A6%E6%88%B7%EF%BC%88%E4%B8%AA%E4%BA%BA%EF%BC%89%2F</url>
    <content type="text"><![CDATA[免费获取 windows10 开发者账户（个人）因为要学习开发uwp应用的缘故，所以不得不注册一个windows10的开发者账户。但是胖虎眉头一皱发现此事并不简单。首先，有微软的账户不代表就有开发者账户，两者并不是一回事儿，只怪当初很傻很天真；其次，开发者账户并不是free的，个人版要花116CNY（人民币？），企业版需要600CNY；再者，就算要购买，居然也只能使用信用卡付款，[图片]，然而我只有Alipay。网上已经有很多利用学校邮箱获取免费注册码的方法了，只是它们的发布时间已经很早了， Dream Spark 网站也已经改版。我这篇博客算是写一个新版的吧。 开始前的准备 可用的微软账户 学生开发人员工具,资源和体验 | Imagine Windows 开发人员中心 可用的校园邮箱 比如： abc@学校校名.edu.cn ：这个不太好弄，视具体学校情况而定，如果本校在校生不允许注册校园邮箱（在我们学校校园邮箱只能教职工注册，学生根本不给注册的），可以借用其他学校同学的学校邮箱来用。其实不管是不是学生，只要有学校邮箱就可以进行学生认证的，你使用的邮箱所属的学校与你填写的学校信息甚至可以不同，这是亲测，我就是这样子。 步骤1.获取注册代码 使用微软账户登录 Imagine 填写个人以及学校信息 选择学生验证方式 登录学校邮箱接收验证邮件 完成验证 回到主页点击导航栏中的下载→软件目录 找到如图栏目： 下面有传送门获取windows应用商店代码 步骤2.注册开发者账户 进入开发人员中心 登录后点击注册传送门：注册成为应用开发人员 填写表格 ，账户类型当然是选择个人 粘贴代码 完成喽]]></content>
      <categories>
        <category>杂货铺</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows10IoT+树莓派官方摄像头（Pi Camara） == 暂时无解]]></title>
    <url>%2F2017%2F06%2F29%2Fwindows10IoT%2B%E6%A0%91%E8%8E%93%E6%B4%BE%E5%AE%98%E6%96%B9%E6%91%84%E5%83%8F%E5%A4%B4%EF%BC%88Pi-Camara%EF%BC%89-%3D%3D-%E6%9A%82%E6%97%B6%E6%97%A0%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[暂不要使用windows10IoT+树莓派官方摄像头原因如图： 主要意思就是，由于Pi Camara是通过GPU子系统连接到系统的，但是操作系统并不支持这种连接，官方还不能给出任何解决办法。但是将来会支持的。这是win10IoT官方开发团队做出的回复所以只能选择原谅他了····哇···真坑···· 详情点击：MSDN原文链接]]></content>
      <categories>
        <category>树莓派</category>
        <category>IoT</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>windows10Iot</tag>
        <tag>树莓派</tag>
      </tags>
  </entry>
</search>
